 
      Welcome - OSG      
|------------------------
| Process: --n
| Maps   : 1
|------------------------
 
Traceback (most recent call last):
  File "/home/ubuntu/mcarbonera/osg/test.py", line 150, in <module>
    neuroDist(args[1], args[2], args[3], args[4])
IndexError: list index out of range
 
      Welcome - OSG      
|------------------------
| Process: --nAll
|------------------------
 
Traceback (most recent call last):
  File "/home/ubuntu/mcarbonera/osg/test.py", line 163, in <module>
    seed, folderù
NameError: name 'folderù' is not defined
 
      Welcome - OSG      
|------------------------
| Process: --nAll
|------------------------
 
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 0}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 0
\seed data:	 0
\seed noise:	 0
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.020843 	loss:  1.0980313 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.016809 	loss:  0.13788368 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017564 	loss:  3.2462971 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.016573 	loss:  2.8804681 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.016774 	loss:  11.230031 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.016868 	loss:  9.463309 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017281 	loss:  2.018199 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017224 	loss:  -2.8795455 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017455 	loss:  2.758828 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.020816 	loss:  4.206155 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017091 	loss:  4.4347177 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017140 	loss:  3.61186 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.019072 	loss:  4.1147065 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017010 	loss:  3.6118233 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017336 	loss:  4.846055 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.016975 	loss:  4.5716786 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017938 	loss:  4.8002462 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.016741 	loss:  6.21738 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.016828 	loss:  6.2173696 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017004 	loss:  6.445931 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.016988 	loss:  6.8116345 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017301 	loss:  6.9030533 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017770 	loss:  6.765903 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017493 	loss:  6.765896 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.016979 	loss:  6.76589 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017233 	loss:  7.5887423 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017055 	loss:  8.13731 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017644 	loss:  8.137306 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017370 	loss:  8.137302 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017207 	loss:  8.137298 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017679 	loss:  8.137292 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.016840 	loss:  8.137292 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017147 	loss:  8.137291 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017102 	loss:  8.137291 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017433 	loss:  8.13729 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017458 	loss:  8.137289 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017651 	loss:  8.137288 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017851 	loss:  8.137288 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017291 	loss:  8.137287 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017519 	loss:  8.137286 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017057 	loss:  8.137285 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017627 	loss:  8.137285 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017081 	loss:  8.137284 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017251 	loss:  8.137283 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.016942 	loss:  8.137283 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017175 	loss:  8.137282 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017621 	loss:  8.137282 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017015 	loss:  8.137282 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017515 	loss:  8.137282 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017128 	loss:  8.137282 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.364840
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_0/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 9.950502 	D(real) 0.9496920108795166 	D(fake) 0.7087249755859375 	 G:  5.953518 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 9.650239 	D(real) 0.9932713508605957 	D(fake) 0.6151018540064493 	 G:  3.7842467 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 9.640325 	D(real) 0.6306263208389282 	D(fake) 0.9760944048563639 	 G:  2.9792752 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 10.359956 	D(real) 0.4967812697092692 	D(fake) 1.229878028233846 	 G:  1.9485127 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 10.530123 	D(real) 0.3248792886734009 	D(fake) 1.4301411310831706 	 G:  1.7604223 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 10.272984 	D(real) 0.29349319140116376 	D(fake) 1.418670654296875 	 G:  1.9560711 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 9.71226 	D(real) 0.3260585467020671 	D(fake) 1.2926514943440754 	 G:  2.3051353 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 9.237584 	D(real) 0.3842175006866455 	D(fake) 1.155379851659139 	 G:  2.5511408 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 9.054267 	D(real) 0.42520542939503986 	D(fake) 1.0838390986124675 	 G:  2.619168 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 9.026454 	D(real) 0.43654199441274005 	D(fake) 1.0678669611612956 	 G:  2.5998733 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 8.888826 	D(real) 0.43331368764241535 	D(fake) 1.0481572945912678 	 G:  2.594889 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 8.896168 	D(real) 0.4324825604756673 	D(fake) 1.050212065378825 	 G:  2.5863645 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 8.905663 	D(real) 0.4310626983642578 	D(fake) 1.053214470545451 	 G:  2.5753813 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 8.916519 	D(real) 0.42923521995544434 	D(fake) 1.0568513870239258 	 G:  2.5628657 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 8.928289 	D(real) 0.427146037419637 	D(fake) 1.060902198155721 	 G:  2.5494606 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 8.940478 	D(real) 0.42491193612416583 	D(fake) 1.0651678244272869 	 G:  2.5357425 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 8.952702 	D(real) 0.4226256211598714 	D(fake) 1.0694912274678547 	 G:  2.5221517 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 8.964678 	D(real) 0.42035961151123047 	D(fake) 1.0737532774607341 	 G:  2.5090108 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 8.97616 	D(real) 0.41816914081573486 	D(fake) 1.077857494354248 	 G:  2.4965677 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 8.986984 	D(real) 0.4160950183868408 	D(fake) 1.0817357699076335 	 G:  2.4849885 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 8.975944 	D(real) 0.4141662120819092 	D(fake) 1.0818243821461995 	 G:  2.4839318 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 8.976881 	D(real) 0.41398894786834717 	D(fake) 1.0821579297383626 	 G:  2.482944 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 8.97775 	D(real) 0.4138249158859253 	D(fake) 1.082466761271159 	 G:  2.4820263 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 8.978578 	D(real) 0.4136717716852824 	D(fake) 1.082757870356242 	 G:  2.4811585 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 8.979338 	D(real) 0.41352800528208417 	D(fake) 1.0830283164978027 	 G:  2.480351 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 8.980091 	D(real) 0.4133920669555664 	D(fake) 1.0832897027333577 	 G:  2.479568 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 8.980788 	D(real) 0.41326284408569336 	D(fake) 1.0835351943969727 	 G:  2.478832 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 8.9814625 	D(real) 0.4131393035252889 	D(fake) 1.0837710698445637 	 G:  2.4781225 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 8.98212 	D(real) 0.41302069028218585 	D(fake) 1.083999236424764 	 G:  2.4774356 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 8.982756 	D(real) 0.4129064480463664 	D(fake) 1.0842195351918538 	 G:  2.4767723 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 8.981646 	D(real) 0.41279582182566327 	D(fake) 1.0841450691223145 	 G:  2.4767022 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 8.981714 	D(real) 0.41278505325317383 	D(fake) 1.0841673215230305 	 G:  2.4766345 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 8.98177 	D(real) 0.41277464230855304 	D(fake) 1.0841868718465169 	 G:  2.4765754 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 8.981808 	D(real) 0.41276435057322186 	D(fake) 1.084203561147054 	 G:  2.4765248 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 8.981883 	D(real) 0.4127542972564697 	D(fake) 1.0842262109120686 	 G:  2.4764557 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 8.981939 	D(real) 0.41274432341257733 	D(fake) 1.0842456022898357 	 G:  2.4763973 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 8.981985 	D(real) 0.412734587987264 	D(fake) 1.0842628479003906 	 G:  2.476344 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 8.982034 	D(real) 0.4127248128255208 	D(fake) 1.0842808087666829 	 G:  2.47629 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 8.9821005 	D(real) 0.4127151568730672 	D(fake) 1.0843016306559246 	 G:  2.4762263 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 8.9821615 	D(real) 0.4127055803934733 	D(fake) 1.0843213399251301 	 G:  2.4761658 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 8.98203 	D(real) 0.4126960039138794 	D(fake) 1.0843090216318767 	 G:  2.476169 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 8.982038 	D(real) 0.41269512971242267 	D(fake) 1.0843111673990886 	 G:  2.4761624 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 8.982054 	D(real) 0.41269417603810626 	D(fake) 1.0843147436777751 	 G:  2.476152 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 8.982059 	D(real) 0.41269322236378986 	D(fake) 1.0843164920806885 	 G:  2.4761465 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 8.982061 	D(real) 0.4126923084259033 	D(fake) 1.0843180020650227 	 G:  2.476142 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 8.982069 	D(real) 0.4126913547515869 	D(fake) 1.0843202273050945 	 G:  2.4761348 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 8.982065 	D(real) 0.4126904010772705 	D(fake) 1.0843205451965332 	 G:  2.4761333 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 8.982086 	D(real) 0.41268948713938397 	D(fake) 1.084324836730957 	 G:  2.4761207 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 8.982073 	D(real) 0.4126885732014974 	D(fake) 1.084323565165202 	 G:  2.4761245 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 8.982077 	D(real) 0.41268761952718097 	D(fake) 1.0843252340952556 	 G:  2.4761195 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 1}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 1
\seed data:	 1
\seed noise:	 1
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.019427 	loss:  0.4365818 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018516 	loss:  0.9876358 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018521 	loss:  9.912986 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018378 	loss:  10.946436 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.019597 	loss:  10.878265 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.018581 	loss:  10.945816 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.019001 	loss:  11.091861 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.018549 	loss:  11.198544 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018777 	loss:  11.2541065 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018359 	loss:  8.922507 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018440 	loss:  8.742207 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018350 	loss:  7.261599 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.018289 	loss:  7.2809896 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018220 	loss:  7.166238 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018528 	loss:  6.106777 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018601 	loss:  6.1949162 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018791 	loss:  6.2143087 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018616 	loss:  6.194913 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018301 	loss:  6.1949105 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.018963 	loss:  6.233696 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018144 	loss:  6.2530875 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018265 	loss:  6.2336917 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018674 	loss:  6.23369 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018867 	loss:  6.1949 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018437 	loss:  6.228053 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018906 	loss:  6.2065573 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018406 	loss:  6.194896 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018701 	loss:  6.2433796 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.018413 	loss:  6.2363753 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018356 	loss:  6.3112555 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018792 	loss:  6.311254 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018416 	loss:  6.311254 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018916 	loss:  6.3112535 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018873 	loss:  6.3112535 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018113 	loss:  6.311253 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.019010 	loss:  6.3188696 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018350 	loss:  6.318869 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018326 	loss:  6.318869 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018436 	loss:  6.311252 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018958 	loss:  6.330646 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018749 	loss:  6.3112516 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018549 	loss:  6.333398 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018053 	loss:  6.359736 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018322 	loss:  6.3444743 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018703 	loss:  6.352208 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018976 	loss:  6.359735 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018718 	loss:  6.3522077 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018787 	loss:  6.359735 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018824 	loss:  6.359735 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.018513 	loss:  6.359735 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.285716
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_1/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 20.26149 	D(real) 0.5246449947357178 	D(fake) 1.5015040397644044 	 G:  5.0098143 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 15.519289 	D(real) 0.5016668796539306 	D(fake) 1.0502620697021485 	 G:  4.5694604 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 15.43376 	D(real) 0.45685977935791017 	D(fake) 1.0865161895751954 	 G:  4.2141943 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 15.358345 	D(real) 0.42138004302978516 	D(fake) 1.114454460144043 	 G:  4.1048994 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 15.212896 	D(real) 0.4105051040649414 	D(fake) 1.1107845306396484 	 G:  4.1665173 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 15.066698 	D(real) 0.4166584491729736 	D(fake) 1.0900113105773925 	 G:  4.2759495 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 14.981085 	D(real) 0.42762088775634766 	D(fake) 1.0704875946044923 	 G:  4.3462944 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 14.971896 	D(real) 0.4346609115600586 	D(fake) 1.062528705596924 	 G:  4.345801 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 15.024565 	D(real) 0.43457398414611814 	D(fake) 1.0678825378417969 	 G:  4.282106 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 15.111371 	D(real) 0.42821130752563474 	D(fake) 1.082925796508789 	 G:  4.183463 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 14.945434 	D(real) 0.418355655670166 	D(fake) 1.0761877059936524 	 G:  4.1730337 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 14.955832 	D(real) 0.41728720664978025 	D(fake) 1.0782959938049317 	 G:  4.161771 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 14.96525 	D(real) 0.41619105339050294 	D(fake) 1.0803339958190918 	 G:  4.151115 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 14.975287 	D(real) 0.41509857177734377 	D(fake) 1.0824301719665528 	 G:  4.1403403 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 14.984698 	D(real) 0.4140325546264648 	D(fake) 1.0844372749328612 	 G:  4.130167 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 14.993882 	D(real) 0.4130093574523926 	D(fake) 1.0863788604736329 	 G:  4.120435 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 15.002359 	D(real) 0.41204056739807127 	D(fake) 1.0881953239440918 	 G:  4.111426 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 15.010214 	D(real) 0.411134147644043 	D(fake) 1.0898872375488282 	 G:  4.103111 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 15.017729 	D(real) 0.41029510498046873 	D(fake) 1.0914777755737304 	 G:  4.0953536 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 15.024406 	D(real) 0.4095261573791504 	D(fake) 1.0929144859313964 	 G:  4.088404 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 15.009533 	D(real) 0.4088279724121094 	D(fake) 1.0921253204345702 	 G:  4.08779 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 15.010471 	D(real) 0.4087651252746582 	D(fake) 1.0922820091247558 	 G:  4.087025 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 15.010941 	D(real) 0.4087080955505371 	D(fake) 1.092385959625244 	 G:  4.086523 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 15.011032 	D(real) 0.4086559295654297 	D(fake) 1.092447280883789 	 G:  4.0862317 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 15.011934 	D(real) 0.40860776901245116 	D(fake) 1.0925856590270997 	 G:  4.085548 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 15.012302 	D(real) 0.4085629940032959 	D(fake) 1.0926671981811524 	 G:  4.0851493 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 15.01248 	D(real) 0.4085208892822266 	D(fake) 1.0927270889282226 	 G:  4.084859 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 15.013201 	D(real) 0.40848121643066404 	D(fake) 1.0928388595581056 	 G:  4.0843043 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 15.013094 	D(real) 0.40844340324401857 	D(fake) 1.0928659439086914 	 G:  4.084176 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 15.013712 	D(real) 0.4084073543548584 	D(fake) 1.0929638862609863 	 G:  4.0836887 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 15.011878 	D(real) 0.4083725929260254 	D(fake) 1.0928152084350586 	 G:  4.083832 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 15.01205 	D(real) 0.408369255065918 	D(fake) 1.0928357124328614 	 G:  4.083729 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 15.012098 	D(real) 0.4083660125732422 	D(fake) 1.0928438186645508 	 G:  4.0836873 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 15.012242 	D(real) 0.40836286544799805 	D(fake) 1.0928613662719726 	 G:  4.0835996 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 15.012126 	D(real) 0.4083597183227539 	D(fake) 1.0928528785705567 	 G:  4.083642 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 15.012166 	D(real) 0.4083566665649414 	D(fake) 1.092859935760498 	 G:  4.083607 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 15.012312 	D(real) 0.4083536148071289 	D(fake) 1.0928775787353515 	 G:  4.0835185 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 15.012077 	D(real) 0.40835070610046387 	D(fake) 1.0928569793701173 	 G:  4.0836225 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 15.012075 	D(real) 0.40834774971008303 	D(fake) 1.0928597450256348 	 G:  4.0836096 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 15.012354 	D(real) 0.40834479331970214 	D(fake) 1.0928906440734862 	 G:  4.083453 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 15.012142 	D(real) 0.4083418846130371 	D(fake) 1.0928723335266113 	 G:  4.083482 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 15.012296 	D(real) 0.4083415985107422 	D(fake) 1.0928879737854005 	 G:  4.0834036 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 15.011866 	D(real) 0.4083412647247314 	D(fake) 1.0928452491760254 	 G:  4.083618 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 15.011686 	D(real) 0.4083409786224365 	D(fake) 1.092827606201172 	 G:  4.0837073 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 15.012153 	D(real) 0.4083407402038574 	D(fake) 1.092874526977539 	 G:  4.083471 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 15.012113 	D(real) 0.4083404541015625 	D(fake) 1.0928708076477052 	 G:  4.0834894 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 15.01203 	D(real) 0.4083401679992676 	D(fake) 1.0928627967834472 	 G:  4.083531 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 15.0124445 	D(real) 0.4083398818969727 	D(fake) 1.0929045677185059 	 G:  4.08332 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 15.012023 	D(real) 0.4083395957946777 	D(fake) 1.0928627014160157 	 G:  4.0835304 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 15.01207 	D(real) 0.4083393096923828 	D(fake) 1.092867660522461 	 G:  4.083505 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 2}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 2
\seed data:	 2
\seed noise:	 2
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.019553 	loss:  1.1586312 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018800 	loss:  8.649038 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018366 	loss:  9.791695 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017826 	loss:  10.782043 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018148 	loss:  10.781686 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.018663 	loss:  10.782556 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018114 	loss:  9.734757 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.018082 	loss:  8.234375 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018114 	loss:  8.423547 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018423 	loss:  3.3378487 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018679 	loss:  -3.5367112 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018392 	loss:  -3.5836844 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.018741 	loss:  -3.5384207 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018520 	loss:  -0.77492505 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.019067 	loss:  1.9156181 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018783 	loss:  3.9626095 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018686 	loss:  5.10877 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018638 	loss:  5.135599 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018834 	loss:  4.5637383 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.019091 	loss:  3.0022907 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018828 	loss:  2.9487789 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018972 	loss:  3.9947133 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018624 	loss:  3.9671416 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018960 	loss:  6.2422733 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.019073 	loss:  4.5360284 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.019092 	loss:  4.0155663 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018725 	loss:  3.6826544 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018831 	loss:  2.374867 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.018830 	loss:  4.133381 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.019095 	loss:  2.6629443 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018851 	loss:  4.329013 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.019024 	loss:  5.3203826 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.019025 	loss:  3.3297594 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018800 	loss:  2.552057 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.019098 	loss:  4.457755 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018989 	loss:  4.535373 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018823 	loss:  3.736107 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018743 	loss:  2.4164095 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.019228 	loss:  3.9791737 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018523 	loss:  5.020913 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018600 	loss:  2.3048854 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018580 	loss:  5.240468 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018671 	loss:  2.3173528 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.019069 	loss:  4.861371 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018985 	loss:  3.6362371 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.019282 	loss:  3.147084 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018519 	loss:  4.9509516 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018480 	loss:  4.634307 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.019146 	loss:  3.4334126 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.018325 	loss:  4.9464045 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.427929
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_2/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 14.771072 	D(real) 0.9452565908432007 	D(fake) 0.9011275172233582 	 G:  8.180838 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 14.473505 	D(real) 1.0263950824737549 	D(fake) 0.7827929854393005 	 G:  4.109088 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 11.932423 	D(real) 0.5137413740158081 	D(fake) 0.9778114557266235 	 G:  3.9129994 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 11.680115 	D(real) 0.4892933964729309 	D(fake) 0.9707208871841431 	 G:  4.0012836 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 11.759806 	D(real) 0.5009378790855408 	D(fake) 0.9690378904342651 	 G:  3.8765004 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 11.986453 	D(real) 0.48493334650993347 	D(fake) 1.0133732557296753 	 G:  3.581351 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 12.250254 	D(real) 0.4480304419994354 	D(fake) 1.0832512378692627 	 G:  3.2674227 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 12.487955 	D(real) 0.40867358446121216 	D(fake) 1.1523208618164062 	 G:  3.0280898 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 12.6453085 	D(real) 0.378690242767334 	D(fake) 1.20197331905365 	 G:  2.8941834 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 12.684568 	D(real) 0.36200469732284546 	D(fake) 1.2235664129257202 	 G:  2.8634586 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 12.486187 	D(real) 0.3580670952796936 	D(fake) 1.2027063369750977 	 G:  2.8690917 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 12.470524 	D(real) 0.3587262034416199 	D(fake) 1.2000893354415894 	 G:  2.8808947 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 12.449906 	D(real) 0.3601914942264557 	D(fake) 1.1960468292236328 	 G:  2.8969798 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 12.422685 	D(real) 0.36226150393486023 	D(fake) 1.190574049949646 	 G:  2.9175735 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 12.3939295 	D(real) 0.3647754490375519 	D(fake) 1.184465765953064 	 G:  2.9400942 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 12.365865 	D(real) 0.36760202050209045 	D(fake) 1.178131103515625 	 G:  2.963217 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 12.332009 	D(real) 0.3706320524215698 	D(fake) 1.1708691120147705 	 G:  2.9895492 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 12.301041 	D(real) 0.3737744688987732 	D(fake) 1.1638556718826294 	 G:  3.0149772 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 12.270859 	D(real) 0.3769535720348358 	D(fake) 1.1569037437438965 	 G:  3.0402083 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 12.2420025 	D(real) 0.38010603189468384 	D(fake) 1.1501442193984985 	 G:  3.0647922 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 12.223578 	D(real) 0.38317975401878357 	D(fake) 1.1447675228118896 	 G:  3.0671942 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 12.223601 	D(real) 0.3834742605686188 	D(fake) 1.1444759368896484 	 G:  3.0682335 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 12.2187 	D(real) 0.383755624294281 	D(fake) 1.1435818672180176 	 G:  3.071532 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 12.2161455 	D(real) 0.3840259313583374 	D(fake) 1.1429922580718994 	 G:  3.0737033 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 12.21407 	D(real) 0.3842867314815521 	D(fake) 1.1424720287322998 	 G:  3.0756214 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 12.212417 	D(real) 0.38453948497772217 	D(fake) 1.142012596130371 	 G:  3.0773168 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 12.209534 	D(real) 0.38478532433509827 	D(fake) 1.1414064168930054 	 G:  3.0795684 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 12.2075205 	D(real) 0.38502511382102966 	D(fake) 1.1409149169921875 	 G:  3.0813935 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 12.205548 	D(real) 0.3852595090866089 	D(fake) 1.1404340267181396 	 G:  3.0831828 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 12.203347 	D(real) 0.38548919558525085 	D(fake) 1.139929175376892 	 G:  3.0850656 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 12.201501 	D(real) 0.3857146203517914 	D(fake) 1.1394729614257812 	 G:  3.0853152 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 12.201338 	D(real) 0.38573676347732544 	D(fake) 1.1394304037094116 	 G:  3.0854747 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 12.201281 	D(real) 0.38575857877731323 	D(fake) 1.1394015550613403 	 G:  3.0855818 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 12.201107 	D(real) 0.3857801556587219 	D(fake) 1.1393582820892334 	 G:  3.0857446 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 12.200848 	D(real) 0.3858014941215515 	D(fake) 1.139304518699646 	 G:  3.085946 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 12.200645 	D(real) 0.38582268357276917 	D(fake) 1.1392580270767212 	 G:  3.0861208 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 12.203575 	D(real) 0.3858436942100525 	D(fake) 1.1396031379699707 	 G:  3.0848243 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 12.200213 	D(real) 0.38586461544036865 	D(fake) 1.1391620635986328 	 G:  3.0864816 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 12.200045 	D(real) 0.3858853578567505 	D(fake) 1.1391202211380005 	 G:  3.0866385 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 12.200005 	D(real) 0.3859061002731323 	D(fake) 1.1390944719314575 	 G:  3.0867357 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 12.199642 	D(real) 0.385926753282547 	D(fake) 1.139028549194336 	 G:  3.0868435 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 12.199813 	D(real) 0.38592883944511414 	D(fake) 1.1390477418899536 	 G:  3.086771 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 12.199716 	D(real) 0.3859308958053589 	D(fake) 1.139033555984497 	 G:  3.086824 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 12.199751 	D(real) 0.38593292236328125 	D(fake) 1.139035940170288 	 G:  3.0868154 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 12.1996 	D(real) 0.3859350085258484 	D(fake) 1.1390150785446167 	 G:  3.086894 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 12.1996975 	D(real) 0.38593703508377075 	D(fake) 1.139025092124939 	 G:  3.0868564 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 12.199626 	D(real) 0.3859390914440155 	D(fake) 1.1390141248703003 	 G:  3.0868974 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 12.199643 	D(real) 0.38594111800193787 	D(fake) 1.1390142440795898 	 G:  3.086897 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 12.199802 	D(real) 0.38594314455986023 	D(fake) 1.1390321254730225 	 G:  3.0868297 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 12.200647 	D(real) 0.3859451711177826 	D(fake) 1.139135718345642 	 G:  3.08644 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 3}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 3
\seed data:	 3
\seed noise:	 3
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018731 	loss:  2.0412498 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018375 	loss:  5.267794 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018451 	loss:  8.000924 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018459 	loss:  10.2537985 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018618 	loss:  10.254215 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.018278 	loss:  10.2762 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018260 	loss:  10.254123 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.018573 	loss:  10.64083 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018650 	loss:  10.740348 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018568 	loss:  2.2942438 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018227 	loss:  2.0276153 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018268 	loss:  2.3514276 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.018116 	loss:  2.5636106 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018546 	loss:  2.6616225 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018390 	loss:  3.8317928 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018387 	loss:  4.6542807 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018237 	loss:  4.8305745 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018294 	loss:  4.9189997 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018382 	loss:  4.9458733 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.018409 	loss:  4.895299 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017963 	loss:  5.10855 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018272 	loss:  5.193146 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018642 	loss:  5.399542 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018323 	loss:  5.2993846 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018173 	loss:  5.5573545 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018271 	loss:  5.5380073 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018158 	loss:  5.699499 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017961 	loss:  5.6607246 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017926 	loss:  5.7196927 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018545 	loss:  5.777027 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018134 	loss:  5.694228 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017938 	loss:  5.7620015 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018101 	loss:  5.808986 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017816 	loss:  5.734227 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018615 	loss:  5.7303276 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018262 	loss:  5.8163095 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018448 	loss:  5.8278527 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018015 	loss:  5.757496 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018160 	loss:  5.759676 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017927 	loss:  5.8255596 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018773 	loss:  5.8550076 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018832 	loss:  5.893176 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018146 	loss:  5.8434615 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017963 	loss:  5.8571963 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018286 	loss:  5.9503508 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018272 	loss:  5.8353558 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018080 	loss:  5.806144 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017967 	loss:  5.9102955 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018272 	loss:  5.8872485 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.018315 	loss:  5.8207493 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:32.264677
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_3/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 14.833873 	D(real) 0.9283250172932943 	D(fake) 0.7198830710517036 	 G:  9.682233 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 15.638013 	D(real) 1.0844381120469835 	D(fake) 0.6531188752916124 	 G:  5.1548734 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 13.680462 	D(real) 0.568781746758355 	D(fake) 0.9512695736355252 	 G:  4.5071526 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 13.133453 	D(real) 0.5027273495992025 	D(fake) 0.9565452999538846 	 G:  4.548177 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 13.267744 	D(real) 0.5072771708170573 	D(fake) 0.9669166141086154 	 G:  4.3161674 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 13.540213 	D(real) 0.48040517171223956 	D(fake) 1.0240628984239366 	 G:  3.9466019 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 13.837684 	D(real) 0.4387856854332818 	D(fake) 1.0987347496880426 	 G:  3.603888 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 14.087622 	D(real) 0.4005020459493001 	D(fake) 1.1647893057929144 	 G:  3.3686526 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 14.2241955 	D(real) 0.3743063873714871 	D(fake) 1.2061598036024306 	 G:  3.259361 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 14.220911 	D(real) 0.36214685440063477 	D(fake) 1.2179543177286785 	 G:  3.2630084 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 13.988598 	D(real) 0.3625495698716905 	D(fake) 1.1917390823364258 	 G:  3.2717266 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 13.969582 	D(real) 0.36351776123046875 	D(fake) 1.188657972547743 	 G:  3.2862635 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 13.945351 	D(real) 0.3651330206129286 	D(fake) 1.1843503316243489 	 G:  3.3050482 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 13.917669 	D(real) 0.36721981896294487 	D(fake) 1.179187880622016 	 G:  3.3268144 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 13.887904 	D(real) 0.3696390522850884 	D(fake) 1.1734613842434354 	 G:  3.3505678 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 13.857178 	D(real) 0.37227826648288304 	D(fake) 1.167408201429579 	 G:  3.3754787 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 13.826376 	D(real) 0.3750462267133925 	D(fake) 1.161217795477973 	 G:  3.4008722 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 13.796144 	D(real) 0.3778680165608724 	D(fake) 1.1550368203057184 	 G:  3.4262114 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 13.767038 	D(real) 0.38068291876051163 	D(fake) 1.1489879820081923 	 G:  3.4510326 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 13.739373 	D(real) 0.38344139522976345 	D(fake) 1.1431556277804904 	 G:  3.4750085 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 13.720484 	D(real) 0.3861042923397488 	D(fake) 1.138393931918674 	 G:  3.477283 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 13.718056 	D(real) 0.3863573604159885 	D(fake) 1.1378711064656575 	 G:  3.479443 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 13.715736 	D(real) 0.3865977128346761 	D(fake) 1.1373729705810547 	 G:  3.4815097 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 13.713523 	D(real) 0.3868270450168186 	D(fake) 1.1368977228800456 	 G:  3.4834886 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 13.711374 	D(real) 0.38704729080200195 	D(fake) 1.1364387936062283 	 G:  3.485405 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 13.709304 	D(real) 0.3872598012288411 	D(fake) 1.1359961827596028 	 G:  3.4872582 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 13.707312 	D(real) 0.38746552997165257 	D(fake) 1.1355691485934787 	 G:  3.48905 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 13.705351 	D(real) 0.38766545719570583 	D(fake) 1.13515133327908 	 G:  3.4908073 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 13.703448 	D(real) 0.3878603246476915 	D(fake) 1.1347450680202908 	 G:  3.4925194 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 13.701586 	D(real) 0.38805071512858075 	D(fake) 1.1343477037217882 	 G:  3.494197 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 13.699854 	D(real) 0.38823715845743817 	D(fake) 1.1339687771267362 	 G:  3.494363 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 13.699678 	D(real) 0.38825541072421604 	D(fake) 1.1339310540093317 	 G:  3.4945228 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 13.699491 	D(real) 0.38827337159050834 	D(fake) 1.1338922712537978 	 G:  3.4946868 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 13.699322 	D(real) 0.3882910410563151 	D(fake) 1.1338558197021484 	 G:  3.4948416 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 13.69915 	D(real) 0.3883085780673557 	D(fake) 1.1338191562228732 	 G:  3.4949982 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 13.698973 	D(real) 0.38832592964172363 	D(fake) 1.1337821748521593 	 G:  3.4951546 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 13.698809 	D(real) 0.3883431487613254 	D(fake) 1.1337466769748263 	 G:  3.495306 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 13.698642 	D(real) 0.38836023542616105 	D(fake) 1.1337110731336806 	 G:  3.495458 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 13.698469 	D(real) 0.3883772161271837 	D(fake) 1.13367493947347 	 G:  3.495612 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 13.698298 	D(real) 0.3883941173553467 	D(fake) 1.1336390177408855 	 G:  3.4957645 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 13.698121 	D(real) 0.3884109920925564 	D(fake) 1.133602460225423 	 G:  3.4957833 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 13.698122 	D(real) 0.38841266102261013 	D(fake) 1.1336008707682292 	 G:  3.4957902 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 13.6981 	D(real) 0.38841430346171063 	D(fake) 1.1335968441433377 	 G:  3.4958072 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 13.698075 	D(real) 0.38841599888271755 	D(fake) 1.1335923936631944 	 G:  3.495826 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 13.6980715 	D(real) 0.3884176943037245 	D(fake) 1.1335902743869357 	 G:  3.4958355 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 13.698045 	D(real) 0.3884192837609185 	D(fake) 1.1335857179429796 	 G:  3.495855 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 13.698027 	D(real) 0.3884210056728787 	D(fake) 1.133581903245714 	 G:  3.4958706 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 13.69801 	D(real) 0.3884226481119792 	D(fake) 1.1335785124037001 	 G:  3.4958854 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 13.698 	D(real) 0.38842429055107963 	D(fake) 1.133575651380751 	 G:  3.4958975 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 13.69799 	D(real) 0.3884259859720866 	D(fake) 1.1335728963216145 	 G:  3.4959104 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 4}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 4
\seed data:	 4
\seed noise:	 4
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018896 	loss:  3.7919645 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018182 	loss:  5.9251447 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018471 	loss:  9.963055 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017763 	loss:  11.219981 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017865 	loss:  11.219769 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.018252 	loss:  11.21955 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018120 	loss:  11.222602 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017833 	loss:  10.629712 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017808 	loss:  7.7154484 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017819 	loss:  0.14500017 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018404 	loss:  -1.6812086 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018216 	loss:  2.137215 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.018411 	loss:  1.8520815 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018326 	loss:  -1.7969071 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018329 	loss:  -3.80035 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.019046 	loss:  -3.9762354 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018273 	loss:  -4.0227885 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018304 	loss:  -3.9572816 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018301 	loss:  -4.53292 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.018738 	loss:  -4.253584 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018753 	loss:  -3.7849855 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018466 	loss:  -3.9329178 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018973 	loss:  -3.913886 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018575 	loss:  -3.7243342 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018917 	loss:  -4.1149335 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018170 	loss:  -4.193787 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018303 	loss:  -4.150141 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018201 	loss:  -3.182253 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.018359 	loss:  -3.077278 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018911 	loss:  -3.364454 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018381 	loss:  -3.8911464 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018400 	loss:  -3.3405182 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018275 	loss:  -2.8658326 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018482 	loss:  -3.0712688 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018414 	loss:  -3.4565854 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018034 	loss:  -3.0486867 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018525 	loss:  -3.2997234 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018156 	loss:  -3.2852814 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018869 	loss:  -3.7646291 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018191 	loss:  -3.7002535 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018188 	loss:  -2.9024 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018934 	loss:  -2.9111412 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018413 	loss:  -3.3114681 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018500 	loss:  -3.0090115 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018181 	loss:  -3.9870667 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018107 	loss:  -4.060968 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018514 	loss:  -3.1183298 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018371 	loss:  -2.992193 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018371 	loss:  -2.8521342 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.018283 	loss:  -3.901961 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.508754
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_4/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 13.963286 	D(real) 0.7377302646636963 	D(fake) 1.0076805353164673 	 G:  7.668323 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 13.860479 	D(real) 0.9862267374992371 	D(fake) 0.7463331818580627 	 G:  4.0417113 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 12.003028 	D(real) 0.505557656288147 	D(fake) 0.9948208332061768 	 G:  4.0167227 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 11.422684 	D(real) 0.5021233558654785 	D(fake) 0.9257121682167053 	 G:  4.376426 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 11.618045 	D(real) 0.5473437309265137 	D(fake) 0.9049118757247925 	 G:  4.2181373 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 12.027712 	D(real) 0.5275843739509583 	D(fake) 0.9758795499801636 	 G:  3.7153203 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 12.43822 	D(real) 0.4646678864955902 	D(fake) 1.0901095867156982 	 G:  3.212327 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 12.74496 	D(real) 0.40175697207450867 	D(fake) 1.191362977027893 	 G:  2.8891835 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 12.886293 	D(real) 0.361278235912323 	D(fake) 1.2495083808898926 	 G:  2.7525318 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 12.858503 	D(real) 0.34414005279541016 	D(fake) 1.2631728649139404 	 G:  2.7499342 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 12.637678 	D(real) 0.3437860608100891 	D(fake) 1.2359237670898438 	 G:  2.7591007 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 12.6148 	D(real) 0.34493303298950195 	D(fake) 1.2319170236587524 	 G:  2.775173 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 12.585012 	D(real) 0.34693655371665955 	D(fake) 1.2261899709701538 	 G:  2.7962527 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 12.550559 	D(real) 0.34956812858581543 	D(fake) 1.2192517518997192 	 G:  2.820942 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 12.513386 	D(real) 0.3526514172554016 	D(fake) 1.211521863937378 	 G:  2.8480656 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 12.474524 	D(real) 0.35604754090309143 	D(fake) 1.2032679319381714 	 G:  2.8768888 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 12.435455 	D(real) 0.35964536666870117 	D(fake) 1.194786548614502 	 G:  2.9065201 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 12.396726 	D(real) 0.3633544147014618 	D(fake) 1.1862362623214722 	 G:  2.936493 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 12.359007 	D(real) 0.36710065603256226 	D(fake) 1.1777751445770264 	 G:  2.9663033 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 12.322861 	D(real) 0.37082308530807495 	D(fake) 1.16953444480896 	 G:  2.9955087 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 12.303897 	D(real) 0.37447118759155273 	D(fake) 1.1635159254074097 	 G:  2.9982734 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 12.300594 	D(real) 0.3748233914375305 	D(fake) 1.1627509593963623 	 G:  3.0010061 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 12.297496 	D(real) 0.37516269087791443 	D(fake) 1.1620242595672607 	 G:  3.0036104 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 12.294344 	D(real) 0.37549105286598206 	D(fake) 1.1613019704818726 	 G:  3.006207 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 12.291207 	D(real) 0.3758101463317871 	D(fake) 1.1605907678604126 	 G:  3.008772 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 12.288459 	D(real) 0.37612131237983704 	D(fake) 1.1599360704421997 	 G:  3.0111365 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 12.285711 	D(real) 0.3764256536960602 	D(fake) 1.1592882871627808 	 G:  3.013483 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 12.282965 	D(real) 0.376723974943161 	D(fake) 1.158646583557129 	 G:  3.0158112 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 12.280149 	D(real) 0.377017080783844 	D(fake) 1.1580015420913696 	 G:  3.018157 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 12.2773695 	D(real) 0.3773055374622345 	D(fake) 1.1573656797409058 	 G:  3.0204723 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 12.275838 	D(real) 0.3775898516178131 	D(fake) 1.1568899154663086 	 G:  3.020597 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 12.275492 	D(real) 0.37761789560317993 	D(fake) 1.1568185091018677 	 G:  3.0208573 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 12.275244 	D(real) 0.3776456117630005 	D(fake) 1.1567598581314087 	 G:  3.021072 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 12.274827 	D(real) 0.37767305970191956 	D(fake) 1.1566803455352783 	 G:  3.0213633 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 12.274691 	D(real) 0.37770023941993713 	D(fake) 1.156636118888855 	 G:  3.021525 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 12.274515 	D(real) 0.37772732973098755 	D(fake) 1.1565871238708496 	 G:  3.0217044 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 12.274134 	D(real) 0.37775418162345886 	D(fake) 1.1565124988555908 	 G:  3.021978 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 12.273849 	D(real) 0.377780944108963 	D(fake) 1.1564501523971558 	 G:  3.022207 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 12.2736025 	D(real) 0.3778076469898224 	D(fake) 1.1563926935195923 	 G:  3.0224178 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 12.273362 	D(real) 0.3778342306613922 	D(fake) 1.1563360691070557 	 G:  3.0226254 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 12.273287 	D(real) 0.37786078453063965 	D(fake) 1.1563000679016113 	 G:  3.0226014 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 12.27313 	D(real) 0.37786349654197693 	D(fake) 1.1562777757644653 	 G:  3.0226827 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 12.273161 	D(real) 0.37786608934402466 	D(fake) 1.1562790870666504 	 G:  3.0226784 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 12.273113 	D(real) 0.37786874175071716 	D(fake) 1.1562703847885132 	 G:  3.022711 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 12.273133 	D(real) 0.3778713643550873 	D(fake) 1.1562702655792236 	 G:  3.0227113 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 12.273153 	D(real) 0.3778740465641022 	D(fake) 1.156270146369934 	 G:  3.0227115 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 12.273043 	D(real) 0.3778766691684723 	D(fake) 1.156253695487976 	 G:  3.0227723 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 12.272985 	D(real) 0.3778792917728424 	D(fake) 1.156243920326233 	 G:  3.0228071 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 12.272896 	D(real) 0.3778819441795349 	D(fake) 1.156230092048645 	 G:  3.0228581 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 12.272941 	D(real) 0.3778845965862274 	D(fake) 1.1562329530715942 	 G:  3.022848 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 5}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 5
\seed data:	 5
\seed noise:	 5
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.016988 	loss:  -3.5984716 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.016856 	loss:  3.601366 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.016877 	loss:  8.401137 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017110 	loss:  11.600746 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.016392 	loss:  11.600725 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.016514 	loss:  11.605664 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.016582 	loss:  11.601236 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.016679 	loss:  5.2012854 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.016619 	loss:  2.0013032 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.016628 	loss:  -5.1986685 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.016380 	loss:  -3.5986598 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.016785 	loss:  3.0941503 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.016437 	loss:  2.0013208 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.016645 	loss:  3.3084795 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.016777 	loss:  2.6940978 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.016491 	loss:  3.7084296 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.016486 	loss:  3.7084267 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017248 	loss:  4.0012436 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.016432 	loss:  5.386879 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.016404 	loss:  6.0012336 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.016838 	loss:  5.6012306 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.016446 	loss:  6.1868663 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.016352 	loss:  6.186863 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.016273 	loss:  6.001218 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.016979 	loss:  6.8012123 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.016646 	loss:  6.801208 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.016748 	loss:  6.8012037 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.016444 	loss:  6.58684 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.016688 	loss:  6.2940164 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.016355 	loss:  6.6940117 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.016687 	loss:  7.0940065 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.016477 	loss:  7.201186 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.016368 	loss:  7.0940056 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.016578 	loss:  6.801185 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.016467 	loss:  6.8011847 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.016384 	loss:  6.6940055 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.016668 	loss:  6.6940045 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.016329 	loss:  6.2940054 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.016235 	loss:  7.201183 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.016355 	loss:  7.0940027 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.016776 	loss:  6.8011823 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.016787 	loss:  6.801182 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.016611 	loss:  6.694002 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.016667 	loss:  7.201181 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.016253 	loss:  6.694001 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.016335 	loss:  7.20118 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017242 	loss:  6.6940007 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.016282 	loss:  7.2011795 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.016364 	loss:  7.2011795 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.016890 	loss:  7.0939994 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.463582
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_5/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 5.0367403 	D(real) 0.7585086822509766 	D(fake) 0.9204048315684 	 G:  2.8201787 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 4.8477726 	D(real) 0.9755450884501139 	D(fake) 0.6403791109720866 	 G:  2.007196 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 4.591302 	D(real) 0.6712459723154703 	D(fake) 0.8591880003611246 	 G:  1.6154667 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 4.490319 	D(real) 0.5384695927302042 	D(fake) 0.9583033720652262 	 G:  1.4482975 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 4.5649667 	D(real) 0.48283390204111737 	D(fake) 1.0388216972351074 	 G:  1.2914201 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 4.648978 	D(real) 0.43060914675394696 	D(fake) 1.1190502643585205 	 G:  1.1934325 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 4.691326 	D(real) 0.3979836304982503 	D(fake) 1.1657917499542236 	 G:  1.1533307 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 4.6877637 	D(real) 0.3846283753712972 	D(fake) 1.1779595216115315 	 G:  1.1532953 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 4.650169 	D(real) 0.3845870892206828 	D(fake) 1.1654691696166992 	 G:  1.1777071 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 4.6014547 	D(real) 0.3926991621653239 	D(fake) 1.1411190032958984 	 G:  1.2105001 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 4.5228043 	D(real) 0.40357247988382977 	D(fake) 1.104028860727946 	 G:  1.2134843 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 4.5200996 	D(real) 0.4045711358388265 	D(fake) 1.1021288235982258 	 G:  1.2159643 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 4.517916 	D(real) 0.40539562702178955 	D(fake) 1.100576400756836 	 G:  1.2179838 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 4.5163193 	D(real) 0.40606363614400226 	D(fake) 1.0993762016296387 	 G:  1.2195243 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 4.5149994 	D(real) 0.4065919319788615 	D(fake) 1.0984079043070476 	 G:  1.2207555 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 4.5140743 	D(real) 0.4069964090983073 	D(fake) 1.097695032755534 	 G:  1.221637 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 4.513385 	D(real) 0.4072919686635335 	D(fake) 1.097169558207194 	 G:  1.2222661 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 4.5129366 	D(real) 0.4074929555257161 	D(fake) 1.096819241841634 	 G:  1.2226572 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 4.512793 	D(real) 0.4076126416524251 	D(fake) 1.0966517130533855 	 G:  1.2227968 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 4.5128183 	D(real) 0.4076637427012126 	D(fake) 1.0966090361277263 	 G:  1.2227702 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 4.506715 	D(real) 0.40765833854675293 	D(fake) 1.0945800145467122 	 G:  1.2227914 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 4.5068192 	D(real) 0.40765313307444256 	D(fake) 1.094619909922282 	 G:  1.2227254 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 4.506861 	D(real) 0.40764375527699787 	D(fake) 1.094643274943034 	 G:  1.2226852 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 4.5069695 	D(real) 0.40763107935587567 	D(fake) 1.09469207127889 	 G:  1.2226082 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 4.506963 	D(real) 0.40761574109395343 	D(fake) 1.0947052637736003 	 G:  1.2225857 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 4.5070353 	D(real) 0.40759825706481934 	D(fake) 1.0947469075520833 	 G:  1.2225208 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 4.5070524 	D(real) 0.40757910410563153 	D(fake) 1.0947717030843098 	 G:  1.222482 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 4.5071607 	D(real) 0.4075586398442586 	D(fake) 1.0948282877604167 	 G:  1.2223955 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 4.5071926 	D(real) 0.4075371026992798 	D(fake) 1.0948603947957356 	 G:  1.2223462 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 4.5072193 	D(real) 0.4075147310892741 	D(fake) 1.0948917071024578 	 G:  1.2222989 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 4.506619 	D(real) 0.4074917634328206 	D(fake) 1.0947145620981853 	 G:  1.2222899 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 4.5066566 	D(real) 0.4074893792470296 	D(fake) 1.0947295824686687 	 G:  1.222267 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 4.5067134 	D(real) 0.40748703479766846 	D(fake) 1.0947507222493489 	 G:  1.2222352 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 4.506726 	D(real) 0.40748465061187744 	D(fake) 1.094757318496704 	 G:  1.2222252 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 4.50665 	D(real) 0.4074821472167969 	D(fake) 1.0947344303131104 	 G:  1.2222598 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 4.506735 	D(real) 0.4074796835581462 	D(fake) 1.094765345255534 	 G:  1.222213 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 4.506717 	D(real) 0.4074772198994954 	D(fake) 1.094761848449707 	 G:  1.2222186 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 4.5066786 	D(real) 0.40747467676798504 	D(fake) 1.094751516977946 	 G:  1.2222341 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 4.5067377 	D(real) 0.4074721336364746 	D(fake) 1.094773769378662 	 G:  1.2222004 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 4.5067606 	D(real) 0.4074696699778239 	D(fake) 1.0947839419047039 	 G:  1.2221851 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 4.5066347 	D(real) 0.4074671268463135 	D(fake) 1.094744364420573 	 G:  1.2222171 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 4.5066586 	D(real) 0.4074668486913045 	D(fake) 1.0947526295979817 	 G:  1.2222047 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 4.506719 	D(real) 0.4074666102727254 	D(fake) 1.0947731335957844 	 G:  1.2221736 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 4.506646 	D(real) 0.4074662923812866 	D(fake) 1.094749132792155 	 G:  1.2222102 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 4.506769 	D(real) 0.4074660936991374 	D(fake) 1.0947902997334797 	 G:  1.222148 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 4.506689 	D(real) 0.40746577580769855 	D(fake) 1.094763994216919 	 G:  1.2221876 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 4.5066733 	D(real) 0.4074656168619792 	D(fake) 1.0947588284810383 	 G:  1.2221956 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 4.5066876 	D(real) 0.40746525923411053 	D(fake) 1.0947639147440593 	 G:  1.2221878 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 4.5066643 	D(real) 0.40746502081553143 	D(fake) 1.0947564442952473 	 G:  1.222199 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 4.5067263 	D(real) 0.40746474266052246 	D(fake) 1.094777266184489 	 G:  1.2221676 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 6}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 6
\seed data:	 6
\seed noise:	 6
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.017484 	loss:  0.73369503 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017049 	loss:  1.5594918 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.016821 	loss:  7.6393085 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017080 	loss:  6.9992676 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017567 	loss:  4.6662517 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017104 	loss:  4.6662326 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017023 	loss:  4.6662517 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.016719 	loss:  4.666234 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.016790 	loss:  3.6542528 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017405 	loss:  -1.3056488 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017041 	loss:  -3.5456603 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.016851 	loss:  -4.3456674 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.016779 	loss:  -2.4256704 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.016835 	loss:  0.7743253 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017361 	loss:  0.77432597 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017433 	loss:  0.77432483 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.016573 	loss:  0.77432406 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017633 	loss:  0.7743225 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.016580 	loss:  0.7743206 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.016611 	loss:  0.7743184 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.016692 	loss:  0.77431643 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017515 	loss:  0.7743147 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.016735 	loss:  0.7743133 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.016626 	loss:  0.77431244 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.016794 	loss:  0.6813298 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017008 	loss:  0.26834738 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.016902 	loss:  -0.34568834 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.016878 	loss:  0.29431087 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017565 	loss:  0.45431 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.016916 	loss:  0.681327 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.016924 	loss:  0.77430844 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017191 	loss:  0.7743083 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.016838 	loss:  0.61430836 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.016677 	loss:  0.7743082 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.016847 	loss:  0.7743081 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.016802 	loss:  0.77430797 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.016902 	loss:  0.73325455 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017200 	loss:  0.7743077 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.016619 	loss:  0.6143078 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017225 	loss:  0.6143078 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017433 	loss:  0.7332541 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.016959 	loss:  0.7743074 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.016867 	loss:  0.77430737 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017164 	loss:  0.6143074 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.016827 	loss:  0.7743072 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.016775 	loss:  0.6143072 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.016613 	loss:  0.77430713 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.016586 	loss:  0.7332537 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.016625 	loss:  0.6143073 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.016926 	loss:  0.6143072 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.097726
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_6/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 7.302875 	D(real) 0.7045825719833374 	D(fake) 1.12113618850708 	 G:  3.1517525 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 6.5985966 	D(real) 0.7873269319534302 	D(fake) 0.862322211265564 	 G:  1.9151217 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 6.3444896 	D(real) 0.4789220094680786 	D(fake) 1.1072003841400146 	 G:  1.6514957 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 6.1834564 	D(real) 0.41287916898727417 	D(fake) 1.1329848766326904 	 G:  1.7297611 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 6.1241446 	D(real) 0.4324163794517517 	D(fake) 1.0986196994781494 	 G:  1.7555794 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 6.19531 	D(real) 0.43887314200401306 	D(fake) 1.1099543571472168 	 G:  1.6353666 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 6.251131 	D(real) 0.40883296728134155 	D(fake) 1.1539497375488281 	 G:  1.5454099 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 6.215435 	D(real) 0.3863508105278015 	D(fake) 1.1675078868865967 	 G:  1.553504 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 6.140031 	D(real) 0.3883703351020813 	D(fake) 1.1466373205184937 	 G:  1.6059023 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 6.066588 	D(real) 0.4014696180820465 	D(fake) 1.1151773929595947 	 G:  1.6672049 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 5.976637 	D(real) 0.4167962074279785 	D(fake) 1.0773630142211914 	 G:  1.6716353 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 5.974376 	D(real) 0.4179037809371948 	D(fake) 1.0756902694702148 	 G:  1.6739368 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 5.973768 	D(real) 0.4184799790382385 	D(fake) 1.0749620199203491 	 G:  1.6745336 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 5.9743376 	D(real) 0.4186345934867859 	D(fake) 1.074949860572815 	 G:  1.6738465 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 5.9758964 	D(real) 0.4184585511684418 	D(fake) 1.0755155086517334 	 G:  1.6721268 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 5.9781866 	D(real) 0.4180280566215515 	D(fake) 1.0765186548233032 	 G:  1.6696401 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 5.981002 	D(real) 0.41740745306015015 	D(fake) 1.0778430700302124 	 G:  1.6666083 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 5.984153 	D(real) 0.41665053367614746 	D(fake) 1.0793876647949219 	 G:  1.6632234 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 5.987532 	D(real) 0.4158026874065399 	D(fake) 1.0810803174972534 	 G:  1.6596204 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 5.991021 	D(real) 0.4149014949798584 	D(fake) 1.0828537940979004 	 G:  1.6559248 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 5.9842486 	D(real) 0.41397783160209656 	D(fake) 1.08208429813385 	 G:  1.6555451 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 5.984593 	D(real) 0.41388508677482605 	D(fake) 1.0822631120681763 	 G:  1.6551766 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 5.9849386 	D(real) 0.41379210352897644 	D(fake) 1.0824425220489502 	 G:  1.6548076 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 5.985282 	D(real) 0.413699209690094 	D(fake) 1.0826213359832764 	 G:  1.6544406 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 5.9856358 	D(real) 0.41360658407211304 	D(fake) 1.0828022956848145 	 G:  1.6540699 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 5.9859858 	D(real) 0.4135143756866455 	D(fake) 1.082982063293457 	 G:  1.653702 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 5.9863296 	D(real) 0.41342273354530334 	D(fake) 1.0831596851348877 	 G:  1.653339 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 5.9866714 	D(real) 0.4133317172527313 	D(fake) 1.0833361148834229 	 G:  1.6529789 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 5.9870253 	D(real) 0.4132414162158966 	D(fake) 1.083514928817749 	 G:  1.6526139 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 5.9873586 	D(real) 0.4131518602371216 	D(fake) 1.0836877822875977 	 G:  1.6522619 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 5.98669 	D(real) 0.4130631685256958 	D(fake) 1.0836093425750732 	 G:  1.6522288 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 5.9867196 	D(real) 0.41305434703826904 	D(fake) 1.0836255550384521 	 G:  1.6521956 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 5.986763 	D(real) 0.41304558515548706 	D(fake) 1.0836451053619385 	 G:  1.6521559 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 5.9867916 	D(real) 0.41303694248199463 	D(fake) 1.0836609601974487 	 G:  1.6521239 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 5.986828 	D(real) 0.4130283296108246 	D(fake) 1.0836786031723022 	 G:  1.6520877 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 5.9868584 	D(real) 0.41301971673965454 	D(fake) 1.0836948156356812 	 G:  1.6520543 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 5.9868946 	D(real) 0.4130111336708069 	D(fake) 1.0837125778198242 	 G:  1.6520182 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 5.9869328 	D(real) 0.4130026698112488 	D(fake) 1.0837304592132568 	 G:  1.6519818 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 5.98695 	D(real) 0.4129942059516907 	D(fake) 1.0837432146072388 	 G:  1.651956 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 5.9869905 	D(real) 0.4129856824874878 	D(fake) 1.0837619304656982 	 G:  1.6519172 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 5.986912 	D(real) 0.4129771590232849 	D(fake) 1.0837507247924805 	 G:  1.6519206 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 5.9869285 	D(real) 0.41297635436058044 	D(fake) 1.0837557315826416 	 G:  1.65191 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 5.9869204 	D(real) 0.4129754900932312 	D(fake) 1.083754539489746 	 G:  1.6519129 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 5.9869366 	D(real) 0.41297465562820435 	D(fake) 1.0837595462799072 	 G:  1.6519024 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 5.9869366 	D(real) 0.4129738211631775 	D(fake) 1.0837602615356445 	 G:  1.651901 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 5.986927 	D(real) 0.41297295689582825 	D(fake) 1.08375883102417 	 G:  1.6519039 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 5.9869356 	D(real) 0.4129721522331238 	D(fake) 1.0837616920471191 	 G:  1.651898 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 5.9869375 	D(real) 0.41297125816345215 	D(fake) 1.0837631225585938 	 G:  1.6518952 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 5.9869423 	D(real) 0.4129704236984253 	D(fake) 1.0837651491165161 	 G:  1.6518908 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 5.9869547 	D(real) 0.41296958923339844 	D(fake) 1.0837690830230713 	 G:  1.6518829 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 7}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 7
\seed data:	 7
\seed noise:	 7
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.017805 	loss:  -2.3988144 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017406 	loss:  8.001026 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017493 	loss:  8.560854 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017591 	loss:  10.960728 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017360 	loss:  10.960514 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017193 	loss:  10.9606495 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017222 	loss:  10.962411 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017051 	loss:  10.960772 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017223 	loss:  8.960887 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017202 	loss:  -0.8790541 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017042 	loss:  -2.1590495 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017028 	loss:  -2.987649 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.016973 	loss:  -2.1814568 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017220 	loss:  -0.4298118 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017354 	loss:  -2.1041353 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017114 	loss:  -2.2787051 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017217 	loss:  -1.3709068 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017475 	loss:  -1.428831 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017169 	loss:  -2.2553244 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017314 	loss:  -2.3239102 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017685 	loss:  -2.6477845 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.016924 	loss:  -2.317155 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017148 	loss:  -3.384356 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017009 	loss:  -3.0065126 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017145 	loss:  -3.0236676 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017287 	loss:  -3.4537916 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017161 	loss:  -2.8792462 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017677 	loss:  -3.1426353 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017121 	loss:  -3.5389938 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017185 	loss:  -3.0330174 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017677 	loss:  -2.5925062 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017767 	loss:  -3.0803778 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017221 	loss:  -3.4350977 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017544 	loss:  -3.0610898 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017004 	loss:  -3.7410758 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017215 	loss:  -3.4008198 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017660 	loss:  -3.5909407 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017350 	loss:  -3.492763 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017295 	loss:  -3.3973472 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.016892 	loss:  -3.0454895 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017080 	loss:  -2.6184585 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017087 	loss:  -4.1073484 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017438 	loss:  -2.7457469 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017315 	loss:  -3.0662732 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017267 	loss:  -3.1789992 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017032 	loss:  -2.9431555 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017683 	loss:  -3.152508 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017348 	loss:  -3.4210775 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017012 	loss:  -3.4683511 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.016984 	loss:  -3.2693903 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.292925
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_7/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 7.600794 	D(real) 0.7434584140777588 	D(fake) 0.7767003059387207 	 G:  3.5871968 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 7.87293 	D(real) 0.7164361000061035 	D(fake) 0.8581499099731446 	 G:  2.6085634 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 7.6629496 	D(real) 0.5216808319091797 	D(fake) 1.010909080505371 	 G:  2.1590655 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 7.8546634 	D(real) 0.43181257247924804 	D(fake) 1.139120101928711 	 G:  1.9135277 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 7.986775 	D(real) 0.38271417617797854 	D(fake) 1.2146408081054687 	 G:  1.7969074 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 8.0132885 	D(real) 0.3593867778778076 	D(fake) 1.2432708740234375 	 G:  1.7621958 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 7.9304147 	D(real) 0.3524414777755737 	D(fake) 1.2336414337158204 	 G:  1.8073936 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 7.7864513 	D(real) 0.3614795207977295 	D(fake) 1.1958107948303223 	 G:  1.9057399 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 7.6385617 	D(real) 0.381148362159729 	D(fake) 1.14656400680542 	 G:  2.0214245 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 7.523885 	D(real) 0.4042850971221924 	D(fake) 1.1004919052124023 	 G:  2.1229985 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 7.432845 	D(real) 0.42459979057312014 	D(fake) 1.0619691848754882 	 G:  2.1294522 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 7.430417 	D(real) 0.4258904933929443 	D(fake) 1.06019287109375 	 G:  2.132287 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 7.430523 	D(real) 0.42645750045776365 	D(fake) 1.0596470832824707 	 G:  2.1322641 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 7.432582 	D(real) 0.4264528751373291 	D(fake) 1.0600634574890138 	 G:  2.1300154 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 7.436132 	D(real) 0.42600317001342775 	D(fake) 1.0612232208251953 	 G:  2.1260712 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 7.440793 	D(real) 0.4252142429351807 	D(fake) 1.0629443168640136 	 G:  2.1208763 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 7.446251 	D(real) 0.42417540550231936 	D(fake) 1.0650747299194336 	 G:  2.1148045 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 7.452244 	D(real) 0.4229609489440918 	D(fake) 1.0674878120422364 	 G:  2.1081665 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 7.4585567 	D(real) 0.42163333892822263 	D(fake) 1.0700779914855958 	 G:  2.101217 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 7.4650064 	D(real) 0.4202434539794922 	D(fake) 1.0727578163146974 	 G:  2.0941641 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 7.457699 	D(real) 0.41883292198181155 	D(fake) 1.0727067947387696 	 G:  2.0934641 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 7.458337 	D(real) 0.41869292259216306 	D(fake) 1.072974395751953 	 G:  2.0927703 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 7.458969 	D(real) 0.41855416297912595 	D(fake) 1.0732396125793457 	 G:  2.092084 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 7.4595966 	D(real) 0.4184168815612793 	D(fake) 1.0735024452209472 	 G:  2.0914035 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 7.4602184 	D(real) 0.4182807445526123 	D(fake) 1.0737628936767578 	 G:  2.0907304 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 7.4608335 	D(real) 0.41814608573913575 	D(fake) 1.0740206718444825 	 G:  2.0900645 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 7.461445 	D(real) 0.4180129051208496 	D(fake) 1.074276065826416 	 G:  2.0894048 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 7.4620495 	D(real) 0.4178809642791748 	D(fake) 1.0745288848876953 	 G:  2.0887523 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 7.4626493 	D(real) 0.41775054931640626 	D(fake) 1.0747793197631836 	 G:  2.088106 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 7.463243 	D(real) 0.4176213264465332 	D(fake) 1.0750272750854493 	 G:  2.0874667 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 7.4625196 	D(real) 0.41749348640441897 	D(fake) 1.0750104904174804 	 G:  2.0874038 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 7.4625773 	D(real) 0.4174807548522949 	D(fake) 1.0750347137451173 	 G:  2.0873408 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 7.462636 	D(real) 0.4174682140350342 	D(fake) 1.075058937072754 	 G:  2.0872784 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 7.4626927 	D(real) 0.41745576858520506 	D(fake) 1.075082778930664 	 G:  2.0872169 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 7.46275 	D(real) 0.4174433708190918 	D(fake) 1.0751066207885742 	 G:  2.0871549 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 7.4628077 	D(real) 0.4174311637878418 	D(fake) 1.0751303672790526 	 G:  2.0870936 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 7.462865 	D(real) 0.4174188613891602 	D(fake) 1.0751541137695313 	 G:  2.0870326 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 7.462921 	D(real) 0.41740665435791013 	D(fake) 1.0751775741577148 	 G:  2.0869718 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 7.462978 	D(real) 0.4173943519592285 	D(fake) 1.0752012252807617 	 G:  2.0869112 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 7.463034 	D(real) 0.4173823356628418 	D(fake) 1.0752244949340821 	 G:  2.0868502 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 7.462961 	D(real) 0.41737022399902346 	D(fake) 1.0752220153808594 	 G:  2.0868442 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 7.462967 	D(real) 0.4173689365386963 	D(fake) 1.0752244949340821 	 G:  2.0868382 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 7.4629726 	D(real) 0.41736769676208496 	D(fake) 1.0752267837524414 	 G:  2.086832 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 7.4629784 	D(real) 0.41736655235290526 	D(fake) 1.0752291679382324 	 G:  2.0868263 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 7.462984 	D(real) 0.41736531257629395 	D(fake) 1.0752314567565917 	 G:  2.0868201 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 7.462989 	D(real) 0.4173640251159668 	D(fake) 1.0752337455749512 	 G:  2.086814 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 7.4629946 	D(real) 0.41736292839050293 	D(fake) 1.075235939025879 	 G:  2.086808 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 7.4630003 	D(real) 0.4173616886138916 	D(fake) 1.0752384185791015 	 G:  2.086802 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 7.463006 	D(real) 0.41736040115356443 	D(fake) 1.0752408027648925 	 G:  2.0867963 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 7.4630113 	D(real) 0.4173592567443848 	D(fake) 1.0752429962158203 	 G:  2.0867903 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 8}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 8
\seed data:	 8
\seed noise:	 8
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.017854 	loss:  -1.1874585 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018072 	loss:  2.0581005 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017255 	loss:  9.417921 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017507 	loss:  10.926537 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017628 	loss:  10.835021 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017516 	loss:  9.326424 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018074 	loss:  8.137816 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017733 	loss:  10.69776 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017501 	loss:  10.698029 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017647 	loss:  10.514983 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017691 	loss:  9.783612 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017298 	loss:  7.4979186 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017856 	loss:  5.836697 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017246 	loss:  4.4318976 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017374 	loss:  2.1530094 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017782 	loss:  0.49993798 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017361 	loss:  0.27503562 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018180 	loss:  0.30122787 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017603 	loss:  0.24066287 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.018008 	loss:  0.50360054 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017115 	loss:  0.6298972 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017139 	loss:  1.1314172 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017444 	loss:  1.3631783 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017527 	loss:  1.5626953 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017842 	loss:  1.7492208 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017391 	loss:  2.2709289 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018106 	loss:  2.384546 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017118 	loss:  2.4692988 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017464 	loss:  2.5126765 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017460 	loss:  2.6064396 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017448 	loss:  2.5428727 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017347 	loss:  2.3945522 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017100 	loss:  2.3536751 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017442 	loss:  2.5775747 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.016950 	loss:  2.486146 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017333 	loss:  2.4295876 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017518 	loss:  2.491485 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017285 	loss:  2.640641 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017261 	loss:  2.5375328 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017120 	loss:  2.3778663 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017251 	loss:  2.5882523 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017502 	loss:  2.366355 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017606 	loss:  2.6064377 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.016943 	loss:  2.5150092 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017493 	loss:  2.6521518 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.016950 	loss:  2.3778658 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018138 	loss:  2.3778658 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017546 	loss:  2.4968233 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017198 	loss:  2.6863546 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017301 	loss:  2.3925486 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.321503
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_8/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 11.098427 	D(real) 0.8933984438578287 	D(fake) 0.956339438756307 	 G:  4.6052046 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 9.383187 	D(real) 0.7692131201426188 	D(fake) 0.7946514288584391 	 G:  3.5413203 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 8.909803 	D(real) 0.5902744928995768 	D(fake) 0.8946928183237711 	 G:  3.158687 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 8.951125 	D(real) 0.5264519055684408 	D(fake) 0.9654022852579752 	 G:  2.8723242 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 9.107265 	D(real) 0.47872304916381836 	D(fake) 1.0391546090443928 	 G:  2.6043806 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 9.283292 	D(real) 0.4340640703837077 	D(fake) 1.11315123240153 	 G:  2.389984 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 9.406229 	D(real) 0.39833080768585205 	D(fake) 1.1693739891052246 	 G:  2.2637472 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 9.445264 	D(real) 0.3772912422815959 	D(fake) 1.1969194412231445 	 G:  2.223159 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 9.40176 	D(real) 0.3705265124638875 	D(fake) 1.196433464686076 	 G:  2.2503076 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 9.302861 	D(real) 0.37505125999450684 	D(fake) 1.17542560895284 	 G:  2.3220358 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 9.145994 	D(real) 0.3870059649149577 	D(fake) 1.1373263200124104 	 G:  2.330909 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 9.135185 	D(real) 0.3884848753611247 	D(fake) 1.1340460777282715 	 G:  2.3401835 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 9.124438 	D(real) 0.39003058274586994 	D(fake) 1.1307090918223064 	 G:  2.349586 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 9.113962 	D(real) 0.3915976683298747 	D(fake) 1.127396027247111 	 G:  2.3589003 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 9.103917 	D(real) 0.39315009117126465 	D(fake) 1.1241694291432698 	 G:  2.3679588 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 9.094423 	D(real) 0.3946598370869954 	D(fake) 1.1210773785909016 	 G:  2.3766325 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 9.08556 	D(real) 0.39610548814137775 	D(fake) 1.118154525756836 	 G:  2.3848238 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 9.077381 	D(real) 0.3974706331888835 	D(fake) 1.1154261430104573 	 G:  2.3924634 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 9.069914 	D(real) 0.3987439076105754 	D(fake) 1.1129084428151448 	 G:  2.3995056 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 9.063168 	D(real) 0.3999176025390625 	D(fake) 1.1106104056040447 	 G:  2.405924 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 9.052239 	D(real) 0.40098734696706134 	D(fake) 1.1077192624409993 	 G:  2.4065013 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 9.0517025 	D(real) 0.4010835488637288 	D(fake) 1.1075335343678792 	 G:  2.4070203 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 9.051216 	D(real) 0.4011700550715129 	D(fake) 1.1073660055796306 	 G:  2.4074926 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 9.050772 	D(real) 0.4012487729390462 	D(fake) 1.1072130997975667 	 G:  2.4079244 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 9.050359 	D(real) 0.40132073561350506 	D(fake) 1.1070724328358967 	 G:  2.4083247 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 9.049977 	D(real) 0.4013874928156535 	D(fake) 1.1069420178731282 	 G:  2.4086976 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 9.049618 	D(real) 0.40144960085550946 	D(fake) 1.1068199475606282 	 G:  2.4090474 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 9.049276 	D(real) 0.4015079339345296 	D(fake) 1.1067047119140625 	 G:  2.409379 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 9.048953 	D(real) 0.40156320730845135 	D(fake) 1.1065955956776936 	 G:  2.409694 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 9.048643 	D(real) 0.4016156593958537 	D(fake) 1.106491486231486 	 G:  2.4099953 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 9.047604 	D(real) 0.4016658862431844 	D(fake) 1.106268008550008 	 G:  2.4100246 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 9.047575 	D(real) 0.40167077382405597 	D(fake) 1.1062583128611247 	 G:  2.4100525 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 9.047546 	D(real) 0.40167542298634845 	D(fake) 1.1062490145365398 	 G:  2.4100797 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 9.047521 	D(real) 0.4016799529393514 	D(fake) 1.1062401135762532 	 G:  2.4101067 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 9.047493 	D(real) 0.4016844431559245 	D(fake) 1.1062311331431072 	 G:  2.4101326 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 9.047466 	D(real) 0.40168877442677814 	D(fake) 1.1062223116556804 	 G:  2.4101584 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 9.047442 	D(real) 0.40169306596120197 	D(fake) 1.1062139670054119 	 G:  2.4101834 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 9.047417 	D(real) 0.40169723828633624 	D(fake) 1.1062054634094238 	 G:  2.4102082 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 9.04739 	D(real) 0.4017013708750407 	D(fake) 1.1061969598134358 	 G:  2.4102333 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 9.047365 	D(real) 0.401705543200175 	D(fake) 1.106188694636027 	 G:  2.410257 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 9.047261 	D(real) 0.40170951684316 	D(fake) 1.1061673959096272 	 G:  2.41026 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 9.04726 	D(real) 0.4017099936803182 	D(fake) 1.10616668065389 	 G:  2.4102619 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 9.047257 	D(real) 0.401710311571757 	D(fake) 1.106165885925293 	 G:  2.4102647 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 9.047255 	D(real) 0.4017107884089152 	D(fake) 1.1061649322509766 	 G:  2.4102669 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 9.047252 	D(real) 0.4017111460367839 	D(fake) 1.1061641375223796 	 G:  2.4102693 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 9.047251 	D(real) 0.40171154340108234 	D(fake) 1.106163501739502 	 G:  2.4102716 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 9.047247 	D(real) 0.40171194076538086 	D(fake) 1.1061625480651855 	 G:  2.4102743 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 9.047244 	D(real) 0.4017123778661092 	D(fake) 1.1061616738637288 	 G:  2.4102762 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 9.047243 	D(real) 0.40171273549397785 	D(fake) 1.1061610380808513 	 G:  2.410279 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 9.047239 	D(real) 0.40171317259470624 	D(fake) 1.106160084406535 	 G:  2.4102814 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 9}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 9
\seed data:	 9
\seed noise:	 9
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.019528 	loss:  0.088635445 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018910 	loss:  7.8921194 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018935 	loss:  11.506475 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018956 	loss:  11.055476 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018908 	loss:  10.98988 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.018873 	loss:  10.989645 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018520 	loss:  11.055457 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.018628 	loss:  11.084581 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.019014 	loss:  9.855513 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018777 	loss:  9.920966 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.019472 	loss:  8.43732 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018876 	loss:  8.49353 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.019301 	loss:  8.611856 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018994 	loss:  10.080935 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018573 	loss:  10.25547 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018883 	loss:  10.037284 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018760 	loss:  9.986372 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.019099 	loss:  9.93029 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018637 	loss:  9.91364 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.018601 	loss:  9.913637 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.019112 	loss:  9.899088 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018639 	loss:  9.884539 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018779 	loss:  9.891808 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018800 	loss:  9.891802 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018687 	loss:  9.884522 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.019662 	loss:  9.89906 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018655 	loss:  9.899051 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018996 	loss:  9.8408575 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.019293 	loss:  9.549933 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018413 	loss:  8.648096 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018534 	loss:  8.473526 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018816 	loss:  8.473522 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018909 	loss:  8.471632 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.019359 	loss:  8.466242 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.019119 	loss:  8.466238 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018872 	loss:  8.466233 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018831 	loss:  8.466229 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018687 	loss:  8.466225 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018606 	loss:  8.46622 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.019557 	loss:  8.466214 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018736 	loss:  8.466208 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018447 	loss:  8.466203 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018877 	loss:  8.466197 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018687 	loss:  8.46619 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.019236 	loss:  8.466184 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018331 	loss:  8.466176 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018282 	loss:  8.466175 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018567 	loss:  8.466175 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018826 	loss:  8.466174 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.019031 	loss:  8.466173 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.318968
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_9/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 16.344889 	D(real) 0.6726225506175648 	D(fake) 0.8132764642888849 	 G:  7.748564 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 16.812948 	D(real) 0.7049447839910333 	D(fake) 0.8235050548206676 	 G:  5.849791 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 17.07779 	D(real) 0.5317466475746848 	D(fake) 1.0207796096801758 	 G:  4.615675 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 17.62293 	D(real) 0.41968033530495386 	D(fake) 1.182404258034446 	 G:  3.9509614 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 17.882305 	D(real) 0.35927763852206146 	D(fake) 1.2663864655928179 	 G:  3.821955 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 17.697605 	D(real) 0.3474524237892844 	D(fake) 1.2614207701249556 	 G:  3.981477 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 17.315296 	D(real) 0.3619605844671076 	D(fake) 1.2121571627530185 	 G:  4.209758 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 17.2048 	D(real) 0.3827071189880371 	D(fake) 1.1813656200062146 	 G:  4.3823028 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 16.700592 	D(real) 0.3983922438188033 	D(fake) 1.1198433962735264 	 G:  4.642407 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 16.46337 	D(real) 0.42212386564774945 	D(fake) 1.0745461203835227 	 G:  4.8112307 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 16.24392 	D(real) 0.43738859350031073 	D(fake) 1.0393313494595615 	 G:  4.8160367 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 16.250708 	D(real) 0.43782420591874555 	D(fake) 1.039512807672674 	 G:  4.8096232 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 16.26178 	D(real) 0.4372937029058283 	D(fake) 1.0410499572753906 	 G:  4.7963247 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 16.278841 	D(real) 0.43603008443659 	D(fake) 1.0438645102761008 	 G:  4.776507 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 16.29977 	D(real) 0.4342282468622381 	D(fake) 1.0475691015070134 	 G:  4.7523837 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 16.322308 	D(real) 0.43205326253717596 	D(fake) 1.0517929250543767 	 G:  4.7260566 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 16.346672 	D(real) 0.4296417669816451 	D(fake) 1.0564193725585938 	 G:  4.6981463 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 16.371946 	D(real) 0.4271062070673162 	D(fake) 1.0612525939941406 	 G:  4.669721 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 16.396477 	D(real) 0.4245380921797319 	D(fake) 1.0660506161776455 	 G:  4.6420884 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 16.420755 	D(real) 0.42200916463678534 	D(fake) 1.0707867362282493 	 G:  4.6153135 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 16.40085 	D(real) 0.41957517103715375 	D(fake) 1.071411219510165 	 G:  4.6127853 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 16.40309 	D(real) 0.4193442084572532 	D(fake) 1.0718457482077859 	 G:  4.610351 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 16.406239 	D(real) 0.41912416978315875 	D(fake) 1.0723520625721326 	 G:  4.607503 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 16.407242 	D(real) 0.4189137112010609 	D(fake) 1.0726537704467773 	 G:  4.605818 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 16.409273 	D(real) 0.4187111421064897 	D(fake) 1.0730409622192383 	 G:  4.6036396 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 16.411224 	D(real) 0.4185156388716264 	D(fake) 1.0734139355746182 	 G:  4.60154 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 16.413088 	D(real) 0.41832633451981976 	D(fake) 1.073772517117587 	 G:  4.5995197 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 16.414898 	D(real) 0.4181421453302557 	D(fake) 1.0741213885220615 	 G:  4.597555 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 16.416946 	D(real) 0.417962984605269 	D(fake) 1.074486645785245 	 G:  4.595494 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 16.418358 	D(real) 0.41778798536820844 	D(fake) 1.0747900876131924 	 G:  4.5937834 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 16.41641 	D(real) 0.4176168008284135 	D(fake) 1.0747841054742986 	 G:  4.593579 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 16.41658 	D(real) 0.4175999814813787 	D(fake) 1.0748163570057263 	 G:  4.593398 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 16.416964 	D(real) 0.4175834655761719 	D(fake) 1.074867768721147 	 G:  4.593106 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 16.417412 	D(real) 0.41756725311279297 	D(fake) 1.074924815784801 	 G:  4.592781 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 16.41704 	D(real) 0.41755108399824664 	D(fake) 1.074907129461115 	 G:  4.5928826 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 16.417995 	D(real) 0.4175352616743608 	D(fake) 1.0750097794966265 	 G:  4.5923004 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 16.417622 	D(real) 0.41751961274580524 	D(fake) 1.0749914862892844 	 G:  4.592404 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 16.417559 	D(real) 0.41750383377075195 	D(fake) 1.0750015432184392 	 G:  4.592347 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 16.417677 	D(real) 0.4174882715398615 	D(fake) 1.075027812610973 	 G:  4.592199 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 16.41789 	D(real) 0.41747279600663617 	D(fake) 1.0750627517700195 	 G:  4.591999 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 16.417633 	D(real) 0.4174573204734109 	D(fake) 1.0750547755848279 	 G:  4.592011 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 16.417728 	D(real) 0.417455716566606 	D(fake) 1.075065092606978 	 G:  4.5919523 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 16.417768 	D(real) 0.41745424270629883 	D(fake) 1.0750701210715554 	 G:  4.5919256 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 16.41768 	D(real) 0.41745276884599164 	D(fake) 1.075063618746671 	 G:  4.5919623 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 16.41771 	D(real) 0.41745133833451703 	D(fake) 1.0750676068392666 	 G:  4.591939 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 16.417713 	D(real) 0.41744964773004706 	D(fake) 1.0750697742808948 	 G:  4.5919266 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 16.417744 	D(real) 0.41744821721857245 	D(fake) 1.075073849071156 	 G:  4.5919037 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 16.41779 	D(real) 0.41744665666060016 	D(fake) 1.0750795711170544 	 G:  4.5918713 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 16.417788 	D(real) 0.4174451394514604 	D(fake) 1.0750809582796963 	 G:  4.5918636 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 16.417862 	D(real) 0.4174437089399858 	D(fake) 1.0750892812555486 	 G:  4.5918155 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 10}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 10
\seed data:	 10
\seed noise:	 10
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.019084 	loss:  1.7082734 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018539 	loss:  -4.0385504 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018552 	loss:  7.206413 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018549 	loss:  11.667812 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018402 	loss:  11.667716 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.018847 	loss:  11.6673565 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018778 	loss:  11.667475 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.018354 	loss:  11.679239 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018445 	loss:  11.668083 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018888 	loss:  10.758056 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018553 	loss:  3.5018084 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018513 	loss:  6.2136235 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.018554 	loss:  3.4238043 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018471 	loss:  1.8180456 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018507 	loss:  -1.619365 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018606 	loss:  -0.26048884 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.019183 	loss:  0.34221447 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018497 	loss:  0.87317413 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018515 	loss:  1.3305395 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.018241 	loss:  1.6135906 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018779 	loss:  1.9407233 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018400 	loss:  2.1647174 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018477 	loss:  2.3883643 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018338 	loss:  2.4856424 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018920 	loss:  2.942479 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018310 	loss:  3.8636613 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018368 	loss:  3.9691079 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018723 	loss:  4.2321615 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.018781 	loss:  4.3183055 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018502 	loss:  4.3477063 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018773 	loss:  4.683941 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018744 	loss:  4.693016 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018232 	loss:  4.597636 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018714 	loss:  4.6245265 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018541 	loss:  4.559466 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018994 	loss:  4.6992307 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018429 	loss:  4.602316 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018319 	loss:  4.7942796 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018218 	loss:  4.708045 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018433 	loss:  4.8364615 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018488 	loss:  4.8940253 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018201 	loss:  4.9480987 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018287 	loss:  4.8908687 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018072 	loss:  5.008493 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018137 	loss:  4.9948773 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018860 	loss:  4.8198485 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018426 	loss:  5.054693 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018804 	loss:  5.0613875 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018600 	loss:  5.0609403 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.018905 	loss:  5.07307 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.976368
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_10/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 14.894231 	D(real) 0.7645541297064887 	D(fake) 0.8903604083591037 	 G:  5.221098 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 14.416433 	D(real) 0.5856968031989204 	D(fake) 1.0161290698581271 	 G:  4.021917 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 14.093553 	D(real) 0.44675763448079425 	D(fake) 1.1191926532321506 	 G:  3.5919755 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 14.269814 	D(real) 0.39911958906385636 	D(fake) 1.1864152484469943 	 G:  3.3297968 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 14.299563 	D(real) 0.3699160681830512 	D(fake) 1.2189243104722765 	 G:  3.256168 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 14.190308 	D(real) 0.3617727491590712 	D(fake) 1.2149280971950955 	 G:  3.3091612 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 14.0026 	D(real) 0.36768807305230033 	D(fake) 1.1881563398573134 	 G:  3.431463 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 13.801727 	D(real) 0.3812863826751709 	D(fake) 1.1522388458251953 	 G:  3.577698 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 13.632545 	D(real) 0.39753397305806476 	D(fake) 1.1171933280097113 	 G:  3.7134855 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 13.513912 	D(real) 0.4126204914516873 	D(fake) 1.088925255669488 	 G:  3.818171 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 13.384091 	D(real) 0.42425137095981175 	D(fake) 1.0628699196709528 	 G:  3.8243713 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 13.382509 	D(real) 0.42494135432773167 	D(fake) 1.0620040893554688 	 G:  3.8262808 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 13.383951 	D(real) 0.4251529905531142 	D(fake) 1.0619526969061956 	 G:  3.8247907 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 13.387727 	D(real) 0.42498792542351616 	D(fake) 1.0625372992621527 	 G:  3.8206654 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 13.393279 	D(real) 0.424530029296875 	D(fake) 1.0636120902167425 	 G:  3.814536 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 13.400178 	D(real) 0.4238486819797092 	D(fake) 1.065059979756673 	 G:  3.8069131 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 13.408047 	D(real) 0.42300181918674046 	D(fake) 1.0667811499701605 	 G:  3.7982342 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 13.416584 	D(real) 0.4220375484890408 	D(fake) 1.0686940087212458 	 G:  3.788855 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 13.425526 	D(real) 0.42099523544311523 	D(fake) 1.0707297854953342 	 G:  3.779074 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 13.4346895 	D(real) 0.4199080997043186 	D(fake) 1.0728351804945204 	 G:  3.7691178 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 13.423788 	D(real) 0.41880271169874406 	D(fake) 1.0727293226453993 	 G:  3.7681234 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 13.4247055 	D(real) 0.418691979514228 	D(fake) 1.072941992017958 	 G:  3.767128 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 13.425611 	D(real) 0.4185815387301975 	D(fake) 1.0731529659695096 	 G:  3.7661405 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 13.426519 	D(real) 0.41847138934665257 	D(fake) 1.073364045884874 	 G:  3.765155 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 13.427439 	D(real) 0.41836171680026585 	D(fake) 1.0735759735107422 	 G:  3.7641659 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 13.428319 	D(real) 0.41825254758199054 	D(fake) 1.0737829208374023 	 G:  3.763201 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 13.429243 	D(real) 0.4181440406375461 	D(fake) 1.07399410671658 	 G:  3.7622168 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 13.430125 	D(real) 0.41803622245788574 	D(fake) 1.0741998884412978 	 G:  3.761258 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 13.431 	D(real) 0.41792911953396267 	D(fake) 1.0744041866726346 	 G:  3.7603073 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 13.431889 	D(real) 0.41782281133863663 	D(fake) 1.074609226650662 	 G:  3.7593536 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 13.430807 	D(real) 0.41771719190809464 	D(fake) 1.07459470960829 	 G:  3.7592614 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 13.430902 	D(real) 0.4177067279815674 	D(fake) 1.074615690443251 	 G:  3.759164 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 13.430984 	D(real) 0.4176962905459934 	D(fake) 1.0746351877848308 	 G:  3.7590737 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 13.431061 	D(real) 0.4176859325832791 	D(fake) 1.0746541553073459 	 G:  3.7589853 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 13.431168 	D(real) 0.41767554812961155 	D(fake) 1.0746764077080622 	 G:  3.7588809 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 13.431249 	D(real) 0.41766534911261666 	D(fake) 1.0746955871582031 	 G:  3.7587922 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 13.431343 	D(real) 0.4176550441318088 	D(fake) 1.0747163560655382 	 G:  3.7586946 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 13.431434 	D(real) 0.41764479213290745 	D(fake) 1.0747367011176214 	 G:  3.7586002 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 13.431501 	D(real) 0.4176347255706787 	D(fake) 1.0747542911105685 	 G:  3.7585185 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 13.431578 	D(real) 0.4176246060265435 	D(fake) 1.0747729407416449 	 G:  3.758431 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 13.431467 	D(real) 0.4176144599914551 	D(fake) 1.0747707155015733 	 G:  3.7584248 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 13.431509 	D(real) 0.4176134003533257 	D(fake) 1.0747765435112848 	 G:  3.7583969 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 13.431484 	D(real) 0.4176123407151964 	D(fake) 1.0747748480902777 	 G:  3.7584045 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 13.431519 	D(real) 0.41761136054992676 	D(fake) 1.0747796164618597 	 G:  3.7583828 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 13.431534 	D(real) 0.41761038038465714 	D(fake) 1.0747822655571833 	 G:  3.7583702 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 13.431513 	D(real) 0.4176092677646213 	D(fake) 1.074780993991428 	 G:  3.7583766 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 13.431522 	D(real) 0.41760826110839844 	D(fake) 1.0747831132676866 	 G:  3.7583663 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 13.431524 	D(real) 0.41760725445217556 	D(fake) 1.0747843848334417 	 G:  3.7583613 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 13.431536 	D(real) 0.4176063272688124 	D(fake) 1.0747865041097004 	 G:  3.7583501 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 13.4315405 	D(real) 0.4176052941216363 	D(fake) 1.0747880935668945 	 G:  3.758343 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 11}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 11
\seed data:	 11
\seed noise:	 11
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018551 	loss:  -0.35750595 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018357 	loss:  -4.6411147 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018072 	loss:  9.171826 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017863 	loss:  9.834225 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017983 	loss:  7.22298 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017784 	loss:  7.870864 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017727 	loss:  8.8617115 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017798 	loss:  8.882108 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017983 	loss:  7.0514774 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017932 	loss:  7.051738 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018108 	loss:  7.1391535 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018052 	loss:  6.8601837 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017935 	loss:  4.1129966 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017919 	loss:  2.1310222 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017792 	loss:  2.2607198 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017762 	loss:  2.8386273 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018023 	loss:  2.958717 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017768 	loss:  3.066508 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018069 	loss:  3.0349023 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017994 	loss:  2.9892824 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017800 	loss:  3.2032065 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017843 	loss:  3.3741179 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017976 	loss:  3.4361477 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017975 	loss:  3.6649444 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018136 	loss:  3.6351676 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018008 	loss:  4.103493 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017954 	loss:  4.2888136 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017920 	loss:  4.358079 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017673 	loss:  4.521381 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017871 	loss:  4.847017 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018394 	loss:  5.153376 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018297 	loss:  5.208001 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018067 	loss:  5.275464 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018050 	loss:  5.442407 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017946 	loss:  5.363127 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018154 	loss:  5.6020803 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018022 	loss:  5.6035666 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018303 	loss:  5.7619815 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017990 	loss:  5.9682074 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017824 	loss:  5.8960557 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017777 	loss:  5.951541 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017890 	loss:  6.018035 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018196 	loss:  6.068741 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017866 	loss:  6.3037486 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017694 	loss:  6.063452 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018039 	loss:  6.1344557 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017965 	loss:  6.172245 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018181 	loss:  6.151367 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018321 	loss:  6.2536983 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.018281 	loss:  6.2030473 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:32.128666
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_11/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 15.412746 	D(real) 0.4568159282207489 	D(fake) 1.4697773456573486 	 G:  4.5851364 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 12.551851 	D(real) 0.5873614549636841 	D(fake) 0.9816198945045471 	 G:  3.6713634 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 12.01891 	D(real) 0.4090152680873871 	D(fake) 1.093348503112793 	 G:  3.9367783 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 9.659561 	D(real) 0.3422868549823761 	D(fake) 0.8651583194732666 	 G:  5.678729 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 6.7981877 	D(real) 0.26764464378356934 	D(fake) 0.5821288228034973 	 G:  7.7431765 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 4.1862717 	D(real) 0.13199101388454437 	D(fake) 0.391292929649353 	 G:  10.809492 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 2.4727201 	D(real) 0.07839106768369675 	D(fake) 0.23069895803928375 	 G:  14.752844 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 1.4062071 	D(real) 0.04439454525709152 	D(fake) 0.1313813477754593 	 G:  18.890793 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 0.8153816 	D(real) 0.025555836036801338 	D(fake) 0.0763668641448021 	 G:  22.891571 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 0.4934562 	D(real) 0.01531400065869093 	D(fake) 0.04636802524328232 	 G:  26.582447 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 0.36477605 	D(real) 0.009641162119805813 	D(fake) 0.03595584258437157 	 G:  26.910206 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 0.35038456 	D(real) 0.009253724478185177 	D(fake) 0.03454434499144554 	 G:  27.208164 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 0.33814353 	D(real) 0.008922500535845757 	D(fake) 0.03334544226527214 	 G:  27.472061 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 0.327206 	D(real) 0.00863578449934721 	D(fake) 0.032264962792396545 	 G:  27.719631 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 0.31771395 	D(real) 0.00838459748774767 	D(fake) 0.031329646706581116 	 G:  27.941572 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 0.30940843 	D(real) 0.008162100799381733 	D(fake) 0.030513953417539597 	 G:  28.14135 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 0.30164117 	D(real) 0.007962874136865139 	D(fake) 0.029742272570729256 	 G:  28.33643 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 0.29465398 	D(real) 0.0077826776541769505 	D(fake) 0.029049070551991463 	 G:  28.51672 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 0.28823334 	D(real) 0.007618105970323086 	D(fake) 0.028411060571670532 	 G:  28.687164 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 0.28211623 	D(real) 0.007466457784175873 	D(fake) 0.02779807336628437 	 G:  28.855288 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 0.27873603 	D(real) 0.00732558686286211 	D(fake) 0.02751641534268856 	 G:  28.86149 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 0.2780384 	D(real) 0.00731227220967412 	D(fake) 0.027442529797554016 	 G:  28.882448 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 0.27757075 	D(real) 0.007299490738660097 	D(fake) 0.027396852150559425 	 G:  28.895405 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 0.27715907 	D(real) 0.00728713721036911 	D(fake) 0.02735774591565132 	 G:  28.906548 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 0.27645302 	D(real) 0.0072750914841890335 	D(fake) 0.027281535789370537 	 G:  28.928452 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 0.2759857 	D(real) 0.007263293489813805 	D(fake) 0.027234917506575584 	 G:  28.941883 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 0.27565375 	D(real) 0.007251684553921223 	D(fake) 0.027205035090446472 	 G:  28.950504 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 0.2751154 	D(real) 0.007240156643092632 	D(fake) 0.027149269357323647 	 G:  28.966682 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 0.27465615 	D(real) 0.0072287567891180515 	D(fake) 0.027103260159492493 	 G:  28.98007 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 0.2745892 	D(real) 0.007217335049062967 	D(fake) 0.02710631489753723 	 G:  28.979214 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 0.2738307 	D(real) 0.0072060031816363335 	D(fake) 0.027022836729884148 	 G:  28.997143 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 0.27377635 	D(real) 0.007204839959740639 	D(fake) 0.027017202228307724 	 G:  28.998796 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 0.27381167 	D(real) 0.007203729823231697 	D(fake) 0.027022728696465492 	 G:  28.997189 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 0.2736696 	D(real) 0.007202558219432831 	D(fake) 0.02700614184141159 	 G:  29.00204 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 0.2736574 	D(real) 0.0072014108300209045 	D(fake) 0.027005765587091446 	 G:  29.002161 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 0.27370313 	D(real) 0.007200232706964016 	D(fake) 0.0270126573741436 	 G:  29.000158 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 0.2736646 	D(real) 0.0071990471333265305 	D(fake) 0.02700902707874775 	 G:  29.001219 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 0.27355945 	D(real) 0.007197868544608355 	D(fake) 0.02699706330895424 	 G:  29.004725 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 0.27374232 	D(real) 0.007196667604148388 	D(fake) 0.027021123096346855 	 G:  28.9977 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 0.27337712 	D(real) 0.007195489481091499 	D(fake) 0.026976650580763817 	 G:  29.010708 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 0.27367732 	D(real) 0.007194243837147951 	D(fake) 0.02701542153954506 	 G:  28.998692 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 0.27336416 	D(real) 0.007194123696535826 	D(fake) 0.02697639726102352 	 G:  29.010092 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 0.27343303 	D(real) 0.007194011006504297 	D(fake) 0.02698511630296707 	 G:  29.007538 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 0.2733402 	D(real) 0.007193853612989187 	D(fake) 0.026973670348525047 	 G:  29.010891 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 0.27333966 	D(real) 0.007193726021796465 	D(fake) 0.026973731815814972 	 G:  29.010872 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 0.27353394 	D(real) 0.007193605415523052 	D(fake) 0.026998136192560196 	 G:  29.003738 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 0.27338594 	D(real) 0.007193485740572214 	D(fake) 0.026979755610227585 	 G:  29.009113 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 0.27330878 	D(real) 0.007193365599960089 	D(fake) 0.026970233768224716 	 G:  29.011894 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 0.27333963 	D(real) 0.007193245925009251 	D(fake) 0.026974206790328026 	 G:  29.010735 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 0.27327076 	D(real) 0.007193110417574644 	D(fake) 0.026965735480189323 	 G:  29.013218 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 12}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 12
\seed data:	 12
\seed noise:	 12
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018743 	loss:  1.3080717 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018535 	loss:  1.5212376 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018522 	loss:  8.694401 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018640 	loss:  11.587702 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018587 	loss:  11.494239 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.018440 	loss:  11.493777 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018340 	loss:  11.493793 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.018678 	loss:  11.494441 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018242 	loss:  10.56061 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018612 	loss:  7.813966 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018450 	loss:  7.8143167 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017969 	loss:  9.254397 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.018054 	loss:  11.454398 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018535 	loss:  11.201058 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018500 	loss:  11.147715 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018098 	loss:  11.147699 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018531 	loss:  11.147697 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018823 	loss:  11.147695 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018198 	loss:  11.147692 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.018194 	loss:  11.147688 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018085 	loss:  11.147684 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017955 	loss:  11.147681 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018380 	loss:  11.174344 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.019425 	loss:  11.161006 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018757 	loss:  11.241002 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018493 	loss:  11.307667 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018436 	loss:  11.440996 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018552 	loss:  11.494328 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.018046 	loss:  11.494325 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018070 	loss:  11.507656 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018257 	loss:  11.494319 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018150 	loss:  11.494318 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018166 	loss:  11.494318 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018092 	loss:  11.494318 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017968 	loss:  11.494317 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018108 	loss:  11.494317 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018395 	loss:  11.494317 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018569 	loss:  11.494316 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018194 	loss:  11.494316 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018942 	loss:  11.494316 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018188 	loss:  11.494315 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018566 	loss:  11.494315 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018761 	loss:  11.494314 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018603 	loss:  11.494314 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018193 	loss:  11.494314 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018149 	loss:  11.494313 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018886 	loss:  11.494313 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018208 	loss:  11.494313 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018178 	loss:  11.494313 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017854 	loss:  11.494313 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.259778
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_12/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 14.517712 	D(real) 0.6508185598585341 	D(fake) 0.9622605641682943 	 G:  4.8072815 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 13.810324 	D(real) 0.5344592730204264 	D(fake) 1.0000211927625868 	 G:  5.2244186 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 13.064112 	D(real) 0.5804183748033311 	D(fake) 0.8711495399475098 	 G:  4.7716656 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 13.478488 	D(real) 0.5301419364081489 	D(fake) 0.9674678378634982 	 G:  4.157416 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 13.719894 	D(real) 0.46193520228068036 	D(fake) 1.0624974568684895 	 G:  3.7960174 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 13.896037 	D(real) 0.4218229452768962 	D(fake) 1.122181150648329 	 G:  3.5939145 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 13.998671 	D(real) 0.39940783712599015 	D(fake) 1.1560000313652887 	 G:  3.4855711 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 14.026212 	D(real) 0.38741861449347603 	D(fake) 1.171049329969618 	 G:  3.4490125 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 13.987667 	D(real) 0.38332769605848527 	D(fake) 1.1708575354682074 	 G:  3.469956 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 13.903224 	D(real) 0.3855944474538167 	D(fake) 1.1592081917656794 	 G:  3.5310354 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 13.673647 	D(real) 0.3923910723792182 	D(fake) 1.1269030041164823 	 G:  3.53916 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 13.663274 	D(real) 0.39328183068169487 	D(fake) 1.1248597039116754 	 G:  3.547984 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 13.652359 	D(real) 0.39427052603827584 	D(fake) 1.122658199734158 	 G:  3.5574384 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 13.641653 	D(real) 0.39531376626756454 	D(fake) 1.1204254362318251 	 G:  3.5669842 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 13.630738 	D(real) 0.39637737803988987 	D(fake) 1.1181491216023762 	 G:  3.5766869 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 13.620396 	D(real) 0.3974342876010471 	D(fake) 1.1159429550170898 	 G:  3.5860624 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 13.611202 	D(real) 0.3984634081522624 	D(fake) 1.1138923433091905 	 G:  3.5947475 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 13.602183 	D(real) 0.3994482888115777 	D(fake) 1.1119054158528645 	 G:  3.603149 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 13.593346 	D(real) 0.40037666426764595 	D(fake) 1.10999510023329 	 G:  3.6112173 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 13.586009 	D(real) 0.4012402163611518 	D(fake) 1.1083163155449762 	 G:  3.6182747 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 13.569195 	D(real) 0.4020332230461968 	D(fake) 1.105655140346951 	 G:  3.6188653 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 13.56884 	D(real) 0.40210504002041286 	D(fake) 1.1055438783433702 	 G:  3.6193266 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 13.567649 	D(real) 0.40216999583774143 	D(fake) 1.1053465737236872 	 G:  3.6201775 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 13.567785 	D(real) 0.4022293620639377 	D(fake) 1.1053022808498807 	 G:  3.6203516 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 13.56753 	D(real) 0.40228403939141166 	D(fake) 1.1052192052205403 	 G:  3.6207025 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 13.566816 	D(real) 0.40233487553066677 	D(fake) 1.1050891876220703 	 G:  3.6212654 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 13.566277 	D(real) 0.4023824797736274 	D(fake) 1.1049815283881292 	 G:  3.6217315 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 13.565871 	D(real) 0.4024273289574517 	D(fake) 1.1048916710747614 	 G:  3.6221209 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 13.565617 	D(real) 0.4024699529012044 	D(fake) 1.1048207812839084 	 G:  3.6224267 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 13.565042 	D(real) 0.4025106694963243 	D(fake) 1.1047161950005426 	 G:  3.6228843 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 13.564006 	D(real) 0.40254966417948407 	D(fake) 1.1045621236165364 	 G:  3.622634 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 13.5633135 	D(real) 0.40255345238579643 	D(fake) 1.1044813791910808 	 G:  3.6229935 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 13.563519 	D(real) 0.40255702866448295 	D(fake) 1.1045005586412218 	 G:  3.6229072 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 13.563432 	D(real) 0.402560551961263 	D(fake) 1.104487419128418 	 G:  3.6229653 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 13.563492 	D(real) 0.40256402227613663 	D(fake) 1.104490598042806 	 G:  3.6229506 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 13.563845 	D(real) 0.40256738662719727 	D(fake) 1.1045265197753906 	 G:  3.6227908 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 13.563367 	D(real) 0.4025707509782579 	D(fake) 1.1044700410630968 	 G:  3.6230419 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 13.563449 	D(real) 0.4025740358564589 	D(fake) 1.1044758690728083 	 G:  3.6230168 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 13.563876 	D(real) 0.4025772677527534 	D(fake) 1.1045200559828017 	 G:  3.6228192 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 13.56327 	D(real) 0.40258047315809464 	D(fake) 1.1044494840833876 	 G:  3.6231334 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 13.563657 	D(real) 0.40258365207248265 	D(fake) 1.1044893264770508 	 G:  3.6228657 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 13.56317 	D(real) 0.40258396996392143 	D(fake) 1.1044349670410156 	 G:  3.623107 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 13.563074 	D(real) 0.40258428785536027 	D(fake) 1.1044239468044705 	 G:  3.6231575 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 13.562942 	D(real) 0.40258463223775226 	D(fake) 1.104408899943034 	 G:  3.6232243 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 13.563031 	D(real) 0.4025848971472846 	D(fake) 1.1044185426500108 	 G:  3.623181 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 13.563097 	D(real) 0.40258516205681694 	D(fake) 1.1044256422254775 	 G:  3.6231494 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 13.5631485 	D(real) 0.4025855329301622 	D(fake) 1.104430940416124 	 G:  3.6231256 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 13.563238 	D(real) 0.40258582433064777 	D(fake) 1.1044405831231012 	 G:  3.623083 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 13.563739 	D(real) 0.40258611573113334 	D(fake) 1.1044960021972656 	 G:  3.6228354 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 13.563088 	D(real) 0.4025864866044786 	D(fake) 1.1044233110215929 	 G:  3.6231596 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 13}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 13
\seed data:	 13
\seed noise:	 13
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018042 	loss:  0.9614289 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017642 	loss:  -1.507302 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017657 	loss:  7.17825 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017640 	loss:  8.27538 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017804 	loss:  8.275296 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017897 	loss:  8.2752075 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017440 	loss:  8.274793 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017583 	loss:  9.555291 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017976 	loss:  9.555198 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017273 	loss:  8.274455 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017319 	loss:  8.274524 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017713 	loss:  9.554436 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017389 	loss:  9.41735 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017442 	loss:  9.417936 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017673 	loss:  9.372292 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018063 	loss:  9.555031 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017682 	loss:  9.555002 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017598 	loss:  9.554955 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017632 	loss:  9.554887 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017477 	loss:  9.554798 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017823 	loss:  9.554687 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017690 	loss:  9.554562 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017790 	loss:  9.554442 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017084 	loss:  9.55438 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017187 	loss:  9.554445 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017268 	loss:  9.554563 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017481 	loss:  9.554547 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017644 	loss:  9.554449 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017668 	loss:  9.554376 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017723 	loss:  9.554358 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017132 	loss:  9.554376 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017024 	loss:  9.5543785 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017152 	loss:  9.554379 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017113 	loss:  9.55438 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017418 	loss:  9.55438 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017224 	loss:  9.554379 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017254 	loss:  9.5543785 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017094 	loss:  9.554377 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017229 	loss:  9.554374 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017341 	loss:  9.554372 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017531 	loss:  9.554369 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017073 	loss:  9.554366 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017057 	loss:  9.554363 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017477 	loss:  9.55436 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017808 	loss:  9.554358 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017356 	loss:  9.554356 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017056 	loss:  9.554355 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017500 	loss:  9.554355 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017171 	loss:  9.554355 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017454 	loss:  9.554355 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.311152
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_13/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 11.35425 	D(real) 0.4978493849436442 	D(fake) 1.3945255279541016 	 G:  2.9914827 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 9.361807 	D(real) 0.5069764057795206 	D(fake) 1.0533246994018555 	 G:  2.6460688 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 9.112176 	D(real) 0.44099191824595135 	D(fake) 1.0777041117350261 	 G:  2.6937873 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 9.040698 	D(real) 0.44922006130218506 	D(fake) 1.0575629870096843 	 G:  2.677473 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 9.136147 	D(real) 0.4463003873825073 	D(fake) 1.0763906637827556 	 G:  2.542331 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 9.207379 	D(real) 0.4269847472508748 	D(fake) 1.10757843653361 	 G:  2.4417832 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 9.243345 	D(real) 0.40696390469868976 	D(fake) 1.1335935592651367 	 G:  2.3798735 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 9.233485 	D(real) 0.39663652578989667 	D(fake) 1.142277717590332 	 G:  2.3687665 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 9.191132 	D(real) 0.3947944641113281 	D(fake) 1.1370607217152913 	 G:  2.3902686 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 9.137584 	D(real) 0.3983783721923828 	D(fake) 1.1245522499084473 	 G:  2.4257278 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 9.037579 	D(real) 0.40428821245829266 	D(fake) 1.1019748051961262 	 G:  2.4291408 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 9.034019 	D(real) 0.40487194061279297 	D(fake) 1.1007980505625408 	 G:  2.432176 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 9.031904 	D(real) 0.40533947944641113 	D(fake) 1.0999778111775715 	 G:  2.4342542 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 9.030126 	D(real) 0.40571077664693195 	D(fake) 1.0993101596832275 	 G:  2.4359405 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 9.028626 	D(real) 0.4060027201970418 	D(fake) 1.0987683931986492 	 G:  2.4373055 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 9.025034 	D(real) 0.40622854232788086 	D(fake) 1.097943862279256 	 G:  2.4393823 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 9.027309 	D(real) 0.406356414159139 	D(fake) 1.098195234934489 	 G:  2.4384303 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 9.027036 	D(real) 0.4064081112543742 	D(fake) 1.098097801208496 	 G:  2.4386196 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 9.02456 	D(real) 0.40643660227457684 	D(fake) 1.0976567268371582 	 G:  2.4398885 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 9.027026 	D(real) 0.4064440329869588 	D(fake) 1.0980602900187175 	 G:  2.438576 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 9.011885 	D(real) 0.40643544991811115 	D(fake) 1.0955453713734944 	 G:  2.4423542 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 9.019796 	D(real) 0.4064173698425293 	D(fake) 1.0968819459279378 	 G:  2.4383132 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 9.020088 	D(real) 0.4063862164815267 	D(fake) 1.0969617366790771 	 G:  2.4380867 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 9.020077 	D(real) 0.4063597122828166 	D(fake) 1.0969863732655842 	 G:  2.4380212 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 9.020205 	D(real) 0.40633686383565265 	D(fake) 1.097030480702718 	 G:  2.437898 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 9.02033 	D(real) 0.40631715456644696 	D(fake) 1.0970711708068848 	 G:  2.4377818 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 9.02039 	D(real) 0.4062996705373128 	D(fake) 1.0970985094706218 	 G:  2.4377053 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 9.02047 	D(real) 0.40628449122111004 	D(fake) 1.0971271991729736 	 G:  2.4376237 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 9.020491 	D(real) 0.4062707821528117 	D(fake) 1.0971442858378093 	 G:  2.4375768 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 8.999066 	D(real) 0.4062586228052775 	D(fake) 1.0935858090718586 	 G:  2.4483202 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 9.020056 	D(real) 0.4062236150105794 	D(fake) 1.0971190929412842 	 G:  2.4373012 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 9.020071 	D(real) 0.4062184492746989 	D(fake) 1.097126801808675 	 G:  2.4372814 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 9.012632 	D(real) 0.4062141577402751 	D(fake) 1.0958913167317708 	 G:  2.4410198 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 9.020178 	D(real) 0.406210462252299 	D(fake) 1.0971524715423584 	 G:  2.4372067 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 8.9955015 	D(real) 0.4062070846557617 	D(fake) 1.0930431683858235 	 G:  2.449782 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 9.020188 	D(real) 0.40620168050130206 	D(fake) 1.0971630414326985 	 G:  2.4371648 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 9.013243 	D(real) 0.4061947266260783 	D(fake) 1.0960123538970947 	 G:  2.440647 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 9.020344 	D(real) 0.4061888058980306 	D(fake) 1.0972018241882324 	 G:  2.4370534 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 9.020273 	D(real) 0.40618379910786945 	D(fake) 1.097194989522298 	 G:  2.4370766 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 9.013975 	D(real) 0.40617962678273517 	D(fake) 1.0961496035257976 	 G:  2.4402373 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 9.01931 	D(real) 0.4061758518218994 	D(fake) 1.097042401631673 	 G:  2.4375088 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 9.012814 	D(real) 0.40617553393046063 	D(fake) 1.0959601402282715 	 G:  2.440784 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 9.020226 	D(real) 0.4061752160390218 	D(fake) 1.0971957842508953 	 G:  2.4370482 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 9.0202265 	D(real) 0.40617485841115314 	D(fake) 1.0971962610880535 	 G:  2.437046 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 9.020428 	D(real) 0.40617461999257404 	D(fake) 1.0972299575805664 	 G:  2.4369457 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 9.020229 	D(real) 0.4061744213104248 	D(fake) 1.0971970558166504 	 G:  2.4370446 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 9.02023 	D(real) 0.40617422262827557 	D(fake) 1.097197453180949 	 G:  2.4370432 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 9.020229 	D(real) 0.406174103418986 	D(fake) 1.0971975326538086 	 G:  2.4370432 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 9.020229 	D(real) 0.40617390473683673 	D(fake) 1.0971976121266682 	 G:  2.4370427 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 9.02018 	D(real) 0.4061737855275472 	D(fake) 1.0971895853678386 	 G:  2.4370675 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 14}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 14
\seed data:	 14
\seed noise:	 14
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018160 	loss:  -2.827852 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018048 	loss:  -0.9422702 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018355 	loss:  1.9054766 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018465 	loss:  9.1432295 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017887 	loss:  9.94323 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017595 	loss:  9.828904 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018426 	loss:  10.171704 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.018116 	loss:  10.028868 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017970 	loss:  10.028727 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017557 	loss:  10.030079 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017527 	loss:  10.02889 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017498 	loss:  10.028939 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017860 	loss:  9.252814 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018153 	loss:  5.6647153 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018210 	loss:  6.878115 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017700 	loss:  4.112705 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018200 	loss:  3.9618683 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018217 	loss:  4.2037115 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018119 	loss:  3.2231736 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017891 	loss:  3.5133686 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018096 	loss:  3.4845958 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018504 	loss:  2.932949 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017951 	loss:  2.6324034 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018184 	loss:  3.004706 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018027 	loss:  2.1485965 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018039 	loss:  2.759521 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018173 	loss:  2.5725393 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018288 	loss:  2.4886556 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.018531 	loss:  2.3945973 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017893 	loss:  2.5571373 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018804 	loss:  2.140594 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018194 	loss:  2.4389796 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018380 	loss:  2.1695938 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018531 	loss:  2.3984282 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018238 	loss:  2.0771494 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017876 	loss:  2.6792483 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017972 	loss:  2.3382847 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017807 	loss:  2.6267245 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018310 	loss:  2.5463407 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018224 	loss:  2.0631628 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017990 	loss:  2.161286 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017971 	loss:  1.6632195 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017564 	loss:  2.801922 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018135 	loss:  2.610578 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017843 	loss:  2.8030176 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017930 	loss:  2.461798 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017724 	loss:  2.7353938 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018790 	loss:  2.7732267 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018217 	loss:  2.3397374 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017723 	loss:  2.9614096 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.242413
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_14/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 15.49129 	D(real) 0.7246953419276646 	D(fake) 1.4883460998535156 	 G:  2.211941 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 11.700383 	D(real) 0.31655832699366976 	D(fake) 1.3549250194004603 	 G:  2.390797 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 10.957473 	D(real) 0.3415441853659494 	D(fake) 1.223809106009347 	 G:  2.720646 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 10.539551 	D(real) 0.3886540276663644 	D(fake) 1.1169960839407784 	 G:  2.9950309 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 10.358722 	D(real) 0.42786056654793875 	D(fake) 1.0519568579537528 	 G:  3.1642923 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 10.303972 	D(real) 0.45204142161778044 	D(fake) 1.0199545451572962 	 G:  3.235439 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 10.325637 	D(real) 0.46220551218305317 	D(fake) 1.012885502406529 	 G:  3.222145 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 10.400036 	D(real) 0.46030657632010324 	D(fake) 1.0254127638680595 	 G:  3.1415982 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 10.506147 	D(real) 0.4487998144967215 	D(fake) 1.0520783833095007 	 G:  3.0228539 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 10.619131 	D(real) 0.43183633259364534 	D(fake) 1.0851823261805944 	 G:  2.9013026 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 10.491776 	D(real) 0.4144718647003174 	D(fake) 1.084353310721261 	 G:  2.8906739 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 10.50057 	D(real) 0.4129535470690046 	D(fake) 1.087127958025251 	 G:  2.8811874 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 10.50845 	D(real) 0.41159820556640625 	D(fake) 1.089608873639788 	 G:  2.872791 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 10.515428 	D(real) 0.4103987898145403 	D(fake) 1.0918051855904716 	 G:  2.8654299 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 10.521538 	D(real) 0.4093471254621233 	D(fake) 1.0937297003609794 	 G:  2.8590372 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 10.526823 	D(real) 0.40843394824436735 	D(fake) 1.09539794921875 	 G:  2.853547 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 10.53133 	D(real) 0.4076495851789202 	D(fake) 1.0968261446271623 	 G:  2.8488903 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 10.535118 	D(real) 0.40698436328342985 	D(fake) 1.0980324745178223 	 G:  2.8449945 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 10.538246 	D(real) 0.40642779214041574 	D(fake) 1.0990359442574638 	 G:  2.8417869 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 10.540774 	D(real) 0.4059696538107736 	D(fake) 1.0998552867344447 	 G:  2.8391993 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 10.529115 	D(real) 0.40559990065438406 	D(fake) 1.0985593795776367 	 G:  2.8389907 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 10.529282 	D(real) 0.40557009833199636 	D(fake) 1.0986130578177316 	 G:  2.83882 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 10.529412 	D(real) 0.4055459839957101 	D(fake) 1.0986557688031877 	 G:  2.8386848 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 10.529522 	D(real) 0.4055264677320208 	D(fake) 1.0986909866333008 	 G:  2.838574 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 10.52961 	D(real) 0.40551059586661203 	D(fake) 1.0987193243844169 	 G:  2.8384836 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 10.529681 	D(real) 0.40549772126334055 	D(fake) 1.0987424169267928 	 G:  2.8384109 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 10.529738 	D(real) 0.40548733302525114 	D(fake) 1.0987610135759627 	 G:  2.8383522 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 10.529783 	D(real) 0.4054789202553885 	D(fake) 1.098775863647461 	 G:  2.8383057 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 10.5298195 	D(real) 0.40547224453517366 	D(fake) 1.0987876483372279 	 G:  2.838269 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 10.52985 	D(real) 0.40546703338623047 	D(fake) 1.0987972531999861 	 G:  2.8382392 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 10.528689 	D(real) 0.40546274185180664 	D(fake) 1.0986357416425432 	 G:  2.8382363 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 10.52869 	D(real) 0.40546233313424246 	D(fake) 1.0986362865992956 	 G:  2.8382347 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 10.528692 	D(real) 0.40546209471566336 	D(fake) 1.0986367634364538 	 G:  2.8382337 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 10.528694 	D(real) 0.4054619584764753 	D(fake) 1.0986371721540178 	 G:  2.8382323 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 10.528695 	D(real) 0.4054617541176932 	D(fake) 1.098637580871582 	 G:  2.8382308 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 10.528694 	D(real) 0.40546158381870817 	D(fake) 1.098637648991176 	 G:  2.8382306 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 10.528697 	D(real) 0.4054615156991141 	D(fake) 1.0986380577087402 	 G:  2.8382297 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 10.528697 	D(real) 0.40546137945992605 	D(fake) 1.0986381939479284 	 G:  2.8382292 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 10.528698 	D(real) 0.40546137945992605 	D(fake) 1.0986383983067103 	 G:  2.8382292 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 10.528698 	D(real) 0.40546131134033203 	D(fake) 1.0986383983067103 	 G:  2.8382292 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 10.528582 	D(real) 0.40546131134033203 	D(fake) 1.0986218452453613 	 G:  2.8382292 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 10.528584 	D(real) 0.40546131134033203 	D(fake) 1.0986219814845495 	 G:  2.8382287 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 10.528583 	D(real) 0.40546131134033203 	D(fake) 1.0986219133649553 	 G:  2.8382287 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 10.528584 	D(real) 0.40546131134033203 	D(fake) 1.0986219814845495 	 G:  2.8382287 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 10.528583 	D(real) 0.40546131134033203 	D(fake) 1.0986219133649553 	 G:  2.8382287 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 10.528583 	D(real) 0.40546131134033203 	D(fake) 1.0986219133649553 	 G:  2.838229 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 10.528582 	D(real) 0.40546131134033203 	D(fake) 1.0986218452453613 	 G:  2.8382292 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 10.528582 	D(real) 0.40546131134033203 	D(fake) 1.0986218452453613 	 G:  2.8382292 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 10.528583 	D(real) 0.40546131134033203 	D(fake) 1.0986219133649553 	 G:  2.838229 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 10.528584 	D(real) 0.40546131134033203 	D(fake) 1.0986219814845495 	 G:  2.8382287 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 15}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 15
\seed data:	 15
\seed noise:	 15
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.017718 	loss:  1.7614506 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017204 	loss:  3.7612886 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017035 	loss:  10.081091 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017285 	loss:  11.20101 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017245 	loss:  11.2006 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017317 	loss:  11.20086 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017451 	loss:  11.204038 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017283 	loss:  7.6812606 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017175 	loss:  5.44128 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.016926 	loss:  5.1212964 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017147 	loss:  6.6413074 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.016873 	loss:  9.0210495 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017073 	loss:  6.721295 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017176 	loss:  4.7379017 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017143 	loss:  0.49787837 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017087 	loss:  -2.2387743 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018005 	loss:  -2.070464 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017208 	loss:  -2.0522892 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017699 	loss:  -2.4112537 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.016954 	loss:  -2.3556702 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017194 	loss:  -2.2626922 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017382 	loss:  -2.2060702 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017287 	loss:  -2.343213 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017240 	loss:  -2.195687 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017894 	loss:  -2.328517 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017254 	loss:  -2.3250484 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017181 	loss:  -2.267388 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017583 	loss:  -2.4788232 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.016870 	loss:  -2.4258456 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.016821 	loss:  -2.5957153 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017047 	loss:  -2.6985812 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.016872 	loss:  -2.4315643 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.016868 	loss:  -2.670013 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017182 	loss:  -2.766099 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017215 	loss:  -2.592092 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017443 	loss:  -2.4746838 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017478 	loss:  -2.9546843 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017030 	loss:  -2.8689764 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017149 	loss:  -2.9157102 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017145 	loss:  -2.6637821 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017190 	loss:  -2.878843 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017281 	loss:  -2.4830003 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017265 	loss:  -2.846118 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017123 	loss:  -2.710361 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017057 	loss:  -2.6778061 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017699 	loss:  -2.9006536 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.016987 	loss:  -2.632611 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017222 	loss:  -2.6345186 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017327 	loss:  -2.7375503 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017305 	loss:  -2.9920983 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.448604
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_15/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 8.809391 	D(real) 0.7624529361724853 	D(fake) 0.9994253158569336 	 G:  3.363193 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 8.078244 	D(real) 0.6839982986450195 	D(fake) 0.9316505432128906 	 G:  2.2256541 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 7.836255 	D(real) 0.43843350410461424 	D(fake) 1.1288174629211425 	 G:  2.0494545 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 7.5632143 	D(real) 0.4094101428985596 	D(fake) 1.1032326698303223 	 G:  2.2036922 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 7.449705 	D(real) 0.4411147117614746 	D(fake) 1.048826313018799 	 G:  2.281087 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 7.4642816 	D(real) 0.4561478614807129 	D(fake) 1.036708450317383 	 G:  2.2489705 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 7.5420537 	D(real) 0.4493077278137207 	D(fake) 1.059103012084961 	 G:  2.1527493 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 7.636409 	D(real) 0.4297367572784424 	D(fake) 1.0975449562072754 	 G:  2.0446312 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 7.7178345 	D(real) 0.4074862957000732 	D(fake) 1.136080551147461 	 G:  1.9603066 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 7.7524667 	D(real) 0.3895470380783081 	D(fake) 1.1609462738037108 	 G:  1.928441 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 7.6072206 	D(real) 0.3796576499938965 	D(fake) 1.141786479949951 	 G:  1.930454 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 7.595676 	D(real) 0.37949495315551757 	D(fake) 1.1396402359008788 	 G:  1.9374062 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 7.5776567 	D(real) 0.3798943519592285 	D(fake) 1.1356369972229003 	 G:  1.948285 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 7.5582876 	D(real) 0.3807016611099243 	D(fake) 1.1309558868408203 	 G:  1.960397 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 7.5372334 	D(real) 0.3817615032196045 	D(fake) 1.125685214996338 	 G:  1.9735988 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 7.5124583 	D(real) 0.3828925371170044 	D(fake) 1.1195991516113282 	 G:  1.9883502 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 7.490729 	D(real) 0.3838153600692749 	D(fake) 1.1143303871154786 	 G:  2.0008385 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 7.4626036 	D(real) 0.3841684103012085 	D(fake) 1.108352279663086 	 G:  2.0147698 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 7.4400005 	D(real) 0.38352463245391843 	D(fake) 1.104475498199463 	 G:  2.023433 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 7.418734 	D(real) 0.3816048622131348 	D(fake) 1.1021419525146485 	 G:  2.0287786 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 7.3806543 	D(real) 0.3785824775695801 	D(fake) 1.0975483894348144 	 G:  2.0310493 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 7.3785744 	D(real) 0.3782170295715332 	D(fake) 1.0974978446960448 	 G:  2.0312085 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 7.3727436 	D(real) 0.37782926559448243 	D(fake) 1.096719455718994 	 G:  2.0332065 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 7.3703446 	D(real) 0.37742650508880615 	D(fake) 1.0966423988342284 	 G:  2.033443 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 7.364795 	D(real) 0.3770144462585449 	D(fake) 1.095944595336914 	 G:  2.0352426 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 7.360055 	D(real) 0.3765981197357178 	D(fake) 1.095412826538086 	 G:  2.0366302 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 7.357389 	D(real) 0.37617905139923097 	D(fake) 1.0952987670898438 	 G:  2.0369668 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 7.349913 	D(real) 0.37576248645782473 	D(fake) 1.0942201614379883 	 G:  2.0397449 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 7.34566 	D(real) 0.37534921169281005 	D(fake) 1.0937828063964843 	 G:  2.0408945 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 7.337413 	D(real) 0.3749375820159912 	D(fake) 1.092544937133789 	 G:  2.0440745 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 7.3351727 	D(real) 0.3745256900787354 	D(fake) 1.092508888244629 	 G:  2.0428085 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 7.3426647 	D(real) 0.37448480129241946 	D(fake) 1.0940481185913087 	 G:  2.038935 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 7.3359475 	D(real) 0.3744457960128784 	D(fake) 1.0927436828613282 	 G:  2.0422308 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 7.340029 	D(real) 0.3744084596633911 	D(fake) 1.0935973167419433 	 G:  2.0400782 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 7.334991 	D(real) 0.3743722915649414 	D(fake) 1.092625904083252 	 G:  2.0425317 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 7.336879 	D(real) 0.3743372917175293 	D(fake) 1.0930384635925292 	 G:  2.0414958 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 7.338057 	D(real) 0.3743027687072754 	D(fake) 1.0933086395263671 	 G:  2.0408146 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 7.3328424 	D(real) 0.37426931858062745 	D(fake) 1.0922991752624511 	 G:  2.0433633 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 7.3328276 	D(real) 0.3742362499237061 	D(fake) 1.092329216003418 	 G:  2.0432858 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 7.3307095 	D(real) 0.3742032527923584 	D(fake) 1.0919386863708496 	 G:  2.0442734 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 7.338289 	D(real) 0.3741702318191528 	D(fake) 1.093487548828125 	 G:  2.0402071 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 7.334316 	D(real) 0.37416696548461914 	D(fake) 1.092696189880371 	 G:  2.0422077 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 7.334289 	D(real) 0.374163818359375 	D(fake) 1.0926939964294433 	 G:  2.0422058 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 7.3245525 	D(real) 0.37416064739227295 	D(fake) 1.0907498359680177 	 G:  2.0471165 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 7.3286767 	D(real) 0.374157452583313 	D(fake) 1.091577911376953 	 G:  2.0450282 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 7.326579 	D(real) 0.3741541862487793 	D(fake) 1.0911616325378417 	 G:  2.0460749 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 7.3312316 	D(real) 0.37415077686309817 	D(fake) 1.0920955657958984 	 G:  2.0437179 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 7.330063 	D(real) 0.3741474628448486 	D(fake) 1.091865062713623 	 G:  2.0443006 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 7.3251123 	D(real) 0.3741441249847412 	D(fake) 1.090878391265869 	 G:  2.0467927 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 7.3326755 	D(real) 0.37414073944091797 	D(fake) 1.0923943519592285 	 G:  2.0429604 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 16}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 16
\seed data:	 16
\seed noise:	 16
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.019467 	loss:  0.89612114 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018192 	loss:  3.8673801 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017880 	loss:  10.267244 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017533 	loss:  9.505329 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018419 	loss:  6.114807 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017573 	loss:  9.295639 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017274 	loss:  9.295738 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017302 	loss:  10.286084 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017744 	loss:  10.286466 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017878 	loss:  9.981696 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017508 	loss:  8.0387535 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017424 	loss:  5.562495 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017143 	loss:  3.46725 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017483 	loss:  3.0133638 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018109 	loss:  1.083027 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018011 	loss:  2.3667693 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017533 	loss:  2.4286861 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017371 	loss:  2.4706674 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017235 	loss:  2.7288926 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017384 	loss:  2.687512 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017870 	loss:  2.6101322 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017635 	loss:  2.4980128 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018095 	loss:  2.7270348 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017696 	loss:  2.6378531 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017721 	loss:  2.6804898 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017509 	loss:  2.707877 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018089 	loss:  2.5016139 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017264 	loss:  2.5213828 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017809 	loss:  2.426245 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017733 	loss:  2.522052 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017842 	loss:  2.4250672 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017543 	loss:  2.4613314 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017916 	loss:  2.5322883 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017548 	loss:  2.514842 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018020 	loss:  2.6144266 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017784 	loss:  2.48198 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017104 	loss:  2.4621599 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017370 	loss:  2.506768 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017425 	loss:  2.329713 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017517 	loss:  2.4831524 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018334 	loss:  2.4812071 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017562 	loss:  2.4452465 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017979 	loss:  2.6334732 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017416 	loss:  2.5853395 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017294 	loss:  2.5793047 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018020 	loss:  2.5612576 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018045 	loss:  2.6563125 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017159 	loss:  2.6240916 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017177 	loss:  2.4620445 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017337 	loss:  2.6198275 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.719198
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_16/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 14.347371 	D(real) 0.832805335521698 	D(fake) 0.9606160521507263 	 G:  4.455284 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 11.988409 	D(real) 0.5574302673339844 	D(fake) 0.9411208033561707 	 G:  4.0536947 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 11.823958 	D(real) 0.5067160725593567 	D(fake) 0.971278727054596 	 G:  3.9044616 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 12.012121 	D(real) 0.4880613386631012 	D(fake) 1.0134538412094116 	 G:  3.5849187 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 12.279861 	D(real) 0.4481157958507538 	D(fake) 1.086866855621338 	 G:  3.2409291 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 12.497929 	D(real) 0.40511637926101685 	D(fake) 1.157124638557434 	 G:  3.0100634 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 12.577819 	D(real) 0.37625792622566223 	D(fake) 1.1959694623947144 	 G:  2.956144 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 12.492521 	D(real) 0.3695179224014282 	D(fake) 1.1920472383499146 	 G:  3.0379348 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 12.322716 	D(real) 0.37974175810813904 	D(fake) 1.1605976819992065 	 G:  3.1706426 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 12.160554 	D(real) 0.396330326795578 	D(fake) 1.1237388849258423 	 G:  3.3011053 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 11.983602 	D(real) 0.4126381576061249 	D(fake) 1.085312008857727 	 G:  3.3106916 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 11.977584 	D(real) 0.41383644938468933 	D(fake) 1.0833615064620972 	 G:  3.3166087 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 11.974458 	D(real) 0.41457608342170715 	D(fake) 1.0822311639785767 	 G:  3.3196278 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 11.973582 	D(real) 0.41495347023010254 	D(fake) 1.0817443132400513 	 G:  3.3203585 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 11.974461 	D(real) 0.4150448143482208 	D(fake) 1.0817627906799316 	 G:  3.3192942 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 11.976682 	D(real) 0.41491177678108215 	D(fake) 1.082173466682434 	 G:  3.3168473 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 11.979913 	D(real) 0.41460588574409485 	D(fake) 1.0828832387924194 	 G:  3.3133636 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 11.983879 	D(real) 0.41417044401168823 	D(fake) 1.0838145017623901 	 G:  3.3091314 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 11.988353 	D(real) 0.41364142298698425 	D(fake) 1.0849026441574097 	 G:  3.3043957 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 11.9931345 	D(real) 0.41304945945739746 	D(fake) 1.0860923528671265 	 G:  3.2993581 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 11.980123 	D(real) 0.41241976618766785 	D(fake) 1.0850955247879028 	 G:  3.298838 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 11.98063 	D(real) 0.4123547375202179 	D(fake) 1.0852240324020386 	 G:  3.2983057 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 11.981144 	D(real) 0.41228821873664856 	D(fake) 1.0853548049926758 	 G:  3.297764 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 11.981666 	D(real) 0.41222044825553894 	D(fake) 1.085487723350525 	 G:  3.297218 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 11.982192 	D(real) 0.4121522605419159 	D(fake) 1.08562171459198 	 G:  3.2966676 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 11.982719 	D(real) 0.4120834469795227 	D(fake) 1.0857564210891724 	 G:  3.2961156 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 11.983249 	D(real) 0.4120144546031952 	D(fake) 1.085891604423523 	 G:  3.295563 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 11.983776 	D(real) 0.4119453728199005 	D(fake) 1.086026668548584 	 G:  3.295013 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 11.984306 	D(real) 0.4118766188621521 	D(fake) 1.0861616134643555 	 G:  3.2944624 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 11.98483 	D(real) 0.4118078052997589 	D(fake) 1.0862959623336792 	 G:  3.293917 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 11.98356 	D(real) 0.41173961758613586 	D(fake) 1.0862053632736206 	 G:  3.2938619 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 11.983608 	D(real) 0.4117327332496643 	D(fake) 1.086218237876892 	 G:  3.2938082 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 11.983659 	D(real) 0.4117260277271271 	D(fake) 1.0862313508987427 	 G:  3.2937543 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 11.983712 	D(real) 0.41171929240226746 	D(fake) 1.0862447023391724 	 G:  3.2937012 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 11.983766 	D(real) 0.411712646484375 	D(fake) 1.086258053779602 	 G:  3.2936473 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 11.983814 	D(real) 0.4117059111595154 	D(fake) 1.0862709283828735 	 G:  3.2935941 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 11.983866 	D(real) 0.4116992652416229 	D(fake) 1.0862839221954346 	 G:  3.2935407 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 11.983918 	D(real) 0.4116925895214081 	D(fake) 1.0862971544265747 	 G:  3.2934873 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 11.98397 	D(real) 0.41168591380119324 	D(fake) 1.0863102674484253 	 G:  3.2934341 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 11.984017 	D(real) 0.4116792678833008 	D(fake) 1.0863229036331177 	 G:  3.2933812 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 11.983894 	D(real) 0.4116726517677307 	D(fake) 1.086314082145691 	 G:  3.2933767 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 11.983899 	D(real) 0.41167208552360535 	D(fake) 1.0863152742385864 	 G:  3.2933714 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 11.983905 	D(real) 0.4116714298725128 	D(fake) 1.086316704750061 	 G:  3.2933657 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 11.983909 	D(real) 0.4116707146167755 	D(fake) 1.0863178968429565 	 G:  3.2933612 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 11.983913 	D(real) 0.41167014837265015 	D(fake) 1.086319088935852 	 G:  3.2933557 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 11.983919 	D(real) 0.41166946291923523 	D(fake) 1.086320400238037 	 G:  3.2933505 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 11.983925 	D(real) 0.4116688072681427 	D(fake) 1.0863218307495117 	 G:  3.293346 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 11.983929 	D(real) 0.41166824102401733 	D(fake) 1.0863229036331177 	 G:  3.2933393 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 11.9839325 	D(real) 0.4116674065589905 	D(fake) 1.0863242149353027 	 G:  3.2933347 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 11.983939 	D(real) 0.4116668403148651 	D(fake) 1.0863255262374878 	 G:  3.2933295 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 17}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 17
\seed data:	 17
\seed noise:	 17
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018789 	loss:  -2.3702111 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018302 	loss:  3.3807125 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017051 	loss:  6.849594 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017235 	loss:  9.307453 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017779 	loss:  9.307377 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017002 	loss:  9.307189 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017595 	loss:  9.307316 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017830 	loss:  7.8356175 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017420 	loss:  -0.5062379 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017265 	loss:  -3.7397215 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017090 	loss:  2.8322778 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017544 	loss:  5.6976833 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017594 	loss:  7.078091 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017796 	loss:  7.208859 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.016981 	loss:  6.805754 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017137 	loss:  6.691465 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017978 	loss:  6.6049743 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017474 	loss:  6.6049724 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017154 	loss:  6.6906853 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017005 	loss:  6.653644 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017117 	loss:  6.6906815 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017184 	loss:  6.711041 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017190 	loss:  6.6049633 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017423 	loss:  6.604962 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017519 	loss:  6.6906753 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017383 	loss:  6.60496 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017205 	loss:  6.6049595 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017318 	loss:  6.867273 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017983 	loss:  6.867273 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018043 	loss:  7.034305 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017366 	loss:  7.1771617 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017233 	loss:  7.146781 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017161 	loss:  7.2309437 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017118 	loss:  7.1310725 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017757 	loss:  7.2914476 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017318 	loss:  7.1719904 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.029331 	loss:  7.304311 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.022328 	loss:  7.2309437 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017937 	loss:  7.304311 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017654 	loss:  7.2057333 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017840 	loss:  7.1771617 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018074 	loss:  7.232495 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017684 	loss:  7.1295214 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018476 	loss:  7.304311 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017891 	loss:  7.2057333 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018226 	loss:  7.2453585 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018196 	loss:  7.1771617 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018351 	loss:  7.232495 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017605 	loss:  7.1771617 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017758 	loss:  7.2057333 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.310590
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_17/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 13.0725975 	D(real) 0.4917611394609724 	D(fake) 1.3757527215140206 	 G:  2.5105639 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 11.371428 	D(real) 0.3587320191519601 	D(fake) 1.2657575607299805 	 G:  2.588786 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 10.90831 	D(real) 0.36984358515058247 	D(fake) 1.1884863717215401 	 G:  2.849472 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 10.531078 	D(real) 0.4071223054613386 	D(fake) 1.0973174912588937 	 G:  3.0905304 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 10.387068 	D(real) 0.44152726445879253 	D(fake) 1.042339597429548 	 G:  3.1990547 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 10.397328 	D(real) 0.4570169448852539 	D(fake) 1.0283156803676061 	 G:  3.1734784 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 10.483443 	D(real) 0.45335446085248676 	D(fake) 1.0442802565438407 	 G:  3.0615718 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 10.592493 	D(real) 0.4373704024723598 	D(fake) 1.0758428573608398 	 G:  2.9251344 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 10.687643 	D(real) 0.41787818499973844 	D(fake) 1.1089279992239816 	 G:  2.811228 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 10.746193 	D(real) 0.401604379926409 	D(fake) 1.133565970829555 	 G:  2.7424796 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 10.641968 	D(real) 0.3917830671582903 	D(fake) 1.1284980773925781 	 G:  2.739554 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 10.642531 	D(real) 0.39136522156851633 	D(fake) 1.1289964403424944 	 G:  2.7387402 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 10.641385 	D(real) 0.3912492479596819 	D(fake) 1.1289486203874861 	 G:  2.7395556 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 10.638932 	D(real) 0.3913654259272984 	D(fake) 1.1284820692879813 	 G:  2.7416146 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 10.635503 	D(real) 0.3916593279157366 	D(fake) 1.1276982171194894 	 G:  2.7446117 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 10.63135 	D(real) 0.392087527683803 	D(fake) 1.1266766956874303 	 G:  2.7483075 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 10.626688 	D(real) 0.3926155226571219 	D(fake) 1.1254826954432897 	 G:  2.7525043 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 10.621689 	D(real) 0.3932150772639683 	D(fake) 1.124169077192034 	 G:  2.7570446 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 10.616496 	D(real) 0.3938635417393276 	D(fake) 1.1227787562779017 	 G:  2.7617977 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 10.61122 	D(real) 0.3945425237928118 	D(fake) 1.1213460649762834 	 G:  2.7666585 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 10.602733 	D(real) 0.3952369349343436 	D(fake) 1.1194391250610352 	 G:  2.7671466 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 10.602213 	D(real) 0.3953066553388323 	D(fake) 1.119295256478446 	 G:  2.7676332 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 10.601698 	D(real) 0.3953761713845389 	D(fake) 1.1191520690917969 	 G:  2.7681174 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 10.601185 	D(real) 0.3954453468322754 	D(fake) 1.119009562901088 	 G:  2.7685995 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 10.600676 	D(real) 0.3955142157418387 	D(fake) 1.1188679422651018 	 G:  2.769079 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 10.600167 	D(real) 0.39558270999363493 	D(fake) 1.1187268665858678 	 G:  2.7695572 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 10.599664 	D(real) 0.395651033946446 	D(fake) 1.118586608341762 	 G:  2.7700317 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 10.599163 	D(real) 0.3957188129425049 	D(fake) 1.1184473037719727 	 G:  2.770504 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 10.598664 	D(real) 0.3957862854003906 	D(fake) 1.1183086122785295 	 G:  2.7709744 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 10.598169 	D(real) 0.3958534853799002 	D(fake) 1.1181707382202148 	 G:  2.771442 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 10.597338 	D(real) 0.3959202766418457 	D(fake) 1.1179850442068917 	 G:  2.7714884 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 10.597289 	D(real) 0.3959269183022635 	D(fake) 1.11797148840768 	 G:  2.7715342 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 10.59724 	D(real) 0.3959334577832903 	D(fake) 1.1179580688476562 	 G:  2.7715802 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 10.597193 	D(real) 0.3959400313241141 	D(fake) 1.1179445811680384 	 G:  2.7716265 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 10.597143 	D(real) 0.39594667298453196 	D(fake) 1.1179309572492326 	 G:  2.771672 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 10.597097 	D(real) 0.3959531443459647 	D(fake) 1.117917878287179 	 G:  2.771717 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 10.597046 	D(real) 0.3959595816476004 	D(fake) 1.1179041862487793 	 G:  2.7717628 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 10.596999 	D(real) 0.3959661211286272 	D(fake) 1.1178909029279436 	 G:  2.7718081 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 10.596951 	D(real) 0.39597259249006 	D(fake) 1.1178775514875139 	 G:  2.7718542 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 10.596903 	D(real) 0.3959791660308838 	D(fake) 1.1178641319274902 	 G:  2.7718995 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 10.596821 	D(real) 0.39598563739231657 	D(fake) 1.1178459439958846 	 G:  2.771904 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 10.596815 	D(real) 0.3959862845284598 	D(fake) 1.11784451348441 	 G:  2.7719078 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 10.596809 	D(real) 0.3959868294852121 	D(fake) 1.1178431510925293 	 G:  2.7719128 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 10.596805 	D(real) 0.3959875447409494 	D(fake) 1.1178417205810547 	 G:  2.7719176 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 10.5968 	D(real) 0.39598822593688965 	D(fake) 1.117840358189174 	 G:  2.7719223 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 10.596795 	D(real) 0.3959889071328299 	D(fake) 1.1178389957972936 	 G:  2.7719269 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 10.596789 	D(real) 0.3959895542689732 	D(fake) 1.1178374971662248 	 G:  2.7719314 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 10.596785 	D(real) 0.3959902014051165 	D(fake) 1.1178361347743444 	 G:  2.771936 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 10.596781 	D(real) 0.39599084854125977 	D(fake) 1.1178349767412459 	 G:  2.7719405 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 10.596776 	D(real) 0.39599149567740305 	D(fake) 1.1178336824689592 	 G:  2.7719455 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 18}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 18
\seed data:	 18
\seed noise:	 18
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018401 	loss:  0.16084608 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018113 	loss:  -1.1193358 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017808 	loss:  7.6804676 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017741 	loss:  8.240531 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018402 	loss:  8.240456 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.018034 	loss:  5.120422 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017541 	loss:  3.3604612 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017617 	loss:  6.2404637 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017688 	loss:  7.760432 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018372 	loss:  7.7604027 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017273 	loss:  8.240343 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017532 	loss:  8.240357 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.018105 	loss:  8.240856 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017825 	loss:  8.240402 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017843 	loss:  6.400426 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018756 	loss:  6.800436 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017770 	loss:  6.8004365 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017345 	loss:  6.8004365 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017541 	loss:  6.9339447 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017965 	loss:  6.597317 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017332 	loss:  5.907964 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017869 	loss:  6.1604314 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017791 	loss:  6.1604295 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017635 	loss:  6.0310755 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017550 	loss:  6.072113 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017746 	loss:  5.9204245 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017744 	loss:  5.760423 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017753 	loss:  5.9204216 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017534 	loss:  6.0310674 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017539 	loss:  6.244575 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017242 	loss:  6.3204184 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017293 	loss:  6.7287307 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017414 	loss:  6.724574 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017505 	loss:  6.2362614 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017771 	loss:  6.1624956 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017539 	loss:  6.4804177 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017837 	loss:  6.320418 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017097 	loss:  6.1624956 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017203 	loss:  6.328731 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.021073 	loss:  6.8373003 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017302 	loss:  6.2424955 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017226 	loss:  6.166653 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.016838 	loss:  6.482496 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017420 	loss:  6.3287306 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017183 	loss:  6.0804176 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017449 	loss:  6.000417 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017292 	loss:  6.400418 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017092 	loss:  6.7287297 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017465 	loss:  6.4045744 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.016978 	loss:  6.560417 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.697032
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_18/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 10.063477 	D(real) 0.6486377239227294 	D(fake) 1.3640576362609864 	 G:  2.161107 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 8.331692 	D(real) 0.4331214904785156 	D(fake) 1.2332169532775878 	 G:  1.8920306 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 7.805177 	D(real) 0.3783320665359497 	D(fake) 1.182703399658203 	 G:  2.140138 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 7.4707484 	D(real) 0.4279471397399902 	D(fake) 1.0662025451660155 	 G:  2.3371277 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 7.369237 	D(real) 0.46739988327026366 	D(fake) 1.0064475059509277 	 G:  2.405519 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 7.3776464 	D(real) 0.48111920356750487 	D(fake) 0.9944101333618164 	 G:  2.3807998 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 7.4494867 	D(real) 0.47620763778686526 	D(fake) 1.0136897087097168 	 G:  2.2758074 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 7.561973 	D(real) 0.4551889419555664 	D(fake) 1.0572056770324707 	 G:  2.1285982 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 7.6725607 	D(real) 0.4257413387298584 	D(fake) 1.108770751953125 	 G:  1.9961058 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 7.753504 	D(real) 0.399234676361084 	D(fake) 1.1514660835266113 	 G:  1.9067754 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 7.664866 	D(real) 0.3813616752624512 	D(fake) 1.1516115188598632 	 G:  1.9022379 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 7.6663413 	D(real) 0.3804559946060181 	D(fake) 1.1528122901916504 	 G:  1.9007659 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 7.665088 	D(real) 0.3801609992980957 	D(fake) 1.1528566360473633 	 G:  1.9016836 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 7.6617365 	D(real) 0.380342698097229 	D(fake) 1.1520046234130858 	 G:  1.9044465 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 7.656753 	D(real) 0.3808949708938599 	D(fake) 1.1504556655883789 	 G:  1.9086423 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 7.6505914 	D(real) 0.3817324638366699 	D(fake) 1.1483858108520508 	 G:  1.9139051 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 7.6435757 	D(real) 0.382785439491272 	D(fake) 1.145929718017578 	 G:  1.9199592 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 7.635997 	D(real) 0.3839963436126709 	D(fake) 1.1432029724121093 	 G:  1.9265628 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 7.628078 	D(real) 0.38531768321990967 	D(fake) 1.1402978897094727 	 G:  1.9335247 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 7.620027 	D(real) 0.3867097616195679 	D(fake) 1.137295627593994 	 G:  1.9406718 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 7.611744 	D(real) 0.3881393909454346 	D(fake) 1.134209442138672 	 G:  1.9413874 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 7.6109314 	D(real) 0.38828339576721194 	D(fake) 1.1339029312133788 	 G:  1.9421145 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 7.6101303 	D(real) 0.3884275436401367 	D(fake) 1.133598518371582 	 G:  1.9428369 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 7.6093416 	D(real) 0.38857173919677734 	D(fake) 1.133296585083008 	 G:  1.9435537 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 7.6085424 	D(real) 0.3887157917022705 	D(fake) 1.1329927444458008 	 G:  1.9442751 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 7.607772 	D(real) 0.38885955810546874 	D(fake) 1.1326948165893556 	 G:  1.9449826 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 7.606972 	D(real) 0.3890029191970825 	D(fake) 1.1323915481567384 	 G:  1.9457024 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 7.6061983 	D(real) 0.3891458034515381 	D(fake) 1.1320938110351562 	 G:  1.9464098 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 7.6054134 	D(real) 0.38928813934326173 	D(fake) 1.131794548034668 	 G:  1.9471209 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 7.6046352 	D(real) 0.3894298791885376 	D(fake) 1.1314971923828125 	 G:  1.9478275 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 7.603811 	D(real) 0.3895709037780762 	D(fake) 1.1311912536621094 	 G:  1.9478991 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 7.603727 	D(real) 0.38958492279052737 	D(fake) 1.1311604499816894 	 G:  1.9479723 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 7.6036677 	D(real) 0.3895988702774048 	D(fake) 1.1311347007751464 	 G:  1.9480333 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 7.6036053 	D(real) 0.38961281776428225 	D(fake) 1.131108283996582 	 G:  1.9480963 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 7.6035156 	D(real) 0.3896266222000122 	D(fake) 1.1310765266418457 	 G:  1.9481721 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 7.603443 	D(real) 0.38964047431945803 	D(fake) 1.1310482025146484 	 G:  1.9482392 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 7.6033764 	D(real) 0.38965435028076173 	D(fake) 1.1310209274291991 	 G:  1.9483042 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 7.6032934 	D(real) 0.3896681308746338 	D(fake) 1.1309906005859376 	 G:  1.9483764 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 7.60321 	D(real) 0.38968188762664796 	D(fake) 1.1309600830078126 	 G:  1.9484494 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 7.6031256 	D(real) 0.3896956920623779 	D(fake) 1.1309293746948241 	 G:  1.9485227 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 7.603069 	D(real) 0.38970947265625 	D(fake) 1.1309042930603028 	 G:  1.948517 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 7.6030345 	D(real) 0.38971073627471925 	D(fake) 1.1308961868286134 	 G:  1.9485362 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 7.603035 	D(real) 0.38971216678619386 	D(fake) 1.1308948516845703 	 G:  1.9485394 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 7.6030273 	D(real) 0.3897135019302368 	D(fake) 1.130891990661621 	 G:  1.9485462 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 7.603031 	D(real) 0.3897148609161377 	D(fake) 1.1308913230895996 	 G:  1.9485477 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 7.6030316 	D(real) 0.38971624374389646 	D(fake) 1.1308900833129882 	 G:  1.9485507 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 7.6030016 	D(real) 0.38971762657165526 	D(fake) 1.130882740020752 	 G:  1.9485686 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 7.6030087 	D(real) 0.38971898555755613 	D(fake) 1.130882740020752 	 G:  1.9485679 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 7.602993 	D(real) 0.38972039222717286 	D(fake) 1.1308782577514649 	 G:  1.9485788 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 7.6029816 	D(real) 0.38972175121307373 	D(fake) 1.1308745384216308 	 G:  1.9485877 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 19}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 19
\seed data:	 19
\seed noise:	 19
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.019042 	loss:  2.6866474 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018690 	loss:  2.6007674 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017357 	loss:  8.343452 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017419 	loss:  9.372013 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017788 	loss:  7.971977 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017705 	loss:  6.6862164 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017789 	loss:  7.514661 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017561 	loss:  9.829045 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018171 	loss:  9.829439 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017507 	loss:  10.257565 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017749 	loss:  6.7720156 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017740 	loss:  4.5434794 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017716 	loss:  3.000619 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017911 	loss:  2.4863145 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017555 	loss:  3.5053616 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017279 	loss:  6.314845 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017280 	loss:  6.5148435 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017772 	loss:  6.6422496 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017803 	loss:  6.6425056 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017936 	loss:  6.7148376 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017565 	loss:  7.036296 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017647 	loss:  6.9769535 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018102 	loss:  7.3396363 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017726 	loss:  7.3280144 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017660 	loss:  7.664147 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018120 	loss:  7.8298845 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017724 	loss:  8.353402 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017387 	loss:  8.467178 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017548 	loss:  8.620636 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017202 	loss:  8.486245 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017560 	loss:  8.926129 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017495 	loss:  8.777905 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018035 	loss:  8.83841 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017570 	loss:  8.844293 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017483 	loss:  8.910937 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017384 	loss:  8.836793 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017357 	loss:  8.743386 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017597 	loss:  8.942611 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017883 	loss:  8.923824 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018066 	loss:  8.957025 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018482 	loss:  8.880249 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017921 	loss:  8.791092 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017784 	loss:  9.02548 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017874 	loss:  9.002598 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018110 	loss:  8.761472 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017345 	loss:  9.077498 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017469 	loss:  8.930523 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017999 	loss:  8.939121 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017800 	loss:  9.031169 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017588 	loss:  9.026649 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.160724
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_19/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 12.682268 	D(real) 0.5270216464996338 	D(fake) 1.2847309112548828 	 G:  2.8475125 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 10.499689 	D(real) 0.40678020886012484 	D(fake) 1.0931754112243652 	 G:  3.0756054 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 10.344212 	D(real) 0.43937226704188753 	D(fake) 1.03837217603411 	 G:  3.2352707 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 10.316897 	D(real) 0.462181636265346 	D(fake) 1.0116608483450753 	 G:  3.2746706 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 10.393667 	D(real) 0.4678100858415876 	D(fake) 1.0169995852879115 	 G:  3.1810584 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 10.523084 	D(real) 0.4544370174407959 	D(fake) 1.0488606180463518 	 G:  3.0137534 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 10.6563015 	D(real) 0.43053627014160156 	D(fake) 1.0917925834655762 	 G:  2.8473613 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 10.756968 	D(real) 0.40676590374537874 	D(fake) 1.129943779536656 	 G:  2.731568 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 10.803725 	D(real) 0.3902240140097482 	D(fake) 1.15316527230399 	 G:  2.6839976 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 10.791836 	D(real) 0.3834282330104283 	D(fake) 1.1582626615251814 	 G:  2.7009892 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 10.680187 	D(real) 0.3858556066240583 	D(fake) 1.139885493687221 	 G:  2.7057948 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 10.673275 	D(real) 0.3865421158926828 	D(fake) 1.138211386544364 	 G:  2.7118688 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 10.665438 	D(real) 0.38740982328142437 	D(fake) 1.1362242017473494 	 G:  2.7188337 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 10.657012 	D(real) 0.3884048121316092 	D(fake) 1.1340254374912806 	 G:  2.7263906 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 10.648267 	D(real) 0.3894843714577811 	D(fake) 1.1316965648106165 	 G:  2.734303 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 10.639412 	D(real) 0.3906147139413016 	D(fake) 1.1293013436453683 	 G:  2.7423768 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 10.630622 	D(real) 0.39176811490740093 	D(fake) 1.126892157963344 	 G:  2.7504568 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 10.622028 	D(real) 0.39292240142822266 	D(fake) 1.1245102201189314 	 G:  2.7584167 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 10.613737 	D(real) 0.39405952181134907 	D(fake) 1.1221885681152344 	 G:  2.7661545 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 10.605826 	D(real) 0.3951649325234549 	D(fake) 1.1199530873979842 	 G:  2.77359 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 10.595361 	D(real) 0.39622715541294645 	D(fake) 1.1173958097185408 	 G:  2.7742958 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 10.594648 	D(real) 0.3963279724121094 	D(fake) 1.1171932901654924 	 G:  2.7749681 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 10.593966 	D(real) 0.39642402103969027 	D(fake) 1.116999694279262 	 G:  2.775612 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 10.593311 	D(real) 0.3965160165514265 	D(fake) 1.116814136505127 	 G:  2.776233 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 10.592677 	D(real) 0.39660470826285227 	D(fake) 1.1166348457336426 	 G:  2.776834 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 10.59206 	D(real) 0.3966905730111258 	D(fake) 1.1164608682904924 	 G:  2.777418 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 10.591461 	D(real) 0.3967739854540144 	D(fake) 1.1162919316973006 	 G:  2.777987 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 10.590876 	D(real) 0.396855286189488 	D(fake) 1.1161270141601562 	 G:  2.778543 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 10.590303 	D(real) 0.3969347136361258 	D(fake) 1.1159657069614954 	 G:  2.779088 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 10.589737 	D(real) 0.397012574332101 	D(fake) 1.115807056427002 	 G:  2.7796235 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 10.58872 	D(real) 0.3970890726361956 	D(fake) 1.1155852590288435 	 G:  2.7796762 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 10.588664 	D(real) 0.3970965998513358 	D(fake) 1.1155696596418108 	 G:  2.7797282 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 10.588612 	D(real) 0.39710402488708496 	D(fake) 1.1155547414507185 	 G:  2.7797797 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 10.588557 	D(real) 0.39711138180324007 	D(fake) 1.115539618900844 	 G:  2.7798302 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 10.588504 	D(real) 0.3971186024802072 	D(fake) 1.1155247688293457 	 G:  2.7798805 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 10.588451 	D(real) 0.3971257890973772 	D(fake) 1.1155100549970354 	 G:  2.7799315 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 10.588401 	D(real) 0.3971330778939383 	D(fake) 1.1154956136431013 	 G:  2.7799814 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 10.588347 	D(real) 0.3971401963915144 	D(fake) 1.115480831691197 	 G:  2.7800307 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 10.588294 	D(real) 0.39714724676949636 	D(fake) 1.1154661859784807 	 G:  2.7800806 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 10.588243 	D(real) 0.39715436526707243 	D(fake) 1.1154517446245467 	 G:  2.7801294 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 10.588142 	D(real) 0.3971613475254604 	D(fake) 1.1154304231916154 	 G:  2.7801347 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 10.588137 	D(real) 0.3971620968409947 	D(fake) 1.1154289245605469 	 G:  2.7801394 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 10.588132 	D(real) 0.397162778036935 	D(fake) 1.1154274940490723 	 G:  2.7801447 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 10.588127 	D(real) 0.39716345923287527 	D(fake) 1.1154260635375977 	 G:  2.780149 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 10.588121 	D(real) 0.3971641404288156 	D(fake) 1.115424633026123 	 G:  2.7801538 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 10.588116 	D(real) 0.39716482162475586 	D(fake) 1.1154232025146484 	 G:  2.7801588 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 10.588112 	D(real) 0.39716553688049316 	D(fake) 1.1154218401227678 	 G:  2.7801638 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 10.588106 	D(real) 0.39716625213623047 	D(fake) 1.1154204096112932 	 G:  2.7801688 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 10.588101 	D(real) 0.3971669673919678 	D(fake) 1.1154189109802246 	 G:  2.7801733 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 10.588096 	D(real) 0.39716761452811106 	D(fake) 1.11541748046875 	 G:  2.7801783 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 20}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 20
\seed data:	 20
\seed noise:	 20
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018199 	loss:  4.3440833 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017743 	loss:  6.0582113 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017378 	loss:  9.857972 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017661 	loss:  11.343463 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017723 	loss:  11.34336 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017704 	loss:  11.572341 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018238 	loss:  11.572249 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017600 	loss:  11.429465 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017965 	loss:  11.429468 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017726 	loss:  11.572249 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018341 	loss:  11.572207 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017401 	loss:  11.572192 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017637 	loss:  11.571976 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017907 	loss:  11.572401 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017605 	loss:  11.571628 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017807 	loss:  11.571942 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017409 	loss:  11.571933 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017485 	loss:  11.571887 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017536 	loss:  11.571812 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017685 	loss:  11.571719 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017823 	loss:  11.571634 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017388 	loss:  11.571584 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017378 	loss:  11.571573 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017912 	loss:  11.5715885 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018064 	loss:  11.571608 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018126 	loss:  11.571625 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017557 	loss:  11.571639 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017560 	loss:  11.571648 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017785 	loss:  11.571644 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017191 	loss:  11.5716305 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017552 	loss:  11.571612 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017933 	loss:  11.57161 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017329 	loss:  11.571608 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017409 	loss:  11.571605 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017784 	loss:  11.571603 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017540 	loss:  11.5716 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017618 	loss:  11.571597 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017741 	loss:  11.571594 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017397 	loss:  11.571591 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017366 	loss:  11.5715885 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017454 	loss:  11.571586 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017683 	loss:  11.571583 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017966 	loss:  11.571581 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017818 	loss:  11.571579 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017229 	loss:  11.571576 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017130 	loss:  11.571574 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017479 	loss:  11.571574 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017413 	loss:  11.571573 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017103 	loss:  11.571573 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017049 	loss:  11.571573 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.197769
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_20/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 11.529469 	D(real) 0.7233054297310966 	D(fake) 0.9237615721566337 	 G:  5.9417825 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 10.599882 	D(real) 0.85250152860369 	D(fake) 0.6617672783987862 	 G:  4.1679554 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 10.999046 	D(real) 0.5954438618251255 	D(fake) 0.9758485385349819 	 G:  3.244542 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 10.923285 	D(real) 0.4635816642216274 	D(fake) 1.0968875885009766 	 G:  3.278139 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 10.723177 	D(real) 0.4683008534567697 	D(fake) 1.0635816029139928 	 G:  3.0781233 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 12.364754 	D(real) 0.373253447668893 	D(fake) 1.3931399754115514 	 G:  2.085744 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 12.063753 	D(real) 0.29686416898454937 	D(fake) 1.4265292031424386 	 G:  2.2792473 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 11.072862 	D(real) 0.32571271487644743 	D(fake) 1.256124632699149 	 G:  2.8343825 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 10.347557 	D(real) 0.40457453046526226 	D(fake) 1.073647907802037 	 G:  3.2990558 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 9.860483 	D(real) 0.47133139201572966 	D(fake) 0.9373089926583427 	 G:  3.7165933 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 10.0710125 	D(real) 0.494680574962071 	D(fake) 0.944035530090332 	 G:  3.4529967 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 9.784811 	D(real) 0.4933264596121652 	D(fake) 0.904503617967878 	 G:  3.681538 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 10.1261425 	D(real) 0.4887617656162807 	D(fake) 0.9578300884791783 	 G:  3.3739123 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 10.137802 	D(real) 0.481956992830549 	D(fake) 0.9663004193987165 	 G:  3.3339677 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 10.202702 	D(real) 0.4740751470838274 	D(fake) 0.9834536143711635 	 G:  3.2592492 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 10.241334 	D(real) 0.46563356263296946 	D(fake) 0.9974141802106585 	 G:  3.201108 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 10.280088 	D(real) 0.4570272309439523 	D(fake) 1.011556761605399 	 G:  3.1446 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 10.331554 	D(real) 0.44858254705156597 	D(fake) 1.0273538316999162 	 G:  3.0836673 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 10.373785 	D(real) 0.44053397859845844 	D(fake) 1.041435377938407 	 G:  3.0313423 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 10.049963 	D(real) 0.4330484526497977 	D(fake) 1.0026606151035853 	 G:  3.2511573 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 10.401309 	D(real) 0.42579950605119976 	D(fake) 1.0601017815726144 	 G:  2.975667 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 10.398768 	D(real) 0.4251117706298828 	D(fake) 1.0604265757969447 	 G:  2.9747179 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 10.408328 	D(real) 0.42449685505458284 	D(fake) 1.0624071529933385 	 G:  2.967573 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 10.403299 	D(real) 0.4239422934395926 	D(fake) 1.0622433934892928 	 G:  2.9683728 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 10.412972 	D(real) 0.42343837874276297 	D(fake) 1.064129148210798 	 G:  2.9615257 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 10.415939 	D(real) 0.4229766981942313 	D(fake) 1.0650145666939872 	 G:  2.9583797 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 10.40427 	D(real) 0.4225499629974365 	D(fake) 1.0637743813650948 	 G:  2.9631462 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 10.093763 	D(real) 0.4221535750797817 	D(fake) 1.0198126520429338 	 G:  3.1807995 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 10.05881 	D(real) 0.4217146805354527 	D(fake) 1.0152582441057478 	 G:  3.2126997 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 10.428876 	D(real) 0.4212024211883545 	D(fake) 1.0686370304652624 	 G:  2.9448333 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 10.403958 	D(real) 0.4206984043121338 	D(fake) 1.0655813217163086 	 G:  2.9569275 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 10.427475 	D(real) 0.42065303666251047 	D(fake) 1.068986211504255 	 G:  2.9442537 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 10.427009 	D(real) 0.42061165400913786 	D(fake) 1.0689610072544642 	 G:  2.9443564 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 10.428099 	D(real) 0.4205736092158726 	D(fake) 1.0691548074994768 	 G:  2.9436567 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 10.428095 	D(real) 0.4205380848475865 	D(fake) 1.0691898209708077 	 G:  2.9435356 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 10.415623 	D(real) 0.4205046721867153 	D(fake) 1.067441395350865 	 G:  2.9499729 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 10.426222 	D(real) 0.4204730987548828 	D(fake) 1.0689871651785714 	 G:  2.9442897 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 10.428675 	D(real) 0.42044288771493094 	D(fake) 1.0693677493504115 	 G:  2.9428988 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 10.428852 	D(real) 0.42041380064828054 	D(fake) 1.0694221769060408 	 G:  2.9427032 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 9.7775135 	D(real) 0.4203857013157436 	D(fake) 0.9764018739972796 	 G:  3.3981302 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 10.047559 	D(real) 0.4203474521636963 	D(fake) 1.0150181225367956 	 G:  3.2202828 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 10.247326 	D(real) 0.4203425816127232 	D(fake) 1.0435611861092704 	 G:  3.0523012 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 10.407888 	D(real) 0.4203372001647949 	D(fake) 1.0665039334978377 	 G:  2.9535482 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 10.428171 	D(real) 0.42033181871686665 	D(fake) 1.0694069181169783 	 G:  2.942752 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 10.24611 	D(real) 0.4203270162854876 	D(fake) 1.043403012411935 	 G:  3.053086 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 10.116522 	D(real) 0.4203221457345145 	D(fake) 1.024895259312221 	 G:  3.1550927 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 10.428655 	D(real) 0.4203167302267892 	D(fake) 1.0694911139351981 	 G:  2.942442 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 10.178445 	D(real) 0.420311519077846 	D(fake) 1.0337520326886858 	 G:  3.1033702 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 10.017757 	D(real) 0.4203061376299177 	D(fake) 1.0108021327427454 	 G:  3.2512913 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 10.421206 	D(real) 0.4203002452850342 	D(fake) 1.0684435708182198 	 G:  2.946298 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 21}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 21
\seed data:	 21
\seed noise:	 21
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.017807 	loss:  1.5093404 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017700 	loss:  4.160606 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018057 	loss:  6.4326525 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017271 	loss:  4.8004236 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017289 	loss:  4.8002934 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017328 	loss:  7.634538 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018096 	loss:  5.4861584 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017336 	loss:  4.5755663 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017884 	loss:  4.8903327 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017035 	loss:  4.389011 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017103 	loss:  4.0232787 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017102 	loss:  3.6118624 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017332 	loss:  2.3600605 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017033 	loss:  2.4232812 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017095 	loss:  1.6918474 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017122 	loss:  0.67395616 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017437 	loss:  0.6861348 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017892 	loss:  0.6404199 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017758 	loss:  0.640419 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017710 	loss:  0.465236 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017462 	loss:  0.46523494 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017581 	loss:  0.41184452 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017503 	loss:  0.46523303 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.016969 	loss:  0.46523228 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018023 	loss:  0.5032708 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017004 	loss:  0.54387134 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017140 	loss:  0.77755564 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017741 	loss:  0.8232696 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017244 	loss:  1.1317579 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017525 	loss:  1.3261262 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017563 	loss:  1.6461258 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017118 	loss:  1.4632686 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017799 	loss:  1.5808915 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017057 	loss:  1.5594591 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017161 	loss:  1.5577004 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017519 	loss:  1.7153645 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017655 	loss:  1.4185551 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017027 	loss:  1.634614 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017109 	loss:  1.5808913 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017321 	loss:  1.5461885 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017102 	loss:  1.6461254 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017252 	loss:  1.7153642 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017297 	loss:  1.6269388 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017041 	loss:  1.3953642 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017285 	loss:  1.6948427 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017548 	loss:  1.5089822 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017287 	loss:  1.4746135 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018015 	loss:  1.5667094 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.016902 	loss:  1.4877934 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017399 	loss:  1.4902198 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.047403
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_21/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 10.273525 	D(real) 0.7856698036193848 	D(fake) 0.9265844027201334 	 G:  3.800981 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 8.813793 	D(real) 0.6339439551035563 	D(fake) 0.8350215752919515 	 G:  3.3700695 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 8.911218 	D(real) 0.5616691907246908 	D(fake) 0.9235337575276693 	 G:  2.9281952 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 9.182344 	D(real) 0.4880337715148926 	D(fake) 1.042357047398885 	 G:  2.5119104 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 9.449859 	D(real) 0.41865376631418866 	D(fake) 1.156322717666626 	 G:  2.2278166 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 9.620474 	D(real) 0.37130165100097656 	D(fake) 1.232110579808553 	 G:  2.089469 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 9.646992 	D(real) 0.34824379285176593 	D(fake) 1.2595881621042888 	 G:  2.0704787 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 9.546308 	D(real) 0.34507934252421063 	D(fake) 1.245971918106079 	 G:  2.1371622 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 9.373758 	D(real) 0.3561933437983195 	D(fake) 1.2060997486114502 	 G:  2.256581 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 9.189764 	D(real) 0.3760969638824463 	D(fake) 1.155530293782552 	 G:  2.3965282 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 9.059118 	D(real) 0.39942296346028644 	D(fake) 1.1104300022125244 	 G:  2.4093432 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 9.04792 	D(real) 0.4015578031539917 	D(fake) 1.1064289410909016 	 G:  2.4200363 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 9.038799 	D(real) 0.403339942296346 	D(fake) 1.1031266053517659 	 G:  2.4288647 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 9.031462 	D(real) 0.4048116207122803 	D(fake) 1.1004320780436199 	 G:  2.4360497 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 9.0256405 	D(real) 0.4060096740722656 	D(fake) 1.0982637405395508 	 G:  2.4417996 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 9.021151 	D(real) 0.4069677193959554 	D(fake) 1.0965574582417805 	 G:  2.4462788 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 9.017736 	D(real) 0.4077157179514567 	D(fake) 1.0952403545379639 	 G:  2.4496865 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 9.015316 	D(real) 0.4082813262939453 	D(fake) 1.0942714214324951 	 G:  2.452131 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 9.013691 	D(real) 0.40868961811065674 	D(fake) 1.0935921669006348 	 G:  2.453775 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 9.012751 	D(real) 0.4089633623758952 	D(fake) 1.0931618213653564 	 G:  2.4547331 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 9.003731 	D(real) 0.4091235399246216 	D(fake) 1.0914982159932454 	 G:  2.4547706 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 9.00374 	D(real) 0.40912993748982746 	D(fake) 1.0914934476216633 	 G:  2.4547617 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 9.003801 	D(real) 0.4091283480326335 	D(fake) 1.0915052096048992 	 G:  2.454707 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 9.003866 	D(real) 0.4091203212738037 	D(fake) 1.0915239651997883 	 G:  2.454635 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 9.0039625 	D(real) 0.4091072082519531 	D(fake) 1.0915532112121582 	 G:  2.4545333 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 9.004089 	D(real) 0.4090898434321086 	D(fake) 1.0915916760762532 	 G:  2.454407 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 9.004244 	D(real) 0.4090691804885864 	D(fake) 1.0916380882263184 	 G:  2.4542584 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 9.004372 	D(real) 0.40904585520426434 	D(fake) 1.09168275197347 	 G:  2.4541168 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 9.0045395 	D(real) 0.40902042388916016 	D(fake) 1.0917362372080486 	 G:  2.4539504 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 9.004696 	D(real) 0.40899332364400226 	D(fake) 1.0917892456054688 	 G:  2.453786 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 9.003816 	D(real) 0.4089649518330892 	D(fake) 1.0916709899902344 	 G:  2.453765 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 9.003835 	D(real) 0.4089619318644206 	D(fake) 1.091677188873291 	 G:  2.4537466 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 9.003852 	D(real) 0.4089589516321818 	D(fake) 1.091683069864909 	 G:  2.4537282 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 9.00386 	D(real) 0.4089558521906535 	D(fake) 1.0916875998179119 	 G:  2.4537144 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 9.003889 	D(real) 0.408952792485555 	D(fake) 1.0916954676310222 	 G:  2.4536905 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 9.003902 	D(real) 0.4089495340983073 	D(fake) 1.0917009512583415 	 G:  2.4536734 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 9.00393 	D(real) 0.40894627571105957 	D(fake) 1.091708739598592 	 G:  2.45365 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 9.003955 	D(real) 0.40894309679667157 	D(fake) 1.0917160511016846 	 G:  2.4536278 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 9.003971 	D(real) 0.40893983840942383 	D(fake) 1.091722011566162 	 G:  2.4536097 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 9.003981 	D(real) 0.4089365402857463 	D(fake) 1.0917269388834636 	 G:  2.4535947 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 9.003899 	D(real) 0.40893324216206867 	D(fake) 1.0917164484659831 	 G:  2.45359 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 9.003899 	D(real) 0.4089328447977702 	D(fake) 1.0917168458302815 	 G:  2.4535887 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 9.003896 	D(real) 0.40893256664276123 	D(fake) 1.0917166868845622 	 G:  2.4535892 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 9.003907 	D(real) 0.4089322090148926 	D(fake) 1.0917189915974934 	 G:  2.4535818 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 9.003901 	D(real) 0.4089318911234538 	D(fake) 1.0917181968688965 	 G:  2.4535844 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 9.0039215 	D(real) 0.40893157323201496 	D(fake) 1.0917220910390217 	 G:  2.4535728 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 9.003919 	D(real) 0.40893125534057617 	D(fake) 1.0917218526204426 	 G:  2.4535732 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 9.0039015 	D(real) 0.4089308977127075 	D(fake) 1.091719388961792 	 G:  2.453581 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 9.003915 	D(real) 0.40893057982126874 	D(fake) 1.0917219320933025 	 G:  2.453573 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 9.003917 	D(real) 0.4089302221934001 	D(fake) 1.09172256787618 	 G:  2.453571 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 22}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 22
\seed data:	 22
\seed noise:	 22
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018771 	loss:  -0.38558856 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018467 	loss:  -2.4523818 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018474 	loss:  5.480798 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017925 	loss:  9.974026 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018276 	loss:  10.187342 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.018260 	loss:  9.86728 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018246 	loss:  9.9470625 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.018735 	loss:  9.427333 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018480 	loss:  8.267373 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018192 	loss:  10.107394 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018166 	loss:  10.080727 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018433 	loss:  10.775054 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.018033 	loss:  11.000697 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018152 	loss:  11.027364 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018021 	loss:  10.934025 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018384 	loss:  10.960677 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018581 	loss:  10.960675 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018167 	loss:  10.934007 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018056 	loss:  10.96067 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017975 	loss:  11.027333 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018243 	loss:  10.973998 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018286 	loss:  10.973993 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018029 	loss:  10.973989 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018195 	loss:  10.973982 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018309 	loss:  10.973974 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018065 	loss:  10.973964 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018596 	loss:  10.97395 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018025 	loss:  10.973933 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.018241 	loss:  10.973911 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018373 	loss:  10.973882 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018340 	loss:  10.973844 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017895 	loss:  10.973839 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017876 	loss:  10.973834 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018043 	loss:  10.973828 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018811 	loss:  10.973823 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018494 	loss:  10.973816 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018328 	loss:  10.973809 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018296 	loss:  10.973803 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018169 	loss:  10.973795 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018073 	loss:  10.973787 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018334 	loss:  10.973779 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018590 	loss:  10.97377 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018046 	loss:  10.973762 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017992 	loss:  10.973752 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017825 	loss:  10.9737425 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017833 	loss:  10.973733 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017984 	loss:  10.973732 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018074 	loss:  10.973731 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017901 	loss:  10.97373 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.018301 	loss:  10.973729 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.212402
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_22/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 18.49098 	D(real) 0.5569571918911405 	D(fake) 1.4975961049397786 	 G:  3.4991426 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 13.912243 	D(real) 0.38899556795756024 	D(fake) 1.1568091710408528 	 G:  3.7615042 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 13.545253 	D(real) 0.41794578234354657 	D(fake) 1.0870823330349393 	 G:  3.955847 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 13.377154 	D(real) 0.43953853183322483 	D(fake) 1.0468119515313044 	 G:  4.0725665 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 13.347967 	D(real) 0.45250723097059464 	D(fake) 1.0306002298990886 	 G:  4.081041 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 13.400327 	D(real) 0.453451050652398 	D(fake) 1.035474141438802 	 G:  4.0109034 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 13.48493 	D(real) 0.4456557697719998 	D(fake) 1.052669843037923 	 G:  3.910255 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 13.576867 	D(real) 0.43447285228305393 	D(fake) 1.074067963494195 	 G:  3.8093817 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 13.664026 	D(real) 0.4232640266418457 	D(fake) 1.094961166381836 	 G:  3.7185574 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 13.737139 	D(real) 0.4131726688808865 	D(fake) 1.1131760279337566 	 G:  3.6425974 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 13.567841 	D(real) 0.40473326047261554 	D(fake) 1.1028046078152127 	 G:  3.6368737 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 13.571681 	D(real) 0.40409689479404026 	D(fake) 1.1038676367865667 	 G:  3.6326122 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 13.574352 	D(real) 0.40362321005927193 	D(fake) 1.104638205634223 	 G:  3.629599 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 13.576155 	D(real) 0.4032859802246094 	D(fake) 1.1051756540934246 	 G:  3.6275668 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 13.577115 	D(real) 0.4030628204345703 	D(fake) 1.105505519443088 	 G:  3.6264048 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 13.577388 	D(real) 0.40293431282043457 	D(fake) 1.1056643591986761 	 G:  3.6259544 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 13.577124 	D(real) 0.4028836356268989 	D(fake) 1.105685657925076 	 G:  3.6260684 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 13.576401 	D(real) 0.4028962983025445 	D(fake) 1.1055927276611328 	 G:  3.626648 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 13.575381 	D(real) 0.4029594792260064 	D(fake) 1.1054161919487848 	 G:  3.6275613 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 13.574001 	D(real) 0.4030620257059733 	D(fake) 1.105160289340549 	 G:  3.6287944 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 13.558813 	D(real) 0.40319432152642143 	D(fake) 1.10334046681722 	 G:  3.628885 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 13.55863 	D(real) 0.40320973926120335 	D(fake) 1.1033047570122614 	 G:  3.6290507 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 13.558476 	D(real) 0.40322671996222603 	D(fake) 1.1032706366644964 	 G:  3.6292078 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 13.558308 	D(real) 0.4032450252109104 	D(fake) 1.1032335493299696 	 G:  3.629377 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 13.558 	D(real) 0.40326423115200466 	D(fake) 1.103180143568251 	 G:  3.6296186 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 13.557913 	D(real) 0.403284231821696 	D(fake) 1.1031505796644423 	 G:  3.6297543 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 13.557739 	D(real) 0.4033048417833116 	D(fake) 1.103110631306966 	 G:  3.629934 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 13.55755 	D(real) 0.4033258491092258 	D(fake) 1.1030686696370442 	 G:  3.6301239 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 13.557343 	D(real) 0.4033471743265788 	D(fake) 1.103024164835612 	 G:  3.6303236 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 13.557025 	D(real) 0.4033687379625108 	D(fake) 1.1029673682318792 	 G:  3.630579 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 13.555632 	D(real) 0.40339043405320907 	D(fake) 1.1027908325195312 	 G:  3.6305342 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 13.555572 	D(real) 0.40339260631137425 	D(fake) 1.1027820375230577 	 G:  3.630573 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 13.555567 	D(real) 0.40339475207858616 	D(fake) 1.1027792824639215 	 G:  3.6305861 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 13.555575 	D(real) 0.40339695082770455 	D(fake) 1.1027781168619792 	 G:  3.6305914 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 13.555558 	D(real) 0.40339914957682294 	D(fake) 1.1027739842732747 	 G:  3.6306098 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 13.555511 	D(real) 0.40340129534403485 	D(fake) 1.1027666727701824 	 G:  3.6306422 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 13.555474 	D(real) 0.40340349409315324 	D(fake) 1.1027603149414062 	 G:  3.6306708 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 13.555435 	D(real) 0.40340569284227157 	D(fake) 1.1027537451850042 	 G:  3.6307 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 13.555449 	D(real) 0.4034078386094835 	D(fake) 1.1027531094021268 	 G:  3.6307025 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 13.555456 	D(real) 0.40341001086764866 	D(fake) 1.1027518378363714 	 G:  3.6307085 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 13.555274 	D(real) 0.4034121831258138 	D(fake) 1.1027293735080295 	 G:  3.6307254 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 13.555294 	D(real) 0.4034123950534397 	D(fake) 1.1027313868204753 	 G:  3.6307168 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 13.555288 	D(real) 0.4034126334720188 	D(fake) 1.1027305391099718 	 G:  3.6307197 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 13.555291 	D(real) 0.4034128453996446 	D(fake) 1.1027306450737848 	 G:  3.6307201 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 13.555273 	D(real) 0.4034130573272705 	D(fake) 1.102728419833713 	 G:  3.6307297 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 13.555293 	D(real) 0.40341324276394314 	D(fake) 1.102730433146159 	 G:  3.6307206 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 13.555282 	D(real) 0.40341345469156903 	D(fake) 1.1027289496527777 	 G:  3.6307278 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 13.555277 	D(real) 0.40341366661919487 	D(fake) 1.1027282079060872 	 G:  3.6307316 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 13.555266 	D(real) 0.40341390503777397 	D(fake) 1.1027268303765192 	 G:  3.6307368 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 13.55526 	D(real) 0.40341414345635307 	D(fake) 1.1027257707383897 	 G:  3.6307418 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 23}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 23
\seed data:	 23
\seed noise:	 23
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.017098 	loss:  0.000676707 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.016393 	loss:  1.6005123 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.016234 	loss:  4.8003325 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.016549 	loss:  2.4002407 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.016588 	loss:  1.6002918 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.016643 	loss:  3.2002258 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.015822 	loss:  3.2002156 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.015848 	loss:  3.200236 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.016503 	loss:  1.6002358 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.016033 	loss:  4.8002095 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.016648 	loss:  1.6002185 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.015962 	loss:  1.600218 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.016144 	loss:  1.6002126 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.016469 	loss:  0.00021360617 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.016692 	loss:  3.200201 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.016985 	loss:  4.800198 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.015925 	loss:  6.400192 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.016080 	loss:  6.4001913 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.016438 	loss:  6.4001904 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.015928 	loss:  6.4001894 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.016081 	loss:  6.4001884 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.016266 	loss:  6.400187 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.016921 	loss:  6.4001856 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.015800 	loss:  6.400184 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.015774 	loss:  6.4001827 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.016072 	loss:  8.0001745 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.016237 	loss:  8.000173 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.016379 	loss:  4.8001823 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.016287 	loss:  4.8001795 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.016700 	loss:  4.8001757 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.015817 	loss:  4.8001704 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.015720 	loss:  4.8001695 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.015914 	loss:  4.8001685 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.016551 	loss:  4.8001676 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.016490 	loss:  4.8001666 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.016069 	loss:  4.8001657 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.015992 	loss:  4.8001647 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.016018 	loss:  4.8001633 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.016416 	loss:  4.800162 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.015803 	loss:  4.80016 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.016379 	loss:  4.8001585 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.015765 	loss:  4.800157 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.015769 	loss:  4.800155 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.016242 	loss:  4.8001533 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.016430 	loss:  4.8001513 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017024 	loss:  4.8001494 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.016047 	loss:  4.8001494 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.016794 	loss:  4.800149 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.015692 	loss:  4.800149 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.016448 	loss:  4.800149 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.983218
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_23/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 3.1646242 	D(real) 0.6545753479003906 	D(fake) 0.927736759185791 	 G:  1.2267991 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 2.9016755 	D(real) 0.6134326457977295 	D(fake) 0.8374050855636597 	 G:  1.1377212 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 2.9531927 	D(real) 0.5688608288764954 	D(fake) 0.9077355861663818 	 G:  1.0058639 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 3.023767 	D(real) 0.502932071685791 	D(fake) 1.0089514255523682 	 G:  0.8933174 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 3.0783777 	D(real) 0.4466587007045746 	D(fake) 1.0925301313400269 	 G:  0.8246393 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 3.0989466 	D(real) 0.4123196601867676 	D(fake) 1.1371536254882812 	 G:  0.8000856 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 3.0837154 	D(real) 0.4000428020954132 	D(fake) 1.141814947128296 	 G:  0.8096343 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 3.052703 	D(real) 0.4048171639442444 	D(fake) 1.1215343475341797 	 G:  0.83203423 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 3.0292163 	D(real) 0.4160171151161194 	D(fake) 1.0985910892486572 	 G:  0.84783095 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 3.0223117 	D(real) 0.42391547560691833 	D(fake) 1.0872403383255005 	 G:  0.84899807 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 2.9779322 	D(real) 0.4244990348815918 	D(fake) 1.0644670724868774 	 G:  0.8479666 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 2.979568 	D(real) 0.42398330569267273 	D(fake) 1.065800666809082 	 G:  0.84608 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 2.9817512 	D(real) 0.4230400025844574 	D(fake) 1.0678355693817139 	 G:  0.8436037 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 2.9842987 	D(real) 0.4218018352985382 	D(fake) 1.070347547531128 	 G:  0.8407484 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 2.9870644 	D(real) 0.42037421464920044 	D(fake) 1.0731580257415771 	 G:  0.837682 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 2.9899328 	D(real) 0.41884100437164307 	D(fake) 1.0761253833770752 	 G:  0.8345352 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 2.9928079 	D(real) 0.4172675907611847 	D(fake) 1.0791363716125488 	 G:  0.83141124 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 2.9956193 	D(real) 0.4157056212425232 	D(fake) 1.082103967666626 	 G:  0.8283874 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 2.9983072 	D(real) 0.41419368982315063 	D(fake) 1.0849599838256836 	 G:  0.82552135 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 3.000832 	D(real) 0.4127606749534607 	D(fake) 1.0876553058624268 	 G:  0.8228533 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 2.9971154 	D(real) 0.4114266633987427 	D(fake) 1.0871310234069824 	 G:  0.82260907 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 2.9973307 	D(real) 0.4113045334815979 	D(fake) 1.0873607397079468 	 G:  0.82238394 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 2.9975297 	D(real) 0.4111919701099396 	D(fake) 1.0875729322433472 	 G:  0.82217497 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 2.9977171 	D(real) 0.4110874831676483 	D(fake) 1.0877710580825806 	 G:  0.8219795 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 2.9978938 	D(real) 0.41098976135253906 	D(fake) 1.0879571437835693 	 G:  0.8217956 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 2.9980617 	D(real) 0.41089779138565063 	D(fake) 1.0881329774856567 	 G:  0.8216212 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 2.9982212 	D(real) 0.41081058979034424 	D(fake) 1.0882999897003174 	 G:  0.82145524 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 2.9983742 	D(real) 0.4107276201248169 	D(fake) 1.0884594917297363 	 G:  0.82129616 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 2.9985223 	D(real) 0.41064807772636414 	D(fake) 1.0886130332946777 	 G:  0.8211432 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 2.9986649 	D(real) 0.4105716049671173 	D(fake) 1.0887608528137207 	 G:  0.8209957 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 2.9982958 	D(real) 0.41049784421920776 	D(fake) 1.088650107383728 	 G:  0.82098144 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 2.99831 	D(real) 0.4104907214641571 	D(fake) 1.0886642932891846 	 G:  0.82096744 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 2.9983227 	D(real) 0.410483717918396 	D(fake) 1.0886776447296143 	 G:  0.82095397 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 2.9983363 	D(real) 0.4104769825935364 	D(fake) 1.0886911153793335 	 G:  0.8209407 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 2.9983487 	D(real) 0.4104703366756439 	D(fake) 1.088703989982605 	 G:  0.82092756 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 2.9983613 	D(real) 0.41046378016471863 	D(fake) 1.0887168645858765 	 G:  0.8209146 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 2.9983735 	D(real) 0.4104573130607605 	D(fake) 1.0887295007705688 	 G:  0.8209017 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 2.9983857 	D(real) 0.41045084595680237 	D(fake) 1.0887420177459717 	 G:  0.8208891 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 2.9983978 	D(real) 0.41044455766677856 	D(fake) 1.088754415512085 	 G:  0.82087636 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 2.99841 	D(real) 0.4104381799697876 	D(fake) 1.0887668132781982 	 G:  0.82086414 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 2.9983735 	D(real) 0.4104320704936981 	D(fake) 1.088754653930664 	 G:  0.8208629 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 2.9983745 	D(real) 0.410431444644928 	D(fake) 1.0887558460235596 	 G:  0.8208616 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 2.998376 	D(real) 0.41043078899383545 	D(fake) 1.0887571573257446 	 G:  0.8208603 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 2.998377 	D(real) 0.4104301631450653 	D(fake) 1.0887583494186401 	 G:  0.8208591 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 2.9983778 	D(real) 0.41042953729629517 	D(fake) 1.088759422302246 	 G:  0.820858 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 2.998379 	D(real) 0.4104290008544922 	D(fake) 1.088760495185852 	 G:  0.8208566 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 2.99838 	D(real) 0.4104282855987549 	D(fake) 1.0887616872787476 	 G:  0.8208555 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 2.9983816 	D(real) 0.4104277491569519 	D(fake) 1.0887631177902222 	 G:  0.82085425 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 2.9983828 	D(real) 0.41042712330818176 	D(fake) 1.0887643098831177 	 G:  0.820853 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 2.9983838 	D(real) 0.4104264974594116 	D(fake) 1.0887653827667236 	 G:  0.82085174 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 24}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 24
\seed data:	 24
\seed noise:	 24
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018981 	loss:  -0.124873765 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018474 	loss:  8.97071 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018652 	loss:  10.143802 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018570 	loss:  9.503581 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018286 	loss:  9.688637 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.018230 	loss:  10.561003 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018953 	loss:  9.814181 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.018832 	loss:  9.556429 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018978 	loss:  1.8750254 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018597 	loss:  0.53244 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018600 	loss:  0.5565977 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.019061 	loss:  1.189978 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.018560 	loss:  2.622571 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018792 	loss:  5.0352387 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018597 	loss:  5.932971 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018889 	loss:  6.395642 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.019464 	loss:  6.492081 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018847 	loss:  6.45933 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018939 	loss:  6.6939874 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.018798 	loss:  6.501671 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.019342 	loss:  6.559415 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018464 	loss:  6.7388787 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018569 	loss:  6.8530664 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018798 	loss:  6.6053634 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018786 	loss:  6.544334 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018940 	loss:  6.7990174 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.019014 	loss:  6.768551 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018874 	loss:  6.940367 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.019003 	loss:  6.784536 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018727 	loss:  6.599633 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.019035 	loss:  6.9713664 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018298 	loss:  6.561394 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018591 	loss:  6.689578 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018700 	loss:  6.479393 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.019266 	loss:  6.585275 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018656 	loss:  6.7741485 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.019024 	loss:  6.626189 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018464 	loss:  6.5696692 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018580 	loss:  6.576824 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018969 	loss:  6.586008 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018858 	loss:  6.8019657 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018663 	loss:  6.426241 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018463 	loss:  6.9619827 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018415 	loss:  6.652658 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018821 	loss:  6.6085515 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.019140 	loss:  6.879953 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018733 	loss:  6.442861 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018500 	loss:  6.6102324 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018366 	loss:  6.752228 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.018292 	loss:  6.6809425 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.232767
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_24/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 17.22395 	D(real) 0.8076662063598633 	D(fake) 0.914728832244873 	 G:  5.698834 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 15.177559 	D(real) 0.5699367046356201 	D(fake) 0.9478191375732422 	 G:  4.9512095 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 14.932373 	D(real) 0.49512009620666503 	D(fake) 0.9981171607971191 	 G:  4.766581 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 15.129226 	D(real) 0.4766580581665039 	D(fake) 1.0362645149230958 	 G:  4.4352107 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 15.403332 	D(real) 0.44352107048034667 	D(fake) 1.0968121528625487 	 G:  4.084241 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 15.616432 	D(real) 0.40842409133911134 	D(fake) 1.1532191276550292 	 G:  3.836334 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 15.708806 	D(real) 0.3836333990097046 	D(fake) 1.1872471809387206 	 G:  3.7217114 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 15.674147 	D(real) 0.37217113971710203 	D(fake) 1.1952435493469238 	 G:  3.7236853 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 15.542122 	D(real) 0.37236852645874025 	D(fake) 1.1818436622619628 	 G:  3.8143725 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 15.35857 	D(real) 0.3814372539520264 	D(fake) 1.1544198036193847 	 G:  3.962076 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 15.139892 	D(real) 0.396207594871521 	D(fake) 1.1177815437316894 	 G:  3.9774184 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 15.124783 	D(real) 0.39774184226989745 	D(fake) 1.1147364616394042 	 G:  3.991399 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 15.11134 	D(real) 0.39913990497589114 	D(fake) 1.1119940757751465 	 G:  4.0040035 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 15.09949 	D(real) 0.40040035247802735 	D(fake) 1.1095486640930177 	 G:  4.015241 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 15.089146 	D(real) 0.40152411460876464 	D(fake) 1.1073904991149903 	 G:  4.0251474 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 15.080213 	D(real) 0.40251474380493163 	D(fake) 1.1055065155029298 	 G:  4.033778 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 15.072584 	D(real) 0.4033778190612793 	D(fake) 1.1038805961608886 	 G:  4.0411997 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 15.066153 	D(real) 0.40411996841430664 	D(fake) 1.102495288848877 	 G:  4.0474935 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 15.060825 	D(real) 0.40474934577941896 	D(fake) 1.101333236694336 	 G:  4.0527434 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 15.0564785 	D(real) 0.4052743434906006 	D(fake) 1.1003735542297364 	 G:  4.0570383 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 15.03985 	D(real) 0.40570383071899413 	D(fake) 1.098281192779541 	 G:  4.057383 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 15.039579 	D(real) 0.40573830604553224 	D(fake) 1.0982195854187011 	 G:  4.0576553 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 15.039364 	D(real) 0.4057655334472656 	D(fake) 1.098170852661133 	 G:  4.0578704 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 15.039194 	D(real) 0.4057870388031006 	D(fake) 1.0981324195861817 	 G:  4.0580387 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 15.039068 	D(real) 0.40580387115478517 	D(fake) 1.0981029510498046 	 G:  4.0581675 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 15.038968 	D(real) 0.40581674575805665 	D(fake) 1.0980800628662108 	 G:  4.058266 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 15.0389 	D(real) 0.40582661628723143 	D(fake) 1.0980633735656737 	 G:  4.058339 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 15.038849 	D(real) 0.40583391189575196 	D(fake) 1.0980509757995605 	 G:  4.0583897 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 15.038815 	D(real) 0.4058389663696289 	D(fake) 1.0980424880981445 	 G:  4.0584235 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 15.038794 	D(real) 0.40584235191345214 	D(fake) 1.098037052154541 	 G:  4.058444 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 15.037165 	D(real) 0.40584440231323243 	D(fake) 1.0978720664978028 	 G:  4.058444 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 15.037165 	D(real) 0.40584440231323243 	D(fake) 1.0978720664978028 	 G:  4.058444 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 15.037165 	D(real) 0.40584440231323243 	D(fake) 1.0978720664978028 	 G:  4.058444 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 15.03717 	D(real) 0.40584440231323243 	D(fake) 1.0978726387023925 	 G:  4.0584426 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 15.03717 	D(real) 0.40584425926208495 	D(fake) 1.097872829437256 	 G:  4.0584416 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 15.037172 	D(real) 0.40584416389465333 	D(fake) 1.0978730201721192 	 G:  4.0584393 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 15.037175 	D(real) 0.40584392547607423 	D(fake) 1.097873592376709 	 G:  4.058437 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 15.037178 	D(real) 0.40584368705749513 	D(fake) 1.097874069213867 	 G:  4.058433 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 15.03718 	D(real) 0.40584330558776854 	D(fake) 1.097874641418457 	 G:  4.0584297 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 15.037185 	D(real) 0.4058429718017578 	D(fake) 1.0978754997253417 	 G:  4.0584273 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 15.037022 	D(real) 0.4058427333831787 	D(fake) 1.0978594779968263 	 G:  4.0584273 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 15.037022 	D(real) 0.4058427333831787 	D(fake) 1.0978594779968263 	 G:  4.0584273 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 15.037022 	D(real) 0.4058427333831787 	D(fake) 1.0978594779968263 	 G:  4.058426 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 15.037021 	D(real) 0.40584259033203124 	D(fake) 1.0978594779968263 	 G:  4.0584254 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 15.037025 	D(real) 0.40584254264831543 	D(fake) 1.0978599548339845 	 G:  4.0584254 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 15.037025 	D(real) 0.40584254264831543 	D(fake) 1.0978599548339845 	 G:  4.058425 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 15.0370245 	D(real) 0.4058424949645996 	D(fake) 1.0978599548339845 	 G:  4.0584235 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 15.037024 	D(real) 0.40584235191345214 	D(fake) 1.097860050201416 	 G:  4.0584235 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 15.037024 	D(real) 0.40584235191345214 	D(fake) 1.097860050201416 	 G:  4.0584226 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 15.037024 	D(real) 0.4058422565460205 	D(fake) 1.097860050201416 	 G:  4.0584226 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 25}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 25
\seed data:	 25
\seed noise:	 25
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018174 	loss:  0.058304522 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018610 	loss:  7.734345 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018413 	loss:  11.886528 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018327 	loss:  11.82917 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018254 	loss:  11.828962 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.018105 	loss:  11.841801 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017957 	loss:  11.829539 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017731 	loss:  11.829462 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018016 	loss:  10.3436985 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017777 	loss:  6.019892 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017737 	loss:  4.6675415 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017957 	loss:  4.64853 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.018850 	loss:  1.6961787 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018378 	loss:  1.6413128 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018533 	loss:  0.98986644 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017966 	loss:  -1.7930658 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018667 	loss:  -1.7998737 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018010 	loss:  -1.893456 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018346 	loss:  -2.0747826 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.018242 	loss:  -1.9502183 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018325 	loss:  -1.8349136 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018089 	loss:  -1.67569 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017704 	loss:  -1.6205173 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018146 	loss:  -1.6329639 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017628 	loss:  -1.9954461 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017963 	loss:  -1.9837828 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018397 	loss:  -2.136579 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017748 	loss:  -2.1807747 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017838 	loss:  -1.836338 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017517 	loss:  -2.0533032 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017753 	loss:  -1.9073727 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018201 	loss:  -1.6567804 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018070 	loss:  -1.6059484 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018127 	loss:  -1.5435722 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017805 	loss:  -1.6299595 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018230 	loss:  -1.6179049 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017980 	loss:  -1.8228168 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018413 	loss:  -1.614045 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018315 	loss:  -1.5827 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018074 	loss:  -1.6853855 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018083 	loss:  -1.5816815 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017909 	loss:  -1.5680871 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017846 	loss:  -1.5178087 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018030 	loss:  -1.7990621 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017665 	loss:  -1.6298119 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017672 	loss:  -1.4648743 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017685 	loss:  -1.6340336 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018360 	loss:  -1.5856789 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017794 	loss:  -1.4637284 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.018143 	loss:  -1.6357328 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.965939
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_25/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 14.768288 	D(real) 0.8893073201179504 	D(fake) 0.9567285776138306 	 G:  4.7836833 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 11.612898 	D(real) 0.5994876623153687 	D(fake) 0.8521245718002319 	 G:  4.521488 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 11.7272625 	D(real) 0.5645895004272461 	D(fake) 0.901318371295929 	 G:  4.121363 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 12.01968 	D(real) 0.5148648619651794 	D(fake) 0.9875951409339905 	 G:  3.6181357 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 12.365284 	D(real) 0.45150843262672424 	D(fake) 1.0941520929336548 	 G:  3.1839485 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 12.651044 	D(real) 0.3963741064071655 	D(fake) 1.1850063800811768 	 G:  2.9117262 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 12.76726 	D(real) 0.36013442277908325 	D(fake) 1.2357730865478516 	 G:  2.8089087 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 12.675902 	D(real) 0.340932160615921 	D(fake) 1.2435556650161743 	 G:  2.8331544 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 12.538005 	D(real) 0.32394298911094666 	D(fake) 1.2433075904846191 	 G:  2.911376 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 11.864836 	D(real) 0.2900734841823578 	D(fake) 1.1930309534072876 	 G:  3.4346285 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 10.653864 	D(real) 0.2853059768676758 	D(fake) 1.0464270114898682 	 G:  3.5052423 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 10.501734 	D(real) 0.2825862467288971 	D(fake) 1.0301305055618286 	 G:  3.5760143 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 10.301952 	D(real) 0.27304837107658386 	D(fake) 1.014695644378662 	 G:  3.6444755 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 10.070936 	D(real) 0.25911712646484375 	D(fake) 0.9997499585151672 	 G:  3.7133472 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 9.824651 	D(real) 0.2435503751039505 	D(fake) 0.9845309257507324 	 G:  3.7897077 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 9.581747 	D(real) 0.2284780591726303 	D(fake) 0.9692403078079224 	 G:  3.8764791 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 9.326559 	D(real) 0.21536418795585632 	D(fake) 0.9504557251930237 	 G:  3.9908073 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 9.004433 	D(real) 0.20494048297405243 	D(fake) 0.9206135869026184 	 G:  4.161587 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 8.683809 	D(real) 0.19707942008972168 	D(fake) 0.8883967399597168 	 G:  4.3485804 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 8.365184 	D(real) 0.19121719896793365 	D(fake) 0.8544307351112366 	 G:  4.552263 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 8.151735 	D(real) 0.18675142526626587 	D(fake) 0.8322155475616455 	 G:  4.5807467 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 8.124014 	D(real) 0.18636944890022278 	D(fake) 0.8291322588920593 	 G:  4.600156 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 8.086454 	D(real) 0.1860077977180481 	D(fake) 0.8247990012168884 	 G:  4.627255 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 8.057015 	D(real) 0.18565775454044342 	D(fake) 0.8214691877365112 	 G:  4.6482816 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 8.023821 	D(real) 0.18531230092048645 	D(fake) 0.8176652789115906 	 G:  4.672347 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 7.992893 	D(real) 0.18496790528297424 	D(fake) 0.8141437768936157 	 G:  4.694758 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 7.956775 	D(real) 0.18462149798870087 	D(fake) 0.8099753856658936 	 G:  4.7213736 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 7.9232464 	D(real) 0.1842699497938156 	D(fake) 0.8061358332633972 	 G:  4.7460604 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 7.8925557 	D(real) 0.18390999734401703 	D(fake) 0.8026594519615173 	 G:  4.768567 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 7.86147 	D(real) 0.18354149162769318 	D(fake) 0.7991423010826111 	 G:  4.791477 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 7.8421516 	D(real) 0.1831653118133545 	D(fake) 0.7971036434173584 	 G:  4.7931876 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 7.8387103 	D(real) 0.18312698602676392 	D(fake) 0.796711802482605 	 G:  4.7957563 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 7.8373394 	D(real) 0.1830880343914032 	D(fake) 0.7965793609619141 	 G:  4.796625 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 7.828192 	D(real) 0.18304860591888428 	D(fake) 0.795475423336029 	 G:  4.803871 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 7.826455 	D(real) 0.1830085813999176 	D(fake) 0.7952983379364014 	 G:  4.8050346 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 7.8287272 	D(real) 0.1829679161310196 	D(fake) 0.7956230044364929 	 G:  4.8029037 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 7.819945 	D(real) 0.18292701244354248 	D(fake) 0.7945660948753357 	 G:  4.809854 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 7.8226514 	D(real) 0.18288590013980865 	D(fake) 0.7949455380439758 	 G:  4.807367 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 7.8169127 	D(real) 0.18284468352794647 	D(fake) 0.7942693829536438 	 G:  4.811812 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 7.811691 	D(real) 0.18280339241027832 	D(fake) 0.7936579585075378 	 G:  4.815842 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 7.8095064 	D(real) 0.18276193737983704 	D(fake) 0.7934263348579407 	 G:  4.8162365 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 7.813022 	D(real) 0.18275779485702515 	D(fake) 0.7938699722290039 	 G:  4.813311 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 7.8124948 	D(real) 0.18275360763072968 	D(fake) 0.7938082218170166 	 G:  4.8137174 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 7.8148336 	D(real) 0.1827494204044342 	D(fake) 0.7941047549247742 	 G:  4.8117623 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 7.8066096 	D(real) 0.1827452927827835 	D(fake) 0.7930809259414673 	 G:  4.8185186 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 7.808602 	D(real) 0.18274115025997162 	D(fake) 0.7933340668678284 	 G:  4.816848 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 7.8087177 	D(real) 0.18273700773715973 	D(fake) 0.7933527231216431 	 G:  4.8167233 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 7.8088183 	D(real) 0.18273277580738068 	D(fake) 0.7933695316314697 	 G:  4.8166137 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 7.809253 	D(real) 0.1827286034822464 	D(fake) 0.7934280633926392 	 G:  4.816227 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 7.8055706 	D(real) 0.18272437155246735 	D(fake) 0.7929719686508179 	 G:  4.819238 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 26}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 26
\seed data:	 26
\seed noise:	 26
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018952 	loss:  -0.6042756 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.020270 	loss:  -1.9782406 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.019275 	loss:  9.213611 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.019657 	loss:  8.9079485 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.020103 	loss:  10.333351 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.020236 	loss:  10.205906 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.019317 	loss:  10.334835 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.019984 	loss:  10.496925 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.019970 	loss:  9.231618 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.019642 	loss:  5.908037 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.019196 	loss:  2.9516582 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.019335 	loss:  1.6633952 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.019579 	loss:  3.6668727 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.020016 	loss:  4.9664435 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.020271 	loss:  4.5308237 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.020349 	loss:  5.278501 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.019309 	loss:  5.5190163 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.019971 	loss:  5.2020936 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.019216 	loss:  5.150397 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.019064 	loss:  5.2276416 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.019341 	loss:  5.001873 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.019074 	loss:  5.2531533 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.019363 	loss:  5.070592 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.020023 	loss:  5.3135705 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.019792 	loss:  5.4308257 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.019035 	loss:  5.449442 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.019177 	loss:  5.1158357 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.019001 	loss:  5.396309 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.019458 	loss:  5.2197747 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.019610 	loss:  5.2780766 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.019413 	loss:  5.1463017 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.020173 	loss:  5.15314 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.019510 	loss:  5.307712 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.019513 	loss:  5.286771 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.019567 	loss:  5.1723113 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.019276 	loss:  5.1705465 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.019296 	loss:  5.2201157 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.019046 	loss:  5.1891437 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018783 	loss:  5.1235385 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.019327 	loss:  5.0742183 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.019386 	loss:  5.3311253 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.019952 	loss:  5.146652 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.019170 	loss:  5.135835 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.019368 	loss:  5.406419 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018656 	loss:  5.2773113 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018905 	loss:  5.3231277 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.019357 	loss:  5.3267894 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.019351 	loss:  5.2101555 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.019160 	loss:  5.236506 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.019360 	loss:  5.217428 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.573330
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_26/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 17.13237 	D(real) 0.5698377869345925 	D(fake) 0.9876503510908647 	 G:  7.573513 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 16.066206 	D(real) 0.6892362941395153 	D(fake) 0.7713278857144442 	 G:  6.388311 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 16.375782 	D(real) 0.5807614759965376 	D(fake) 0.9079459797252308 	 G:  5.403509 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 16.861876 	D(real) 0.49117292057384143 	D(fake) 1.0417248119007458 	 G:  4.607143 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 17.383862 	D(real) 0.41874556107954547 	D(fake) 1.1616054014726118 	 G:  4.079915 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 17.700302 	D(real) 0.3708225163546475 	D(fake) 1.2382958152077415 	 G:  3.843125 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 17.708313 	D(real) 0.3492913246154785 	D(fake) 1.2605553540316494 	 G:  3.8591855 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 17.438906 	D(real) 0.35073902390219946 	D(fake) 1.2346161062067205 	 G:  4.0757365 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 17.01536 	D(real) 0.3704032030972568 	D(fake) 1.1764476949518377 	 G:  4.407805 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 16.628763 	D(real) 0.4006003900007768 	D(fake) 1.1111053986982866 	 G:  4.7186127 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 16.315556 	D(real) 0.4288669932972301 	D(fake) 1.0543652447787197 	 G:  4.7363057 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 16.311749 	D(real) 0.4304794831709428 	D(fake) 1.0524066578258167 	 G:  4.7408485 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 16.316572 	D(real) 0.4308884794061834 	D(fake) 1.0524362217296253 	 G:  4.7353287 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 16.328249 	D(real) 0.4303758361122825 	D(fake) 1.0540103912353516 	 G:  4.72207 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 16.344334 	D(real) 0.42917823791503906 	D(fake) 1.056670362299139 	 G:  4.703589 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 16.363716 	D(real) 0.42749448256059125 	D(fake) 1.0601161609996448 	 G:  4.6815133 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 16.384628 	D(real) 0.425489989194003 	D(fake) 1.0640216307206587 	 G:  4.657625 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 16.4068 	D(real) 0.42329978942871094 	D(fake) 1.0682274211536755 	 G:  4.6327467 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 16.42894 	D(real) 0.4210326454856179 	D(fake) 1.0725074247880415 	 G:  4.6080704 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 16.45111 	D(real) 0.41877425800670276 	D(fake) 1.0767813595858486 	 G:  4.5839543 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 16.428406 	D(real) 0.41659077731045807 	D(fake) 1.0769006555730647 	 G:  4.581735 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 16.43033 	D(real) 0.4163841334256259 	D(fake) 1.0772822119972922 	 G:  4.579614 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 16.432203 	D(real) 0.41618763316761365 	D(fake) 1.0776490298184482 	 G:  4.577571 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 16.433975 	D(real) 0.4159999327226119 	D(fake) 1.0779977278275923 	 G:  4.575628 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 16.436026 	D(real) 0.41581986167214136 	D(fake) 1.078364285555753 	 G:  4.5735793 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 16.43761 	D(real) 0.4156464663418857 	D(fake) 1.0786816857077859 	 G:  4.5718064 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 16.439072 	D(real) 0.41547896645285864 	D(fake) 1.0789820931174539 	 G:  4.5701284 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 16.44094 	D(real) 0.4153166250749068 	D(fake) 1.0793143185702236 	 G:  4.568269 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 16.442432 	D(real) 0.41515887867320667 	D(fake) 1.0796077901666814 	 G:  4.566628 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 16.444042 	D(real) 0.4150055105035955 	D(fake) 1.0799073305996982 	 G:  4.564952 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 16.441856 	D(real) 0.41485595703125 	D(fake) 1.0798581730235706 	 G:  4.5647845 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 16.441824 	D(real) 0.41484134847467596 	D(fake) 1.079869963906028 	 G:  4.5647197 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 16.441849 	D(real) 0.4148269566622647 	D(fake) 1.0798866098577327 	 G:  4.564626 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 16.442183 	D(real) 0.41481291164051404 	D(fake) 1.079930999062278 	 G:  4.564376 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 16.44208 	D(real) 0.41479908336292615 	D(fake) 1.0799354206431995 	 G:  4.564351 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 16.442406 	D(real) 0.41478529843417083 	D(fake) 1.0799788561734287 	 G:  4.5641055 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 16.44268 	D(real) 0.4147717735984109 	D(fake) 1.0800174366344104 	 G:  4.563888 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 16.442778 	D(real) 0.41475829211148346 	D(fake) 1.0800396312366833 	 G:  4.563764 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 16.44284 	D(real) 0.4147449406710538 	D(fake) 1.0800587914206765 	 G:  4.563656 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 16.443037 	D(real) 0.41473163257945667 	D(fake) 1.0800899158824573 	 G:  4.5634804 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 16.44275 	D(real) 0.41471845453435724 	D(fake) 1.0800770846280185 	 G:  4.5635 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 16.442986 	D(real) 0.4147171540693803 	D(fake) 1.0800996260209517 	 G:  4.563373 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 16.442818 	D(real) 0.4147158536044034 	D(fake) 1.0800857543945312 	 G:  4.563452 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 16.442799 	D(real) 0.4147145531394265 	D(fake) 1.0800853209062056 	 G:  4.5634537 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 16.442867 	D(real) 0.41471329602328216 	D(fake) 1.0800927769054065 	 G:  4.5634117 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 16.442802 	D(real) 0.41471199555830524 	D(fake) 1.0800881819291548 	 G:  4.563437 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 16.442848 	D(real) 0.4147107384421609 	D(fake) 1.0800935571843928 	 G:  4.563408 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 16.442818 	D(real) 0.41470943797718396 	D(fake) 1.0800920833240857 	 G:  4.563416 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 16.442936 	D(real) 0.41470813751220703 	D(fake) 1.0801041342995383 	 G:  4.5633473 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 16.442919 	D(real) 0.4147068370472301 	D(fake) 1.080103960904208 	 G:  4.563349 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 27}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 27
\seed data:	 27
\seed noise:	 27
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018239 	loss:  -0.71338934 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018540 	loss:  3.2293267 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017494 	loss:  7.972017 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017719 	loss:  10.686243 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017929 	loss:  10.629123 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017495 	loss:  10.314787 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017508 	loss:  8.486213 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017467 	loss:  8.48614 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017422 	loss:  10.229021 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017625 	loss:  10.228824 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017744 	loss:  9.857775 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017548 	loss:  9.857751 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.018236 	loss:  9.857628 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017655 	loss:  9.02906 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017511 	loss:  9.029105 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017509 	loss:  9.029076 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017730 	loss:  9.029059 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017308 	loss:  9.029032 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017622 	loss:  9.028994 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017904 	loss:  9.028947 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017997 	loss:  9.0288925 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018288 	loss:  9.028832 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017517 	loss:  10.228773 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017506 	loss:  10.228725 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017735 	loss:  10.228702 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017354 	loss:  10.22871 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017245 	loss:  10.228714 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017691 	loss:  10.228696 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017746 	loss:  10.228705 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017696 	loss:  10.228725 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017540 	loss:  10.2287245 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017541 	loss:  10.228723 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018063 	loss:  10.228719 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017723 	loss:  10.228715 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018223 	loss:  10.22871 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017514 	loss:  10.228706 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017513 	loss:  10.2287035 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017640 	loss:  10.228702 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017742 	loss:  10.228701 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017568 	loss:  10.228701 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017453 	loss:  10.228702 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017567 	loss:  10.228702 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017670 	loss:  10.228703 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017656 	loss:  10.228702 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017789 	loss:  10.228701 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017811 	loss:  10.228699 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017619 	loss:  10.228699 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017842 	loss:  10.228698 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017207 	loss:  10.228698 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017896 	loss:  10.228698 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.168859
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_27/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 10.32881 	D(real) 0.8471007347106934 	D(fake) 0.6284434454781669 	 G:  6.986453 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 11.296822 	D(real) 0.9982566833496094 	D(fake) 0.6155749729701451 	 G:  4.5278893 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 11.456465 	D(real) 0.6469639369419643 	D(fake) 0.9896738869803292 	 G:  2.802212 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 11.928882 	D(real) 0.4004290444510324 	D(fake) 1.30369690486363 	 G:  2.109262 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 12.142757 	D(real) 0.30132174491882324 	D(fake) 1.4333579199654716 	 G:  1.9970487 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 11.812492 	D(real) 0.28529432841709684 	D(fake) 1.4022045135498047 	 G:  2.2017035 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 11.16708 	D(real) 0.31452897616795134 	D(fake) 1.2807681219918388 	 G:  2.5940607 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 10.581392 	D(real) 0.3705806391579764 	D(fake) 1.1410467965262276 	 G:  3.0126271 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 10.285709 	D(real) 0.43037591661725727 	D(fake) 1.039011069706508 	 G:  3.2820284 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 10.2439575 	D(real) 0.46886134147644043 	D(fake) 0.9945611272539411 	 G:  3.3366756 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 10.14633 	D(real) 0.47666805131094797 	D(fake) 0.9728076117379325 	 G:  3.326335 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 10.16277 	D(real) 0.47519074167524067 	D(fake) 0.9766336168561663 	 G:  3.3043242 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 10.18416 	D(real) 0.47204634121486116 	D(fake) 0.9828337260654995 	 G:  3.2742562 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 10.209072 	D(real) 0.46775126457214355 	D(fake) 0.990687642778669 	 G:  3.2390294 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 10.236394 	D(real) 0.4627185208456857 	D(fake) 0.9996235030038017 	 G:  3.2009172 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 10.26519 	D(real) 0.45727392605372835 	D(fake) 1.0091818400791712 	 G:  3.161686 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 10.294661 	D(real) 0.4516694205147879 	D(fake) 1.01899630682809 	 G:  3.1226718 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 10.324122 	D(real) 0.44609601157052176 	D(fake) 1.0287786211286272 	 G:  3.0848637 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 10.352993 	D(real) 0.44069480895996094 	D(fake) 1.038304260798863 	 G:  3.048962 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 10.380786 	D(real) 0.43556601660592215 	D(fake) 1.047403403690883 	 G:  3.015448 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 10.368548 	D(real) 0.43077833311898367 	D(fake) 1.050442899976458 	 G:  3.01234 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 10.371028 	D(real) 0.4303344999040876 	D(fake) 1.0512409210205078 	 G:  3.0094311 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 10.373372 	D(real) 0.42991880008152555 	D(fake) 1.0519915308271135 	 G:  3.0066879 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 10.375608 	D(real) 0.42952687399727957 	D(fake) 1.0527029037475586 	 G:  3.0040848 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 10.377746 	D(real) 0.42915494101388113 	D(fake) 1.0533801487513952 	 G:  3.0016003 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 10.3798065 	D(real) 0.42880003792898996 	D(fake) 1.0540294647216797 	 G:  2.9992175 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 10.381796 	D(real) 0.4284596102578299 	D(fake) 1.0546540532793318 	 G:  2.996922 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 10.383724 	D(real) 0.4281317506517683 	D(fake) 1.0552574566432409 	 G:  2.9947023 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 10.385601 	D(real) 0.4278146880013602 	D(fake) 1.055842672075544 	 G:  2.9925473 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 10.387431 	D(real) 0.42750675337655203 	D(fake) 1.0564120156424386 	 G:  2.9904516 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 10.386257 	D(real) 0.42720746994018555 	D(fake) 1.0565434864589147 	 G:  2.9902472 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 10.386432 	D(real) 0.4271782125745501 	D(fake) 1.0565977096557617 	 G:  2.9900475 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 10.386606 	D(real) 0.42714970452444895 	D(fake) 1.0566511154174805 	 G:  2.9898498 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 10.386774 	D(real) 0.4271214008331299 	D(fake) 1.0567034312656947 	 G:  2.9896557 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 10.386942 	D(real) 0.42709371021815706 	D(fake) 1.056755202157157 	 G:  2.9894633 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 10.38711 	D(real) 0.4270662580217634 	D(fake) 1.0568065643310547 	 G:  2.9892728 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 10.387275 	D(real) 0.42703897612435476 	D(fake) 1.0568573815482003 	 G:  2.9890847 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 10.387441 	D(real) 0.42701217106410433 	D(fake) 1.0569079262869698 	 G:  2.988897 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 10.387606 	D(real) 0.42698529788425993 	D(fake) 1.0569583347865514 	 G:  2.988709 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 10.387766 	D(real) 0.42695859500340055 	D(fake) 1.0570079939705985 	 G:  2.9885247 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 10.387649 	D(real) 0.42693209648132324 	D(fake) 1.0570177350725447 	 G:  2.9885063 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 10.387667 	D(real) 0.4269294057573591 	D(fake) 1.057022980281285 	 G:  2.9884865 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 10.387681 	D(real) 0.426926783152989 	D(fake) 1.0570276805332728 	 G:  2.9884691 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 10.387698 	D(real) 0.42692419460841585 	D(fake) 1.057032653263637 	 G:  2.9884505 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 10.3877125 	D(real) 0.42692153794424875 	D(fake) 1.057037421635219 	 G:  2.9884324 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 10.387729 	D(real) 0.42691891533987864 	D(fake) 1.0570423262459892 	 G:  2.988414 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 10.387746 	D(real) 0.4269163267953055 	D(fake) 1.0570473670959473 	 G:  2.9883962 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 10.387762 	D(real) 0.4269137382507324 	D(fake) 1.0570522035871233 	 G:  2.9883776 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 10.387777 	D(real) 0.4269111156463623 	D(fake) 1.0570571081978934 	 G:  2.9883592 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 10.387794 	D(real) 0.42690845898219515 	D(fake) 1.0570620128086634 	 G:  2.9883409 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 28}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 28
\seed data:	 28
\seed noise:	 28
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018997 	loss:  -1.8264397 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.019433 	loss:  6.6900334 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018732 	loss:  10.551761 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018641 	loss:  9.649579 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018912 	loss:  9.649309 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.018856 	loss:  9.856854 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.019252 	loss:  10.544599 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.019591 	loss:  10.855932 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018871 	loss:  11.033124 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.019024 	loss:  10.752154 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.019221 	loss:  10.758255 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.019335 	loss:  10.646627 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.019917 	loss:  9.031953 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.019381 	loss:  5.4971313 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.019886 	loss:  4.44521 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.019369 	loss:  4.032539 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.019828 	loss:  4.0333323 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.019784 	loss:  3.4067423 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.020371 	loss:  2.6101503 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.019850 	loss:  2.6108708 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.020282 	loss:  2.2426407 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.020608 	loss:  2.341934 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.019886 	loss:  1.7065957 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.019912 	loss:  3.2571383 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.020170 	loss:  2.971436 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.019656 	loss:  1.6863275 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.019800 	loss:  2.1629817 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.019889 	loss:  1.9844714 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.019390 	loss:  1.5619633 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.019984 	loss:  0.6502824 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.019994 	loss:  1.7679224 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.019698 	loss:  1.015509 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.019925 	loss:  1.3606883 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.020115 	loss:  0.8924385 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.019624 	loss:  1.1370524 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.019207 	loss:  1.2301831 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.019395 	loss:  2.4231498 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.019608 	loss:  3.0871031 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.019914 	loss:  1.6454601 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.019592 	loss:  0.56604403 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.019855 	loss:  2.006575 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.020085 	loss:  1.8935038 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.020224 	loss:  0.7461397 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.019583 	loss:  0.72142065 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.019637 	loss:  1.6004286 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.019360 	loss:  1.8291103 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.019381 	loss:  0.45975885 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.019658 	loss:  2.0420074 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.020010 	loss:  3.1285655 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.019646 	loss:  1.765788 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.203576
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_28/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 17.173077 	D(real) 0.7518288872458718 	D(fake) 0.8093599839643999 	 G:  8.184492 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 17.153652 	D(real) 0.794405156915838 	D(fake) 0.7650177695534446 	 G:  6.181949 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 16.67536 	D(real) 0.5569373044100675 	D(fake) 0.9590044888583097 	 G:  5.109473 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 17.878998 	D(real) 0.40381526947021484 	D(fake) 1.221548167142001 	 G:  4.0075183 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 16.981665 	D(real) 0.3093596805225719 	D(fake) 1.2344280589710583 	 G:  4.482218 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 18.219618 	D(real) 0.2809333151037043 	D(fake) 1.3753956014459783 	 G:  3.6188703 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 18.403555 	D(real) 0.2857378396120938 	D(fake) 1.3873125423084607 	 G:  3.5231192 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 16.834965 	D(real) 0.3202753283760764 	D(fake) 1.210175947709517 	 G:  4.3176107 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 15.965996 	D(real) 0.36857973445545544 	D(fake) 1.0828744714910334 	 G:  4.834477 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 15.291726 	D(real) 0.40385801141912286 	D(fake) 0.9862989078868519 	 G:  5.3773046 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 15.326329 	D(real) 0.39720760692249646 	D(fake) 0.9960950504649769 	 G:  5.3388634 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 15.88305 	D(real) 0.3929907191883434 	D(fake) 1.0509229139848189 	 G:  4.865865 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 15.065996 	D(real) 0.38730677691372956 	D(fake) 0.9823291951959784 	 G:  5.4513597 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 16.493492 	D(real) 0.3798246817155318 	D(fake) 1.1195836500688032 	 G:  4.4304476 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 15.309814 	D(real) 0.37189197540283203 	D(fake) 1.0199093385176226 	 G:  5.3633013 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 14.948858 	D(real) 0.36423505436290393 	D(fake) 0.9947520169344816 	 G:  5.5431423 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 14.888528 	D(real) 0.3552810712294145 	D(fake) 0.9982214840975675 	 G:  5.6200056 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 15.330519 	D(real) 0.34481909058310767 	D(fake) 1.0488644513216885 	 G:  5.2384405 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 16.239983 	D(real) 0.3339659734205766 	D(fake) 1.1423960599032315 	 G:  4.660798 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 14.7734375 	D(real) 0.32402526248585095 	D(fake) 1.0190145319158381 	 G:  5.7824364 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 14.777731 	D(real) 0.31441127170215954 	D(fake) 1.029018835587935 	 G:  5.74233 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 17.862986 	D(real) 0.31344530799172143 	D(fake) 1.3104624314741655 	 G:  3.4556396 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 16.3183 	D(real) 0.3127271262082187 	D(fake) 1.170754692771218 	 G:  4.617186 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 15.523973 	D(real) 0.3122815869071267 	D(fake) 1.0989887064153498 	 G:  5.212348 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 13.880501 	D(real) 0.31188778443769977 	D(fake) 0.9499758807095614 	 G:  6.4615555 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 13.81545 	D(real) 0.31135533072731714 	D(fake) 0.9445946433327415 	 G:  6.4968605 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 16.307951 	D(real) 0.3105999773198908 	D(fake) 1.1719410636208274 	 G:  4.644086 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 17.969173 	D(real) 0.30983695116910065 	D(fake) 1.3237242265181108 	 G:  3.4030426 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 15.464685 	D(real) 0.3093538067557595 	D(fake) 1.0965266661210493 	 G:  5.3290157 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 16.336136 	D(real) 0.3090559352527965 	D(fake) 1.1760473251342773 	 G:  4.6315584 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 13.233814 	D(real) 0.30879926681518555 	D(fake) 0.8942747116088867 	 G:  6.8597145 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 16.277609 	D(real) 0.3087606863542037 	D(fake) 1.171021894975142 	 G:  4.6940894 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 16.331612 	D(real) 0.30871421640569513 	D(fake) 1.1759777936068447 	 G:  4.638371 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 16.245642 	D(real) 0.3086789738048207 	D(fake) 1.1681975451382725 	 G:  4.7297697 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 14.305614 	D(real) 0.3086533546447754 	D(fake) 0.9918570085005327 	 G:  5.925839 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 15.464535 	D(real) 0.30862240357832477 	D(fake) 1.0972443493929775 	 G:  5.3253984 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 14.687368 	D(real) 0.30858317288485443 	D(fake) 1.0266321355646306 	 G:  5.8743987 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 17.159845 	D(real) 0.3085394122383811 	D(fake) 1.251446463844993 	 G:  4.008861 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 15.540829 	D(real) 0.3085032376376065 	D(fake) 1.1042993718927556 	 G:  5.206102 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 15.943904 	D(real) 0.30847751010547986 	D(fake) 1.1409683227539062 	 G:  4.8271613 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 16.565147 	D(real) 0.3084530613639138 	D(fake) 1.1974693645130505 	 G:  4.285049 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 17.78241 	D(real) 0.3084512407129461 	D(fake) 1.3081313913518733 	 G:  3.4749632 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 17.982529 	D(real) 0.3084511106664484 	D(fake) 1.3263242894952947 	 G:  3.3935146 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 16.281244 	D(real) 0.3084531697359952 	D(fake) 1.1716599030928179 	 G:  4.6451154 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 14.824276 	D(real) 0.3084560307589444 	D(fake) 1.039205464449796 	 G:  5.66331 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 15.520566 	D(real) 0.3084574829448353 	D(fake) 1.102503082968972 	 G:  5.2414837 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 16.301897 	D(real) 0.308457461270419 	D(fake) 1.173533179543235 	 G:  4.647025 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 17.163074 	D(real) 0.30845711447975854 	D(fake) 1.2518224716186523 	 G:  4.0081806 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 15.943121 	D(real) 0.308457612991333 	D(fake) 1.1409169977361506 	 G:  4.826827 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 14.648233 	D(real) 0.3084584149447354 	D(fake) 1.0231991681185635 	 G:  5.9358454 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 29}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 29
\seed data:	 29
\seed noise:	 29
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018546 	loss:  0.22961059 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017838 	loss:  5.0485115 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017591 	loss:  8.0769 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017854 	loss:  9.638615 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017993 	loss:  9.638602 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017847 	loss:  8.495893 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017784 	loss:  6.2864065 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.018016 	loss:  -2.5524902 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018486 	loss:  -6.1072235 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018073 	loss:  -5.6293545 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018651 	loss:  -3.2187514 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018192 	loss:  -1.8904916 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.018608 	loss:  -2.1970525 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018104 	loss:  -2.4657044 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018459 	loss:  -1.7868233 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017879 	loss:  -2.4473138 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018567 	loss:  -2.1170125 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.019177 	loss:  -2.266796 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017855 	loss:  -2.0684016 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017926 	loss:  -1.8631626 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018057 	loss:  -1.5798402 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017904 	loss:  -1.6682682 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017981 	loss:  -1.2160695 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018334 	loss:  -1.2430661 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018495 	loss:  -1.1394875 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017888 	loss:  -0.881549 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017908 	loss:  -0.8920999 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017951 	loss:  -0.6559078 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.018024 	loss:  -0.5138333 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018181 	loss:  -0.21311906 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018498 	loss:  -0.2703181 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018220 	loss:  0.15438564 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018166 	loss:  0.09588731 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017596 	loss:  0.16615757 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018260 	loss:  -0.05635049 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017608 	loss:  0.07992844 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018309 	loss:  0.03657087 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018582 	loss:  -0.06967086 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018322 	loss:  0.27819148 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018079 	loss:  0.105031446 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017873 	loss:  0.07519294 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017726 	loss:  0.27962866 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018526 	loss:  -0.11123411 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017795 	loss:  0.12868643 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017652 	loss:  0.3447646 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017902 	loss:  0.23535675 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018436 	loss:  0.38171571 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017779 	loss:  0.35292974 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017649 	loss:  0.09317688 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017764 	loss:  0.120010674 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.245514
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___metr_29/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 14.169546 	D(real) 0.7808961868286133 	D(fake) 0.9902970194816589 	 G:  5.7412386 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 12.171227 	D(real) 0.7180675268173218 	D(fake) 0.8033359050750732 	 G:  4.3626933 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 12.02209 	D(real) 0.5453424453735352 	D(fake) 0.9574187994003296 	 G:  3.8044868 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 11.923597 	D(real) 0.4755592942237854 	D(fake) 1.014890432357788 	 G:  3.6970382 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 11.936973 	D(real) 0.46213003993034363 	D(fake) 1.0299915075302124 	 G:  3.6197648 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 12.044261 	D(real) 0.45247140526771545 	D(fake) 1.0530612468719482 	 G:  3.4780135 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 12.188608 	D(real) 0.4347522556781769 	D(fake) 1.0888237953186035 	 G:  3.312992 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 12.321726 	D(real) 0.41412511467933655 	D(fake) 1.1260906457901 	 G:  3.1748414 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 12.408676 	D(real) 0.39685577154159546 	D(fake) 1.154228687286377 	 G:  3.0906615 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 12.431807 	D(real) 0.386333167552948 	D(fake) 1.1676427125930786 	 G:  3.06601 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 12.239679 	D(real) 0.38325202465057373 	D(fake) 1.1467078924179077 	 G:  3.068365 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 12.232412 	D(real) 0.3835463523864746 	D(fake) 1.1455051898956299 	 G:  3.0741372 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 12.222442 	D(real) 0.3842679262161255 	D(fake) 1.1435372829437256 	 G:  3.0824268 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 12.210603 	D(real) 0.3853038251399994 	D(fake) 1.141021490097046 	 G:  3.0925052 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 12.197566 	D(real) 0.3865636885166168 	D(fake) 1.138132095336914 	 G:  3.1037905 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 12.183878 	D(real) 0.38797441124916077 	D(fake) 1.1350103616714478 	 G:  3.1158042 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 12.169962 	D(real) 0.389476478099823 	D(fake) 1.131768822669983 	 G:  3.1281672 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 12.156189 	D(real) 0.3910214900970459 	D(fake) 1.1285021305084229 	 G:  3.1405532 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 12.142815 	D(real) 0.392569899559021 	D(fake) 1.1252819299697876 	 G:  3.1527154 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 12.13004 	D(real) 0.3940903842449188 	D(fake) 1.1221646070480347 	 G:  3.164456 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 12.114656 	D(real) 0.3955579996109009 	D(fake) 1.1187740564346313 	 G:  3.165573 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 12.113525 	D(real) 0.3956972658634186 	D(fake) 1.1184934377670288 	 G:  3.166631 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 12.112454 	D(real) 0.39582934975624084 	D(fake) 1.118227481842041 	 G:  3.1676373 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 12.111435 	D(real) 0.3959551751613617 	D(fake) 1.1179741621017456 	 G:  3.168599 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 12.110449 	D(real) 0.3960758447647095 	D(fake) 1.1177302598953247 	 G:  3.1695282 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 12.109488 	D(real) 0.39619195461273193 	D(fake) 1.117493987083435 	 G:  3.1704302 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 12.108566 	D(real) 0.39630427956581116 	D(fake) 1.1172665357589722 	 G:  3.171301 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 12.107665 	D(real) 0.39641323685646057 	D(fake) 1.1170449256896973 	 G:  3.1721501 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 12.1068 	D(real) 0.39651936292648315 	D(fake) 1.116830587387085 	 G:  3.1729739 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 12.105944 	D(real) 0.396622896194458 	D(fake) 1.1166200637817383 	 G:  3.1737843 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 12.104484 	D(real) 0.396724134683609 	D(fake) 1.1163363456726074 	 G:  3.1738682 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 12.104418 	D(real) 0.3967340588569641 	D(fake) 1.1163182258605957 	 G:  3.1739378 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 12.1043215 	D(real) 0.3967438042163849 	D(fake) 1.116296410560608 	 G:  3.1740227 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 12.1042385 	D(real) 0.3967534303665161 	D(fake) 1.1162763833999634 	 G:  3.1741004 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 12.104168 	D(real) 0.396762877702713 	D(fake) 1.116258144378662 	 G:  3.1741707 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 12.104088 	D(real) 0.39677226543426514 	D(fake) 1.1162387132644653 	 G:  3.1742458 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 12.104002 	D(real) 0.3967815935611725 	D(fake) 1.1162186861038208 	 G:  3.1743233 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 12.103927 	D(real) 0.3967907428741455 	D(fake) 1.1162000894546509 	 G:  3.174396 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 12.103851 	D(real) 0.3967999517917633 	D(fake) 1.116181492805481 	 G:  3.174468 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 12.103779 	D(real) 0.39680901169776917 	D(fake) 1.1161633729934692 	 G:  3.1745386 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 12.10364 	D(real) 0.396818071603775 	D(fake) 1.116136908531189 	 G:  3.1745434 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 12.103625 	D(real) 0.39681896567344666 	D(fake) 1.1161341667175293 	 G:  3.1745546 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 12.103622 	D(real) 0.3968198895454407 	D(fake) 1.1161329746246338 	 G:  3.174559 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 12.103609 	D(real) 0.3968207836151123 	D(fake) 1.1161303520202637 	 G:  3.1745694 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 12.103602 	D(real) 0.39682164788246155 	D(fake) 1.11612868309021 	 G:  3.1745758 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 12.103595 	D(real) 0.39682260155677795 	D(fake) 1.1161267757415771 	 G:  3.1745827 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 12.103584 	D(real) 0.3968234658241272 	D(fake) 1.1161245107650757 	 G:  3.1745923 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 12.103578 	D(real) 0.39682433009147644 	D(fake) 1.116122841835022 	 G:  3.1745985 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 12.103582 	D(real) 0.39682525396347046 	D(fake) 1.1161224842071533 	 G:  3.1746001 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 12.103566 	D(real) 0.3968261182308197 	D(fake) 1.116119623184204 	 G:  3.174611 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 0}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 0
\seed data:	 0
\seed noise:	 0
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018163 	loss:  1.4689515 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017477 	loss:  1.3448457 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017329 	loss:  1.6864815 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017581 	loss:  1.8232919 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018498 	loss:  1.6404345 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.018029 	loss:  2.9203045 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018082 	loss:  4.0763445 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017043 	loss:  2.5677578 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.016965 	loss:  2.3185964 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017731 	loss:  2.7757223 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017390 	loss:  2.0564914 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017191 	loss:  2.0443258 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.016808 	loss:  2.364321 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.016912 	loss:  2.181449 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017329 	loss:  2.044295 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018778 	loss:  2.1814344 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017137 	loss:  2.2308187 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017149 	loss:  2.2493358 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017367 	loss:  2.2748601 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017786 	loss:  2.31857 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017078 	loss:  2.3185673 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017205 	loss:  2.4375222 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017686 	loss:  2.2735155 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.016819 	loss:  2.2486537 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.016883 	loss:  2.1820831 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.016877 	loss:  2.1820815 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.016751 	loss:  2.18208 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.016750 	loss:  2.364936 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.016902 	loss:  2.547792 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017669 	loss:  2.5044127 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.016883 	loss:  2.4620345 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017205 	loss:  2.302368 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017527 	loss:  2.3192186 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017197 	loss:  2.2698753 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017835 	loss:  2.298739 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017413 	loss:  2.305912 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.016854 	loss:  2.2805119 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017096 	loss:  2.203264 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017836 	loss:  2.0978203 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.016786 	loss:  2.1360276 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017299 	loss:  2.1118357 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018633 	loss:  2.1118357 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017089 	loss:  2.1118355 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017217 	loss:  2.1118355 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.016830 	loss:  2.1118355 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017114 	loss:  2.1118355 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017077 	loss:  2.1118355 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017792 	loss:  2.1118352 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.016781 	loss:  2.1118355 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.016939 	loss:  2.1118355 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.779341
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_0/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 10.282997 	D(real) 0.9470135370890299 	D(fake) 0.7668193976084391 	 G:  5.1229095 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 9.733594 	D(real) 0.9007026354471842 	D(fake) 0.7215630213419596 	 G:  3.7936835 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 9.31237 	D(real) 0.6290406386057535 	D(fake) 0.9230209986368815 	 G:  3.257589 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 9.434848 	D(real) 0.5428679784138998 	D(fake) 1.0296066602071126 	 G:  2.6260035 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 9.079365 	D(real) 0.41102492809295654 	D(fake) 1.1022024949391682 	 G:  2.7265959 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 10.855709 	D(real) 0.2910772164662679 	D(fake) 1.5182075500488281 	 G:  1.5947384 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 9.199467 	D(real) 0.264048953851064 	D(fake) 1.2691954771677654 	 G:  2.5586514 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 9.264896 	D(real) 0.29373900095621747 	D(fake) 1.2504103978474934 	 G:  2.50825 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 8.312905 	D(real) 0.34628617763519287 	D(fake) 1.0391980012257893 	 G:  3.224613 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 8.54865 	D(real) 0.4327991803487142 	D(fake) 0.9919757843017578 	 G:  3.135205 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 7.487149 	D(real) 0.45764438311258954 	D(fake) 0.7902137438456217 	 G:  3.7573087 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 6.9501915 	D(real) 0.4441947142283122 	D(fake) 0.7141705354054769 	 G:  4.2748694 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 6.1201944 	D(real) 0.419266144434611 	D(fake) 0.6007662216822306 	 G:  5.1268783 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 6.938923 	D(real) 0.38888339201609295 	D(fake) 0.7676037152608236 	 G:  4.0572004 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 8.19062 	D(real) 0.35800079504648846 	D(fake) 1.0071025689442952 	 G:  2.927752 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 7.6913285 	D(real) 0.3314340313275655 	D(fake) 0.9504540761311849 	 G:  3.1682444 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 8.550316 	D(real) 0.30935511986414593 	D(fake) 1.1156974633534749 	 G:  2.823563 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 8.264686 	D(real) 0.29179704189300537 	D(fake) 1.0856506029764812 	 G:  2.8692899 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 7.886105 	D(real) 0.2790936827659607 	D(fake) 1.0352571805318196 	 G:  3.227312 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 6.516256 	D(real) 0.2698800762494405 	D(fake) 0.8161625862121582 	 G:  4.2816668 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 5.802517 	D(real) 0.26170339186986286 	D(fake) 0.7053827444712321 	 G:  4.164037 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 6.234264 	D(real) 0.2606949806213379 	D(fake) 0.7783490022023519 	 G:  3.8649526 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 6.8528585 	D(real) 0.25954272349675495 	D(fake) 0.8826003869374593 	 G:  3.8207934 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 6.8321075 	D(real) 0.2585304180781047 	D(fake) 0.8801542123158773 	 G:  3.741072 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 8.425844 	D(real) 0.2576528787612915 	D(fake) 1.146654526392619 	 G:  2.5309424 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 7.5749917 	D(real) 0.25708556175231934 	D(fake) 1.0054130554199219 	 G:  3.3413758 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 8.090093 	D(real) 0.2568693558375041 	D(fake) 1.0914794603983562 	 G:  2.8377376 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 6.8564196 	D(real) 0.2568124135335286 	D(fake) 0.8859241803487142 	 G:  3.7893953 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 7.2897415 	D(real) 0.25674911340077716 	D(fake) 0.9582078456878662 	 G:  3.6693506 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 8.224868 	D(real) 0.2566705346107483 	D(fake) 1.1141408284505208 	 G:  2.6880424 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 6.3877096 	D(real) 0.2568705876668294 	D(fake) 0.8077476819356283 	 G:  4.085822 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 6.528372 	D(real) 0.256902813911438 	D(fake) 0.8311591148376465 	 G:  4.3013287 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 8.633959 	D(real) 0.2569081981976827 	D(fake) 1.1820849577585857 	 G:  2.5445933 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 9.684837 	D(real) 0.2569119930267334 	D(fake) 1.3572274843851726 	 G:  1.8577045 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 7.8792753 	D(real) 0.25697410106658936 	D(fake) 1.0562384923299153 	 G:  3.5330753 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 5.434272 	D(real) 0.25707725683848065 	D(fake) 0.648634672164917 	 G:  5.282035 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 7.7431746 	D(real) 0.2571354905764262 	D(fake) 1.0333936214447021 	 G:  3.111147 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 7.3052917 	D(real) 0.2571719487508138 	D(fake) 0.9603766600290934 	 G:  3.7023811 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 5.3674335 	D(real) 0.25721991062164307 	D(fake) 0.6373523473739624 	 G:  4.5271125 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 6.0153418 	D(real) 0.25721557935078937 	D(fake) 0.7453413804372152 	 G:  4.6104283 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 8.152605 	D(real) 0.2571597099304199 	D(fake) 1.1016077995300293 	 G:  2.67452 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 7.194851 	D(real) 0.2571558753649394 	D(fake) 0.9419859250386556 	 G:  3.5339181 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 7.3851023 	D(real) 0.25715386867523193 	D(fake) 0.9736964702606201 	 G:  3.6331923 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 5.436906 	D(real) 0.25715208053588867 	D(fake) 0.6489988962809244 	 G:  4.594059 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 6.2930756 	D(real) 0.2571479876836141 	D(fake) 0.7916978995005289 	 G:  4.827739 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 7.7220817 	D(real) 0.25713928540547687 	D(fake) 1.029874324798584 	 G:  3.0686603 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 5.682597 	D(real) 0.2571301261583964 	D(fake) 0.6899693806966146 	 G:  4.6881685 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 6.6325755 	D(real) 0.25711967547734577 	D(fake) 0.848309596379598 	 G:  3.7468066 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 8.045232 	D(real) 0.2571072181065877 	D(fake) 1.0837647914886475 	 G:  3.1405013 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 7.9091377 	D(real) 0.25709736347198486 	D(fake) 1.061092217763265 	 G:  3.0517237 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 1}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 1
\seed data:	 1
\seed noise:	 1
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018723 	loss:  -0.90330875 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018500 	loss:  2.2326634 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017675 	loss:  4.6033287 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018112 	loss:  5.5732474 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017240 	loss:  4.5141826 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017451 	loss:  5.263148 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017727 	loss:  7.308288 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017930 	loss:  5.612985 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017914 	loss:  -0.86238533 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017455 	loss:  -3.588946 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018169 	loss:  -2.9993937 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017444 	loss:  -0.52389634 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017570 	loss:  -0.4858043 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017910 	loss:  0.467262 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017280 	loss:  0.57574195 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017437 	loss:  1.703 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018205 	loss:  1.9157963 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017732 	loss:  1.9111466 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018047 	loss:  1.9492414 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017657 	loss:  2.1662738 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017451 	loss:  2.193872 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017944 	loss:  2.1499417 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017436 	loss:  2.0371714 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018017 	loss:  1.9318652 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017564 	loss:  1.9109004 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018293 	loss:  1.8884197 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017742 	loss:  1.8916223 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017662 	loss:  1.9371238 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017431 	loss:  1.9028031 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018084 	loss:  1.9255106 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017750 	loss:  1.9490024 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017583 	loss:  1.8719991 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017437 	loss:  1.9769329 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017353 	loss:  1.7994409 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017378 	loss:  1.9512783 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018085 	loss:  1.9472743 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017650 	loss:  1.9295994 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017792 	loss:  2.0006418 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018081 	loss:  1.922192 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017474 	loss:  1.9773897 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017602 	loss:  2.0106666 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017724 	loss:  1.8840964 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018128 	loss:  2.0811794 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018004 	loss:  2.0583563 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017411 	loss:  1.9951787 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017770 	loss:  2.0468588 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017822 	loss:  2.0487611 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018121 	loss:  1.8223772 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018853 	loss:  2.0376213 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017790 	loss:  1.9228488 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:32.115997
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_1/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 15.682142 	D(real) 0.5475433468818665 	D(fake) 1.4127243757247925 	 G:  4.4350114 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 12.518574 	D(real) 0.5547218322753906 	D(fake) 1.0100998878479004 	 G:  3.7390413 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 12.391644 	D(real) 0.46717455983161926 	D(fake) 1.0817809104919434 	 G:  3.380012 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 12.301094 	D(real) 0.4224795699119568 	D(fake) 1.115157127380371 	 G:  3.2550025 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 12.225643 	D(real) 0.4068734645843506 	D(fake) 1.1213319301605225 	 G:  3.2524526 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 12.151432 	D(real) 0.40655702352523804 	D(fake) 1.1123719215393066 	 G:  3.3012233 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 12.088445 	D(real) 0.4126535654067993 	D(fake) 1.0984020233154297 	 G:  3.356514 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 12.048835 	D(real) 0.419564813375473 	D(fake) 1.0865395069122314 	 G:  3.3959296 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 12.037469 	D(real) 0.4244915246963501 	D(fake) 1.0801920890808105 	 G:  3.410901 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 12.053965 	D(real) 0.4263629615306854 	D(fake) 1.0803825855255127 	 G:  3.3985271 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 11.907318 	D(real) 0.42481619119644165 	D(fake) 1.0635985136032104 	 G:  3.3941228 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 11.913738 	D(real) 0.42426589131355286 	D(fake) 1.0649514198303223 	 G:  3.3869956 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 11.922018 	D(real) 0.4233745336532593 	D(fake) 1.0668777227401733 	 G:  3.3778446 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 11.931625 	D(real) 0.42223069071769714 	D(fake) 1.0692224502563477 	 G:  3.3672814 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 11.942096 	D(real) 0.4209105670452118 	D(fake) 1.071851372718811 	 G:  3.3558347 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 11.953058 	D(real) 0.4194795787334442 	D(fake) 1.0746526718139648 	 G:  3.34394 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 11.964175 	D(real) 0.4179927110671997 	D(fake) 1.0775291919708252 	 G:  3.3319643 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 11.9751835 	D(real) 0.41649577021598816 	D(fake) 1.080402135848999 	 G:  3.320203 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 11.985855 	D(real) 0.41502565145492554 	D(fake) 1.083206295967102 	 G:  3.3088884 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 11.996018 	D(real) 0.41361120343208313 	D(fake) 1.0858911275863647 	 G:  3.2981956 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 11.981879 	D(real) 0.41227462887763977 	D(fake) 1.0854603052139282 	 G:  3.2972007 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 11.982766 	D(real) 0.4121503531932831 	D(fake) 1.0856953859329224 	 G:  3.2962735 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 11.983603 	D(real) 0.4120345115661621 	D(fake) 1.0859158039093018 	 G:  3.2954018 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 11.98439 	D(real) 0.4119255542755127 	D(fake) 1.0861232280731201 	 G:  3.2945795 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 11.985144 	D(real) 0.4118225872516632 	D(fake) 1.086320400238037 	 G:  3.293795 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 11.985868 	D(real) 0.41172438859939575 	D(fake) 1.086509108543396 	 G:  3.2930436 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 11.986562 	D(real) 0.4116306006908417 	D(fake) 1.0866895914077759 	 G:  3.2923224 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 11.987239 	D(real) 0.4115404784679413 	D(fake) 1.0868643522262573 	 G:  3.2916245 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 11.987889 	D(real) 0.41145333647727966 	D(fake) 1.0870327949523926 	 G:  3.2909503 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 11.988526 	D(real) 0.4113689363002777 	D(fake) 1.0871968269348145 	 G:  3.290293 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 11.987082 	D(real) 0.4112869203090668 	D(fake) 1.087098240852356 	 G:  3.29023 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 11.987143 	D(real) 0.41127893328666687 	D(fake) 1.087113857269287 	 G:  3.290167 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 11.987201 	D(real) 0.4112710654735565 	D(fake) 1.08712899684906 	 G:  3.2901063 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 11.98726 	D(real) 0.41126343607902527 	D(fake) 1.0871440172195435 	 G:  3.2900462 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 11.987317 	D(real) 0.4112558662891388 	D(fake) 1.0871587991714478 	 G:  3.2899861 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 11.987377 	D(real) 0.4112483859062195 	D(fake) 1.0871737003326416 	 G:  3.289926 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 11.987433 	D(real) 0.4112410545349121 	D(fake) 1.0871881246566772 	 G:  3.289868 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 11.987489 	D(real) 0.41123369336128235 	D(fake) 1.0872024297714233 	 G:  3.2898092 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 11.987548 	D(real) 0.41122639179229736 	D(fake) 1.087217092514038 	 G:  3.2897518 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 11.987602 	D(real) 0.41121917963027954 	D(fake) 1.0872310400009155 	 G:  3.2896943 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 11.987455 	D(real) 0.41121193766593933 	D(fake) 1.0872199535369873 	 G:  3.2896874 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 11.987459 	D(real) 0.41121119260787964 	D(fake) 1.0872212648391724 	 G:  3.2896829 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 11.987465 	D(real) 0.4112105071544647 	D(fake) 1.0872225761413574 	 G:  3.289678 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 11.9874735 	D(real) 0.4112097918987274 	D(fake) 1.0872243642807007 	 G:  3.2896705 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 11.987477 	D(real) 0.4112091362476349 	D(fake) 1.0872255563735962 	 G:  3.2896662 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 11.987483 	D(real) 0.4112083911895752 	D(fake) 1.0872269868850708 	 G:  3.2896602 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 11.987489 	D(real) 0.4112077057361603 	D(fake) 1.0872284173965454 	 G:  3.2896538 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 11.987494 	D(real) 0.4112069308757782 	D(fake) 1.08722984790802 	 G:  3.2896476 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 11.9875 	D(real) 0.4112062454223633 	D(fake) 1.0872312784194946 	 G:  3.2896426 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 11.987506 	D(real) 0.4112055003643036 	D(fake) 1.0872327089309692 	 G:  3.2896361 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 2}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 2
\seed data:	 2
\seed noise:	 2
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018315 	loss:  0.6329808 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017546 	loss:  3.8760424 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017337 	loss:  4.1565785 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017745 	loss:  4.1565156 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017858 	loss:  4.1836557 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017286 	loss:  4.1562867 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017201 	loss:  5.585384 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017768 	loss:  3.8299966 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017457 	loss:  3.4730036 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017786 	loss:  2.3569298 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017155 	loss:  2.0714984 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017345 	loss:  1.4590946 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017758 	loss:  1.7904743 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017818 	loss:  1.4985602 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017682 	loss:  1.3341107 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017814 	loss:  1.2924074 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017406 	loss:  1.20695 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017359 	loss:  1.0733348 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017275 	loss:  0.9495445 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017567 	loss:  1.1348683 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017991 	loss:  1.0901978 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017847 	loss:  1.0962068 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017846 	loss:  1.272666 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018271 	loss:  0.95748013 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017699 	loss:  1.0515015 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017496 	loss:  1.1434379 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017276 	loss:  1.2546897 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018034 	loss:  1.043799 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017317 	loss:  1.2729039 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017528 	loss:  1.1830173 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018015 	loss:  1.0506691 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017596 	loss:  1.3003778 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017965 	loss:  1.2328436 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017778 	loss:  1.0040979 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017230 	loss:  1.1674743 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017468 	loss:  1.2344424 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018118 	loss:  0.7067755 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017922 	loss:  1.0534625 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018293 	loss:  0.92334765 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017817 	loss:  1.0542858 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017444 	loss:  1.0730314 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017755 	loss:  1.0355954 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018036 	loss:  1.336662 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018207 	loss:  1.1635443 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017333 	loss:  1.0061263 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017896 	loss:  1.0984983 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017741 	loss:  1.0156282 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017949 	loss:  1.0813403 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017675 	loss:  1.2330083 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017576 	loss:  1.2020539 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.799888
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_2/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 12.996824 	D(real) 0.952413831438337 	D(fake) 0.9042752810886928 	 G:  6.7446356 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 12.37011 	D(real) 0.9806603022984096 	D(fake) 0.7864981378827777 	 G:  3.587074 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 10.410636 	D(real) 0.5126565865107945 	D(fake) 0.9745771544320243 	 G:  3.4039705 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 10.321024 	D(real) 0.48676988056727816 	D(fake) 0.9876620428902763 	 G:  3.4039745 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 10.434965 	D(real) 0.48722117287772043 	D(fake) 1.0034881319318498 	 G:  3.261678 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 10.62372 	D(real) 0.46681622096470426 	D(fake) 1.0508580207824707 	 G:  3.0192807 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 10.809808 	D(real) 0.4319009099687849 	D(fake) 1.1123573439461845 	 G:  2.7939432 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 10.947432 	D(real) 0.3994754041944231 	D(fake) 1.1644434247698103 	 G:  2.643304 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 11.014814 	D(real) 0.37780305317470003 	D(fake) 1.195741925920759 	 G:  2.5730462 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 11.007617 	D(real) 0.36767782483782085 	D(fake) 1.2048388889857702 	 G:  2.571328 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 10.83927 	D(real) 0.3673874650682722 	D(fake) 1.181079592023577 	 G:  2.5766559 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 10.827017 	D(real) 0.3681465557643345 	D(fake) 1.178570066179548 	 G:  2.5862412 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 10.811025 	D(real) 0.36951136589050293 	D(fake) 1.1749207632882255 	 G:  2.598955 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 10.792513 	D(real) 0.3713247435433524 	D(fake) 1.1704628808157784 	 G:  2.613897 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 10.772299 	D(real) 0.3734612124306815 	D(fake) 1.1654386520385742 	 G:  2.6304114 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 10.751201 	D(real) 0.3758182866232736 	D(fake) 1.1600675582885742 	 G:  2.6478882 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 10.729864 	D(real) 0.37831142970493864 	D(fake) 1.1545263017926897 	 G:  2.6658282 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 10.708868 	D(real) 0.38087010383605957 	D(fake) 1.1489681516374861 	 G:  2.6837862 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 10.688513 	D(real) 0.3834362711225237 	D(fake) 1.1434940610613142 	 G:  2.7014644 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 10.669043 	D(real) 0.3859620434897287 	D(fake) 1.1381869316101074 	 G:  2.7186117 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 10.654355 	D(real) 0.38840859276907785 	D(fake) 1.1336421285356795 	 G:  2.7202423 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 10.652619 	D(real) 0.38864173207964214 	D(fake) 1.1331609998430525 	 G:  2.7218027 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 10.650967 	D(real) 0.38886356353759766 	D(fake) 1.1327031680515833 	 G:  2.7232924 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 10.649391 	D(real) 0.3890758923121861 	D(fake) 1.1322657040187292 	 G:  2.724721 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 10.647884 	D(real) 0.3892801148550851 	D(fake) 1.1318461554391044 	 G:  2.726095 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 10.646414 	D(real) 0.38947742325919016 	D(fake) 1.1314388002668108 	 G:  2.7274325 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 10.644947 	D(real) 0.3896688393184117 	D(fake) 1.13103791645595 	 G:  2.7287517 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 10.643562 	D(real) 0.389855112348284 	D(fake) 1.1306537219456263 	 G:  2.7300186 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 10.642215 	D(real) 0.3900369576045445 	D(fake) 1.1302794047764368 	 G:  2.7312548 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 10.640889 	D(real) 0.39021481786455425 	D(fake) 1.1299122401646204 	 G:  2.73247 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 10.639502 	D(real) 0.3903891699654715 	D(fake) 1.1295395578656877 	 G:  2.7325938 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 10.639335 	D(real) 0.39040630204336985 	D(fake) 1.1294986179896764 	 G:  2.7327302 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 10.639215 	D(real) 0.39042316164289204 	D(fake) 1.1294646944318498 	 G:  2.7328424 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 10.639083 	D(real) 0.3904397828238351 	D(fake) 1.1294292041233607 	 G:  2.7329602 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 10.638976 	D(real) 0.39045623370579313 	D(fake) 1.1293975285121374 	 G:  2.7330658 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 10.638886 	D(real) 0.39047254834856304 	D(fake) 1.1293683733258928 	 G:  2.7331634 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 10.638723 	D(real) 0.39048865863255094 	D(fake) 1.12932893208095 	 G:  2.7332945 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 10.638647 	D(real) 0.3905047689165388 	D(fake) 1.1293018886021204 	 G:  2.7333853 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 10.638454 	D(real) 0.3905207429613386 	D(fake) 1.12925842830113 	 G:  2.73353 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 10.638383 	D(real) 0.3905367170061384 	D(fake) 1.1292322703770228 	 G:  2.7336178 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 10.638228 	D(real) 0.3905526229313442 	D(fake) 1.1291942596435547 	 G:  2.7336366 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 10.63821 	D(real) 0.3905542237418039 	D(fake) 1.1291900362287248 	 G:  2.733651 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 10.638176 	D(real) 0.3905557904924665 	D(fake) 1.129183564867292 	 G:  2.7336729 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 10.63818 	D(real) 0.3905573231833322 	D(fake) 1.1291826793125697 	 G:  2.7336757 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 10.638211 	D(real) 0.39055892399379183 	D(fake) 1.1291855403355189 	 G:  2.733666 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 10.63817 	D(real) 0.3905605248042515 	D(fake) 1.1291780471801758 	 G:  2.7336912 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 10.638153 	D(real) 0.3905620574951172 	D(fake) 1.129174028124128 	 G:  2.7337046 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 10.63814 	D(real) 0.39056362424577984 	D(fake) 1.1291705540248327 	 G:  2.733716 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 10.638131 	D(real) 0.39056522505623953 	D(fake) 1.1291677611214774 	 G:  2.7337258 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 10.638092 	D(real) 0.3905667577471052 	D(fake) 1.1291606766836983 	 G:  2.7337494 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 3}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 3
\seed data:	 3
\seed noise:	 3
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018294 	loss:  0.21024999 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017707 	loss:  3.3038611 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017352 	loss:  3.3137062 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017202 	loss:  2.426165 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017450 	loss:  4.398868 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.016956 	loss:  4.5733457 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017120 	loss:  6.5499167 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017563 	loss:  3.3504956 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017096 	loss:  -3.1993263 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017251 	loss:  -3.027889 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017925 	loss:  -0.31360617 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017148 	loss:  0.8724833 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017237 	loss:  2.4140956 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017789 	loss:  3.0830967 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017422 	loss:  3.9541721 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017887 	loss:  4.7995563 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017321 	loss:  4.8756804 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017273 	loss:  5.023564 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017907 	loss:  5.1130514 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017281 	loss:  5.4238257 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017481 	loss:  5.142314 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017493 	loss:  5.212474 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017947 	loss:  5.05918 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017295 	loss:  4.7642283 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017332 	loss:  4.814361 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018046 	loss:  4.806111 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017336 	loss:  4.7843018 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017380 	loss:  5.2207975 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017971 	loss:  4.7147007 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017602 	loss:  4.6885276 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018060 	loss:  4.75125 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017439 	loss:  4.7467184 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017339 	loss:  4.6074843 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017411 	loss:  4.867576 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017574 	loss:  4.648248 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017601 	loss:  4.475687 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017282 	loss:  4.681732 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017441 	loss:  4.2902 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017111 	loss:  4.7312207 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017153 	loss:  5.134882 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017423 	loss:  4.574775 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017643 	loss:  4.863439 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017611 	loss:  5.1172853 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017781 	loss:  4.9443846 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017477 	loss:  4.6156034 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017360 	loss:  4.554324 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017318 	loss:  4.8345475 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017489 	loss:  4.7561126 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017769 	loss:  4.5162506 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017888 	loss:  4.9886518 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.919965
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_3/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 11.304808 	D(real) 0.9388127326965332 	D(fake) 0.6761597224644252 	 G:  6.993589 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 11.699134 	D(real) 1.0018133435930525 	D(fake) 0.6694914954049247 	 G:  4.5243955 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 10.472475 	D(real) 0.6464784485953194 	D(fake) 0.8495894840785435 	 G:  3.8495173 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 10.319967 	D(real) 0.5500182424272809 	D(fake) 0.9242627280099052 	 G:  3.4846482 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 10.568975 	D(real) 0.49777466910226004 	D(fake) 1.0120790345328194 	 G:  3.0710955 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 10.863746 	D(real) 0.43871491295950754 	D(fake) 1.1132487569536482 	 G:  2.7297869 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 11.099843 	D(real) 0.3899662835257394 	D(fake) 1.195725577218192 	 G:  2.5206897 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 11.20647 	D(real) 0.36009648868015837 	D(fake) 1.2408276966639928 	 G:  2.4432185 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 11.166103 	D(real) 0.3490300859723772 	D(fake) 1.2461275373186385 	 G:  2.4732003 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 11.014262 	D(real) 0.3533141613006592 	D(fake) 1.2201519012451172 	 G:  2.579888 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 10.816954 	D(real) 0.3685551370893206 	D(fake) 1.1767240251813615 	 G:  2.59451 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 10.7961235 	D(real) 0.3706439222608294 	D(fake) 1.1716594696044922 	 G:  2.6110435 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 10.774179 	D(real) 0.3730060713631766 	D(fake) 1.1661624908447266 	 G:  2.6287732 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 10.751856 	D(real) 0.37553862162998747 	D(fake) 1.1604407174246651 	 G:  2.6471233 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 10.729723 	D(real) 0.3781599998474121 	D(fake) 1.1546576363699776 	 G:  2.6656313 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 10.708198 	D(real) 0.3808043343680246 	D(fake) 1.1489381790161133 	 G:  2.6839352 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 10.687598 	D(real) 0.3834190368652344 	D(fake) 1.1433807100568498 	 G:  2.70174 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 10.668165 	D(real) 0.3859624522072928 	D(fake) 1.1380611147199358 	 G:  2.7188122 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 10.650033 	D(real) 0.38840164457048687 	D(fake) 1.1330316407339913 	 G:  2.7349842 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 10.633308 	D(real) 0.3907115800040109 	D(fake) 1.1283324105398995 	 G:  2.7501209 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 10.619869 	D(real) 0.39287424087524414 	D(fake) 1.1242500032697404 	 G:  2.751521 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 10.618472 	D(real) 0.39307420594351633 	D(fake) 1.1238504137311662 	 G:  2.7528162 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 10.61717 	D(real) 0.3932591506413051 	D(fake) 1.1234794344220842 	 G:  2.7540238 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 10.61595 	D(real) 0.39343176569257465 	D(fake) 1.1231325013296944 	 G:  2.755159 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 10.614792 	D(real) 0.3935939243861607 	D(fake) 1.122804914202009 	 G:  2.756234 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 10.613689 	D(real) 0.3937474318913051 	D(fake) 1.1224938801356725 	 G:  2.757259 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 10.6126375 	D(real) 0.39389375277927946 	D(fake) 1.1221973555428642 	 G:  2.75824 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 10.611626 	D(real) 0.3940338407244001 	D(fake) 1.121912615639823 	 G:  2.7591834 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 10.61065 	D(real) 0.3941687175205776 	D(fake) 1.1216384342738561 	 G:  2.7600954 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 10.6097 	D(real) 0.3942990643637521 	D(fake) 1.1213723591395788 	 G:  2.760982 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 10.608458 	D(real) 0.394425630569458 	D(fake) 1.121068341391427 	 G:  2.7610674 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 10.608366 	D(real) 0.39443792615618023 	D(fake) 1.1210428646632604 	 G:  2.7611525 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 10.6082735 	D(real) 0.39444994926452637 	D(fake) 1.1210177285330636 	 G:  2.7612367 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 10.608193 	D(real) 0.3944617339542934 	D(fake) 1.1209944316319056 	 G:  2.761315 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 10.608109 	D(real) 0.3944733142852783 	D(fake) 1.1209708622523717 	 G:  2.7613938 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 10.608023 	D(real) 0.3944847583770752 	D(fake) 1.1209470885140556 	 G:  2.7614737 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 10.607939 	D(real) 0.39449613434927805 	D(fake) 1.1209237234933036 	 G:  2.7615533 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 10.607856 	D(real) 0.3945073400224958 	D(fake) 1.1209006309509277 	 G:  2.761631 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 10.607773 	D(real) 0.3945183753967285 	D(fake) 1.120877810886928 	 G:  2.7617078 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 10.607694 	D(real) 0.39452947889055523 	D(fake) 1.1208553314208984 	 G:  2.761784 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 10.607568 	D(real) 0.3945403780255999 	D(fake) 1.1208264487130302 	 G:  2.761793 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 10.607555 	D(real) 0.39454150199890137 	D(fake) 1.120823587690081 	 G:  2.7618027 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 10.607548 	D(real) 0.39454266003199984 	D(fake) 1.1208213397434779 	 G:  2.7618093 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 10.607546 	D(real) 0.3945436477661133 	D(fake) 1.1208200454711914 	 G:  2.761814 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 10.607536 	D(real) 0.39454473767961773 	D(fake) 1.1208175931658064 	 G:  2.7618232 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 10.607529 	D(real) 0.39454582759312223 	D(fake) 1.1208153452192033 	 G:  2.7618303 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 10.607521 	D(real) 0.3945469175066267 	D(fake) 1.1208133016313826 	 G:  2.7618365 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 10.607512 	D(real) 0.3945479393005371 	D(fake) 1.1208109855651855 	 G:  2.7618446 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 10.607504 	D(real) 0.3945490973336356 	D(fake) 1.1208085332598006 	 G:  2.761853 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 10.607496 	D(real) 0.39455011912754606 	D(fake) 1.1208064215523856 	 G:  2.7618604 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 4}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 4
\seed data:	 4
\seed noise:	 4
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.017559 	loss:  0.08327947 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017293 	loss:  3.8431258 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.016404 	loss:  5.3628597 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.016575 	loss:  4.721875 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.016530 	loss:  4.167682 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.016514 	loss:  6.0027356 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.016702 	loss:  3.5229063 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.016662 	loss:  3.442951 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.016978 	loss:  1.7032413 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017380 	loss:  1.3630081 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.016844 	loss:  0.4030186 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017162 	loss:  1.2830161 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.016533 	loss:  1.4430046 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.016919 	loss:  2.0829864 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.016849 	loss:  1.7853 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.016947 	loss:  1.5229456 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017145 	loss:  1.5229437 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017059 	loss:  1.5229415 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.016970 	loss:  1.5229391 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017437 	loss:  1.5229365 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.016771 	loss:  1.4429337 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.016852 	loss:  1.4429309 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017191 	loss:  1.3629282 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.016283 	loss:  0.7229256 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.016914 	loss:  1.0429225 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017014 	loss:  1.0429196 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017257 	loss:  1.0429168 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.016803 	loss:  1.0429142 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017041 	loss:  0.8829116 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.016413 	loss:  0.8029092 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.016764 	loss:  0.8029067 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017116 	loss:  0.8029064 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017025 	loss:  0.8029062 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.016695 	loss:  0.8029061 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017209 	loss:  0.8029058 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.016450 	loss:  0.80290556 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.016873 	loss:  0.80290526 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.016548 	loss:  0.80290496 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.016761 	loss:  0.8029048 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.016751 	loss:  0.8029046 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.016549 	loss:  0.80290437 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.016616 	loss:  0.8029042 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017120 	loss:  0.8029039 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.016475 	loss:  0.8029037 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.016661 	loss:  0.8029034 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.016382 	loss:  0.8029032 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.016517 	loss:  0.8029032 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017112 	loss:  0.8029032 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.016455 	loss:  0.8029031 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.016424 	loss:  0.80290306 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.147908
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_4/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 8.784792 	D(real) 0.7474574565887451 	D(fake) 1.0095009803771973 	 G:  4.873351 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 8.579423 	D(real) 0.9987880706787109 	D(fake) 0.7170965194702148 	 G:  2.6014266 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 7.505527 	D(real) 0.5205430030822754 	D(fake) 0.980562400817871 	 G:  2.5738738 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 7.0836744 	D(real) 0.5135598659515381 	D(fake) 0.9031750679016113 	 G:  2.8227081 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 7.233097 	D(real) 0.5628216743469239 	D(fake) 0.8837977409362793 	 G:  2.6859076 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 7.5298605 	D(real) 0.5348626613616944 	D(fake) 0.9711093902587891 	 G:  2.3139107 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 7.808266 	D(real) 0.45975532531738283 	D(fake) 1.10189790725708 	 G:  1.9759398 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 7.985812 	D(real) 0.3907663822174072 	D(fake) 1.2063960075378417 	 G:  1.7911549 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 8.028607 	D(real) 0.35234851837158204 	D(fake) 1.2533729553222657 	 G:  1.7327393 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 7.980774 	D(real) 0.3415555953979492 	D(fake) 1.2545991897583009 	 G:  1.7545943 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 7.827326 	D(real) 0.34637131690979006 	D(fake) 1.2190938949584962 	 G:  1.7611573 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 7.810621 	D(real) 0.34774696826934814 	D(fake) 1.214377212524414 	 G:  1.7728516 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 7.7869205 	D(real) 0.34967129230499266 	D(fake) 1.2077128410339355 	 G:  1.7883464 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 7.7604365 	D(real) 0.35191802978515624 	D(fake) 1.200169277191162 	 G:  1.8054988 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 7.7299466 	D(real) 0.35427539348602294 	D(fake) 1.1917139053344727 	 G:  1.8245552 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 7.6992664 	D(real) 0.3565521240234375 	D(fake) 1.1833011627197265 	 G:  1.8434694 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 7.6674147 	D(real) 0.358595609664917 	D(fake) 1.1748873710632324 	 G:  1.8624973 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 7.630676 	D(real) 0.36032857894897463 	D(fake) 1.1658065795898438 	 G:  1.8834817 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 7.5944858 	D(real) 0.3617445945739746 	D(fake) 1.1571525573730468 	 G:  1.9041277 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 7.5567656 	D(real) 0.3629115343093872 	D(fake) 1.1484416007995606 	 G:  1.9259174 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 7.5174613 	D(real) 0.36396715641021726 	D(fake) 1.1395251274108886 	 G:  1.9301212 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 7.515546 	D(real) 0.36406631469726564 	D(fake) 1.139042854309082 	 G:  1.9313409 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 7.510625 	D(real) 0.3641659259796143 	D(fake) 1.1379590034484863 	 G:  1.933978 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 7.50673 	D(real) 0.36426444053649903 	D(fake) 1.1370815277099608 	 G:  1.9361084 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 7.496975 	D(real) 0.3643613576889038 	D(fake) 1.1350336074829102 	 G:  1.9410293 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 7.493538 	D(real) 0.3644547462463379 	D(fake) 1.1342528343200684 	 G:  1.9429195 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 7.4911685 	D(real) 0.36454336643218993 	D(fake) 1.133690357208252 	 G:  1.9442878 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 7.482792 	D(real) 0.3646296262741089 	D(fake) 1.1319287300109864 	 G:  1.9485347 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 7.472293 	D(real) 0.3647131443023682 	D(fake) 1.1297453880310058 	 G:  1.9537936 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 7.4658036 	D(real) 0.36478986740112307 	D(fake) 1.1283708572387696 	 G:  1.957106 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 7.456709 	D(real) 0.3648579835891724 	D(fake) 1.1264838218688964 	 G:  1.9593378 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 7.464776 	D(real) 0.3648635149002075 	D(fake) 1.1280917167663573 	 G:  1.9554821 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 7.4685493 	D(real) 0.3648681640625 	D(fake) 1.1288416862487793 	 G:  1.9536895 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 7.4660525 	D(real) 0.364872670173645 	D(fake) 1.1283378601074219 	 G:  1.9548981 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 7.455214 	D(real) 0.3648771524429321 	D(fake) 1.1261656761169434 	 G:  1.9600966 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 7.4673653 	D(real) 0.36488101482391355 	D(fake) 1.1285920143127441 	 G:  1.9542855 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 7.457482 	D(real) 0.36488444805145265 	D(fake) 1.1266119003295898 	 G:  1.9590251 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 7.460129 	D(real) 0.3648876905441284 	D(fake) 1.127138042449951 	 G:  1.9577663 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 7.44964 	D(real) 0.36489057540893555 	D(fake) 1.125037384033203 	 G:  1.9628044 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 7.4469156 	D(real) 0.36489267349243165 	D(fake) 1.124490451812744 	 G:  1.9641203 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 7.4494967 	D(real) 0.36489365100860593 	D(fake) 1.1250057220458984 	 G:  1.9626527 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 7.4568553 	D(real) 0.36489362716674806 	D(fake) 1.1264774322509765 	 G:  1.9591204 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 7.4523935 	D(real) 0.36489365100860593 	D(fake) 1.1255850791931152 	 G:  1.9612586 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 7.45857 	D(real) 0.3648935556411743 	D(fake) 1.1268204689025878 	 G:  1.9582946 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 7.461755 	D(real) 0.3648935556411743 	D(fake) 1.1274574279785157 	 G:  1.956784 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 7.456296 	D(real) 0.36489357948303225 	D(fake) 1.1263656616210938 	 G:  1.9593896 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 7.4525642 	D(real) 0.36489365100860593 	D(fake) 1.1256192207336426 	 G:  1.9611765 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 7.4511843 	D(real) 0.36489365100860593 	D(fake) 1.1253432273864745 	 G:  1.9618428 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 7.4584413 	D(real) 0.36489365100860593 	D(fake) 1.1267946243286133 	 G:  1.9583628 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 7.4664593 	D(real) 0.36489365100860593 	D(fake) 1.1283982276916504 	 G:  1.9545288 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 5}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 5
\seed data:	 5
\seed noise:	 5
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.017699 	loss:  -2.1576366 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017252 	loss:  2.322234 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.016856 	loss:  0.80204284 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017025 	loss:  0.16171542 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017073 	loss:  3.441185 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017452 	loss:  3.841527 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.016470 	loss:  2.561105 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017501 	loss:  6.102253 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.016783 	loss:  5.2007146 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.016494 	loss:  4.2417054 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.016543 	loss:  3.842077 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.016823 	loss:  2.242132 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.016790 	loss:  1.202134 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017185 	loss:  0.5933027 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017543 	loss:  0.5621228 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017105 	loss:  1.9221152 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017361 	loss:  2.242114 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.016673 	loss:  2.5621128 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.016712 	loss:  2.322112 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.016654 	loss:  2.082111 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017126 	loss:  2.024444 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017390 	loss:  2.0021079 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017513 	loss:  2.0021062 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017154 	loss:  2.0021045 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.016589 	loss:  2.0021024 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017236 	loss:  2.0021005 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.016462 	loss:  2.0020986 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.016451 	loss:  2.0020964 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.016832 	loss:  2.0020943 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017149 	loss:  2.0020924 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.016728 	loss:  2.0020902 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.016900 	loss:  2.00209 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.016641 	loss:  1.7620897 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017539 	loss:  1.8831286 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.016431 	loss:  2.0020895 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.016816 	loss:  1.7620891 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.016827 	loss:  2.0020888 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017247 	loss:  2.0020888 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017025 	loss:  2.0020883 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017102 	loss:  2.002088 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.016878 	loss:  2.0020878 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.016764 	loss:  2.0020878 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.016707 	loss:  2.0020874 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.016896 	loss:  1.7620872 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.016685 	loss:  2.002087 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.016741 	loss:  2.0020866 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.016909 	loss:  2.0020866 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017309 	loss:  2.0020866 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017423 	loss:  2.0020866 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.016752 	loss:  2.0020864 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:35.133690
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_5/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 7.8008175 	D(real) 0.7847871303558349 	D(fake) 0.7753763675689698 	 G:  4.9315767 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 8.378917 	D(real) 0.9827937126159668 	D(fake) 0.6929896354675293 	 G:  3.0069818 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 8.120224 	D(real) 0.6014012336730957 	D(fake) 1.0226436614990235 	 G:  2.2085395 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 7.7347393 	D(real) 0.4417212963104248 	D(fake) 1.1052265167236328 	 G:  2.2757866 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 7.5741196 	D(real) 0.45516324043273926 	D(fake) 1.0596607208251954 	 G:  2.2945607 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 7.6272626 	D(real) 0.45891504287719725 	D(fake) 1.0665374755859376 	 G:  2.1628869 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 7.7047167 	D(real) 0.43257861137390136 	D(fake) 1.1083646774291993 	 G:  2.031892 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 7.725495 	D(real) 0.40637884140014646 	D(fake) 1.1387201309204102 	 G:  1.9808755 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 7.7014647 	D(real) 0.3961751699447632 	D(fake) 1.1441177368164062 	 G:  1.9858375 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 7.657452 	D(real) 0.3971674919128418 	D(fake) 1.1343229293823243 	 G:  2.0152597 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 7.5405207 	D(real) 0.40305194854736326 	D(fake) 1.1050521850585937 	 G:  2.0183458 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 7.5375414 	D(real) 0.4036691665649414 	D(fake) 1.103839111328125 	 G:  2.0208783 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 7.5351 	D(real) 0.4041756629943848 	D(fake) 1.1028443336486817 	 G:  2.0229821 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 7.5330887 	D(real) 0.4045964241027832 	D(fake) 1.1020213127136231 	 G:  2.0247343 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 7.5314302 	D(real) 0.40494685173034667 	D(fake) 1.1013392448425292 	 G:  2.0261905 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 7.5300684 	D(real) 0.40523810386657716 	D(fake) 1.1007756233215331 	 G:  2.0273924 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 7.5289593 	D(real) 0.40547847747802734 	D(fake) 1.100313377380371 	 G:  2.0283747 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 7.528066 	D(real) 0.40567493438720703 	D(fake) 1.0999382972717284 	 G:  2.0291648 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 7.5273566 	D(real) 0.40583295822143556 	D(fake) 1.0996383666992187 	 G:  2.029789 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 7.526808 	D(real) 0.4059577941894531 	D(fake) 1.0994037628173827 	 G:  2.0302691 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 7.518343 	D(real) 0.4060538291931152 	D(fake) 1.0976147651672363 	 G:  2.030303 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 7.5183167 	D(real) 0.40606060028076174 	D(fake) 1.0976027488708495 	 G:  2.0303245 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 7.5183015 	D(real) 0.40606489181518557 	D(fake) 1.0975954055786132 	 G:  2.0303357 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 7.5182953 	D(real) 0.4060671329498291 	D(fake) 1.0975919723510743 	 G:  2.0303383 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 7.518295 	D(real) 0.4060676574707031 	D(fake) 1.0975913047790526 	 G:  2.0303352 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 7.518302 	D(real) 0.4060670375823975 	D(fake) 1.0975933074951172 	 G:  2.0303268 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 7.518312 	D(real) 0.40606536865234377 	D(fake) 1.097597026824951 	 G:  2.0303137 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 7.518326 	D(real) 0.40606274604797366 	D(fake) 1.097602367401123 	 G:  2.0302978 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 7.518343 	D(real) 0.40605955123901366 	D(fake) 1.097609043121338 	 G:  2.0302794 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 7.518361 	D(real) 0.4060558795928955 	D(fake) 1.0976162910461427 	 G:  2.0302587 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 7.5175505 	D(real) 0.4060517311096191 	D(fake) 1.0974583625793457 	 G:  2.0302565 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 7.5175533 	D(real) 0.4060513019561768 	D(fake) 1.097459316253662 	 G:  2.030254 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 7.5175557 	D(real) 0.4060507774353027 	D(fake) 1.0974603652954102 	 G:  2.0302515 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 7.5175576 	D(real) 0.4060503005981445 	D(fake) 1.097461223602295 	 G:  2.0302494 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 7.51756 	D(real) 0.40604987144470217 	D(fake) 1.0974621772766113 	 G:  2.0302467 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 7.517563 	D(real) 0.4060493469238281 	D(fake) 1.0974632263183595 	 G:  2.0302436 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 7.5175657 	D(real) 0.40604872703552247 	D(fake) 1.0974644660949706 	 G:  2.030241 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 7.5175695 	D(real) 0.40604820251464846 	D(fake) 1.097465705871582 	 G:  2.0302382 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 7.517571 	D(real) 0.4060476303100586 	D(fake) 1.0974665641784669 	 G:  2.0302355 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 7.5175743 	D(real) 0.4060472011566162 	D(fake) 1.0974676132202148 	 G:  2.0302324 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 7.5174937 	D(real) 0.4060464859008789 	D(fake) 1.0974522590637208 	 G:  2.0302324 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 7.5174937 	D(real) 0.4060464859008789 	D(fake) 1.0974522590637208 	 G:  2.030232 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 7.5174947 	D(real) 0.40604639053344727 	D(fake) 1.0974525451660155 	 G:  2.030232 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 7.517495 	D(real) 0.40604639053344727 	D(fake) 1.0974526405334473 	 G:  2.0302315 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 7.5174947 	D(real) 0.40604629516601565 	D(fake) 1.0974526405334473 	 G:  2.030231 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 7.517496 	D(real) 0.406046199798584 	D(fake) 1.0974530220031737 	 G:  2.030231 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 7.517496 	D(real) 0.406046199798584 	D(fake) 1.0974530220031737 	 G:  2.03023 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 7.517496 	D(real) 0.4060460090637207 	D(fake) 1.0974532127380372 	 G:  2.03023 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 7.5174966 	D(real) 0.4060460090637207 	D(fake) 1.0974533081054687 	 G:  2.0302298 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 7.517496 	D(real) 0.40604596138000487 	D(fake) 1.0974533081054687 	 G:  2.0302293 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 6}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 6
\seed data:	 6
\seed noise:	 6
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018027 	loss:  0.4813715 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017005 	loss:  1.6812088 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.016695 	loss:  0.32102844 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.016762 	loss:  0.00085726485 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.016600 	loss:  0.48139116 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.016519 	loss:  3.7609215 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017196 	loss:  3.5209491 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017452 	loss:  2.56097 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017182 	loss:  -0.3190198 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.016531 	loss:  0.08097072 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.016635 	loss:  -0.4790412 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.016562 	loss:  -0.71904117 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.016743 	loss:  -0.1590394 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.016822 	loss:  0.3209522 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.016373 	loss:  0.48093972 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.016909 	loss:  1.760934 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017073 	loss:  1.7609338 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.016982 	loss:  1.7609334 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.016820 	loss:  1.920933 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017336 	loss:  2.160932 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.016718 	loss:  2.1609313 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.016404 	loss:  2.0809305 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.016792 	loss:  2.00093 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.016965 	loss:  2.0009294 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017153 	loss:  2.0009286 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.016628 	loss:  2.000928 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017498 	loss:  2.0009274 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.016850 	loss:  2.000927 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017287 	loss:  2.0933962 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017059 	loss:  1.90067 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.016963 	loss:  1.600926 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017267 	loss:  1.600926 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.016401 	loss:  1.600926 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.016497 	loss:  1.600926 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.016385 	loss:  1.600926 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.016647 	loss:  1.6009259 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017338 	loss:  1.600926 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.016452 	loss:  1.6009259 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017099 	loss:  1.6009259 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.016971 	loss:  1.6009259 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.016926 	loss:  1.6009258 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017169 	loss:  1.6009258 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.016518 	loss:  1.6009258 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.016644 	loss:  1.6009258 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.016702 	loss:  1.6009258 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.016771 	loss:  1.6009258 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017400 	loss:  1.6009257 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.016554 	loss:  1.6009258 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.016732 	loss:  1.6009257 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.016471 	loss:  1.6009257 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.712356
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_6/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 9.23488 	D(real) 0.7226434230804444 	D(fake) 1.1243326187133789 	 G:  3.6630378 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 8.3383255 	D(real) 0.7351869106292724 	D(fake) 0.9324781417846679 	 G:  2.2742295 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 7.8549767 	D(real) 0.45389504432678224 	D(fake) 1.1171002388000488 	 G:  2.0847023 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 7.702279 	D(real) 0.4169395923614502 	D(fake) 1.1235161781311036 	 G:  2.1231472 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 7.6732225 	D(real) 0.42467222213745115 	D(fake) 1.1099722862243653 	 G:  2.099305 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 7.7074566 	D(real) 0.4199355602264404 	D(fake) 1.1215558052062988 	 G:  2.0236669 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 7.7113256 	D(real) 0.40476627349853517 	D(fake) 1.1374988555908203 	 G:  1.9913441 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 7.673773 	D(real) 0.3982714653015137 	D(fake) 1.136483097076416 	 G:  2.0071363 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 7.621397 	D(real) 0.4014428615570068 	D(fake) 1.1228364944458007 	 G:  2.0433364 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 7.5742497 	D(real) 0.40865411758422854 	D(fake) 1.106195831298828 	 G:  2.080975 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 7.4761643 	D(real) 0.416164493560791 	D(fake) 1.079068374633789 	 G:  2.0831246 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 7.4748573 	D(real) 0.4166544437408447 	D(fake) 1.0783170700073241 	 G:  2.0841346 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 7.4754095 	D(real) 0.41680731773376467 	D(fake) 1.078274631500244 	 G:  2.0835195 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 7.4770427 	D(real) 0.41669473648071287 	D(fake) 1.0787137985229491 	 G:  2.0818276 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 7.4791174 	D(real) 0.4163762092590332 	D(fake) 1.0794472694396973 	 G:  2.0795114 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 7.4816895 	D(real) 0.41590051651000975 	D(fake) 1.0804373741149902 	 G:  2.0766554 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 7.4847856 	D(real) 0.4153099060058594 	D(fake) 1.0816472053527832 	 G:  2.0733364 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 7.4883575 	D(real) 0.4146413326263428 	D(fake) 1.0830302238464355 	 G:  2.0696537 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 7.491728 	D(real) 0.4139233112335205 	D(fake) 1.0844222068786622 	 G:  2.0660207 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 7.4954963 	D(real) 0.4131793975830078 	D(fake) 1.0859198570251465 	 G:  2.0621793 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 7.4876404 	D(real) 0.4124304294586182 	D(fake) 1.0850976943969726 	 G:  2.061738 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 7.487403 	D(real) 0.4123558521270752 	D(fake) 1.0851247787475586 	 G:  2.0616686 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 7.488121 	D(real) 0.41228156089782714 	D(fake) 1.0853426933288575 	 G:  2.0611129 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 7.4886546 	D(real) 0.41220769882202146 	D(fake) 1.0855232238769532 	 G:  2.0606527 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 7.4887366 	D(real) 0.4121342658996582 	D(fake) 1.0856130599975586 	 G:  2.060424 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 7.489319 	D(real) 0.4120614051818848 	D(fake) 1.0858023643493653 	 G:  2.0599427 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 7.4895935 	D(real) 0.41198906898498533 	D(fake) 1.0859296798706055 	 G:  2.0596197 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 7.4901776 	D(real) 0.41191720962524414 	D(fake) 1.0861183166503907 	 G:  2.05914 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 7.490036 	D(real) 0.4118460178375244 	D(fake) 1.0861611366271973 	 G:  2.059032 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 7.4905796 	D(real) 0.4117753505706787 	D(fake) 1.0863405227661134 	 G:  2.0585766 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 7.4898157 	D(real) 0.41170544624328614 	D(fake) 1.0862577438354493 	 G:  2.0585294 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 7.489924 	D(real) 0.4116985321044922 	D(fake) 1.0862862586975097 	 G:  2.0584567 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 7.48979 	D(real) 0.41169166564941406 	D(fake) 1.086266326904297 	 G:  2.0585077 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 7.4896116 	D(real) 0.4116847991943359 	D(fake) 1.0862375259399415 	 G:  2.0585814 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 7.48997 	D(real) 0.41167798042297366 	D(fake) 1.0863160133361816 	 G:  2.0583816 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 7.4900274 	D(real) 0.41167125701904295 	D(fake) 1.086334228515625 	 G:  2.0583348 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 7.48996 	D(real) 0.4116644859313965 	D(fake) 1.0863275527954102 	 G:  2.0583515 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 7.48973 	D(real) 0.41165771484375 	D(fake) 1.0862882614135743 	 G:  2.058452 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 7.489949 	D(real) 0.4116509437561035 	D(fake) 1.0863389015197753 	 G:  2.0583231 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 7.4900546 	D(real) 0.41164426803588866 	D(fake) 1.0863666534423828 	 G:  2.0582526 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 7.489933 	D(real) 0.411637544631958 	D(fake) 1.086349105834961 	 G:  2.0582705 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 7.490303 	D(real) 0.4116368293762207 	D(fake) 1.0864237785339355 	 G:  2.0580807 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 7.490133 	D(real) 0.4116361618041992 	D(fake) 1.0863903999328612 	 G:  2.0581653 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 7.490524 	D(real) 0.4116354942321777 	D(fake) 1.0864692687988282 	 G:  2.057965 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 7.489751 	D(real) 0.4116347789764404 	D(fake) 1.0863153457641601 	 G:  2.0583568 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 7.4899235 	D(real) 0.41163411140441897 	D(fake) 1.0863506317138671 	 G:  2.0582662 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 7.4896617 	D(real) 0.41163339614868166 	D(fake) 1.086298942565918 	 G:  2.0583982 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 7.4898777 	D(real) 0.411632776260376 	D(fake) 1.086342716217041 	 G:  2.0582871 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 7.4901743 	D(real) 0.4116321563720703 	D(fake) 1.086402702331543 	 G:  2.058134 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 7.4899063 	D(real) 0.4116313934326172 	D(fake) 1.086349868774414 	 G:  2.0582688 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 7}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 7
\seed data:	 7
\seed noise:	 7
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018135 	loss:  1.3623575 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018118 	loss:  3.602215 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.016772 	loss:  6.162058 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.016724 	loss:  6.321853 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.016588 	loss:  6.321747 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017054 	loss:  6.321766 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017064 	loss:  6.5619245 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.016799 	loss:  7.522001 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.016806 	loss:  6.1620326 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.016672 	loss:  4.082033 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.016638 	loss:  4.3220096 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.016615 	loss:  4.401978 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017030 	loss:  4.202994 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.016245 	loss:  4.081942 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.016916 	loss:  4.401936 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017008 	loss:  3.121934 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.016894 	loss:  3.1219337 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.016627 	loss:  3.03362 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017256 	loss:  3.1894622 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.016575 	loss:  3.109461 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.016554 	loss:  3.1094599 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.016625 	loss:  3.068419 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017001 	loss:  3.2019265 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017218 	loss:  3.1364732 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017149 	loss:  3.0419245 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017600 	loss:  3.0419235 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.016639 	loss:  2.881923 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017114 	loss:  3.041922 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.016624 	loss:  3.0419216 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017011 	loss:  3.0419214 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.016653 	loss:  3.041921 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.016925 	loss:  3.041921 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.016909 	loss:  3.041921 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017329 	loss:  3.041921 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.016788 	loss:  3.0419207 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017182 	loss:  3.0419207 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017393 	loss:  3.0419207 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017242 	loss:  3.0419207 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.016945 	loss:  3.0419204 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017421 	loss:  3.0419207 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.016551 	loss:  3.0419204 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.016745 	loss:  3.0419204 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.016497 	loss:  3.0419202 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.016391 	loss:  3.0419202 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.016364 	loss:  3.0419202 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017109 	loss:  3.0419202 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017106 	loss:  3.0419202 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.016627 	loss:  3.0419202 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.016525 	loss:  3.0419202 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.016328 	loss:  3.0419202 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.732487
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_7/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 7.649932 	D(real) 0.7439657211303711 	D(fake) 0.7860206604003906 	 G:  3.566033 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 7.8518276 	D(real) 0.7131609439849853 	D(fake) 0.8572046279907226 	 G:  2.5859687 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 7.795746 	D(real) 0.5171959400177002 	D(fake) 1.041953182220459 	 G:  2.0572138 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 8.013193 	D(real) 0.4114429473876953 	D(fake) 1.1911957740783692 	 G:  1.8125604 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 8.070404 	D(real) 0.3625120401382446 	D(fake) 1.2515687942504883 	 G:  1.7654963 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 7.982732 	D(real) 0.3530992031097412 	D(fake) 1.243447208404541 	 G:  1.8173388 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 7.814704 	D(real) 0.3634676933288574 	D(fake) 1.1994730949401855 	 G:  1.9277917 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 7.634917 	D(real) 0.38555829524993895 	D(fake) 1.1414250373840331 	 G:  2.0566769 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 7.5062194 	D(real) 0.4113353729248047 	D(fake) 1.089908504486084 	 G:  2.1610255 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 7.445773 	D(real) 0.4322051048278809 	D(fake) 1.056949520111084 	 G:  2.217004 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 7.360112 	D(real) 0.44340081214904786 	D(fake) 1.0286215782165526 	 G:  2.2171328 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 7.364108 	D(real) 0.44342656135559083 	D(fake) 1.0293950080871581 	 G:  2.2126105 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 7.37078 	D(real) 0.4425220966339111 	D(fake) 1.0316339492797852 	 G:  2.2046504 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 7.3794203 	D(real) 0.44093008041381837 	D(fake) 1.0349539756774901 	 G:  2.194233 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 7.389455 	D(real) 0.4388465881347656 	D(fake) 1.0390443801879883 	 G:  2.1821556 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 7.400421 	D(real) 0.4364311218261719 	D(fake) 1.0436531066894532 	 G:  2.1690662 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 7.4119377 	D(real) 0.4338132381439209 	D(fake) 1.0485742568969727 	 G:  2.155485 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 7.4236774 	D(real) 0.43109698295593263 	D(fake) 1.0536384582519531 	 G:  2.141826 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 7.435375 	D(real) 0.4283651828765869 	D(fake) 1.0587099075317383 	 G:  2.1284149 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 7.4468136 	D(real) 0.42568297386169435 	D(fake) 1.0636796951293945 	 G:  2.115499 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 7.438851 	D(real) 0.42309980392456054 	D(fake) 1.0646703720092774 	 G:  2.1142693 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 7.439902 	D(real) 0.4228538513183594 	D(fake) 1.0651265144348145 	 G:  2.1130927 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 7.440914 	D(real) 0.42261853218078616 	D(fake) 1.065564250946045 	 G:  2.1119626 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 7.4418936 	D(real) 0.4223925113677979 	D(fake) 1.0659862518310548 	 G:  2.1108718 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 7.4428453 	D(real) 0.4221743106842041 	D(fake) 1.0663947105407714 	 G:  2.1098144 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 7.4437714 	D(real) 0.42196288108825686 	D(fake) 1.0667913436889649 	 G:  2.108787 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 7.4446754 	D(real) 0.4217574119567871 	D(fake) 1.067177677154541 	 G:  2.1077862 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 7.4455595 	D(real) 0.4215572357177734 	D(fake) 1.0675546646118164 	 G:  2.1068087 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 7.4464283 	D(real) 0.42136173248291015 	D(fake) 1.0679239273071288 	 G:  2.1058512 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 7.44728 	D(real) 0.4211702346801758 	D(fake) 1.0682857513427735 	 G:  2.104913 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 7.4465 	D(real) 0.42098259925842285 	D(fake) 1.0683174133300781 	 G:  2.1048205 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 7.446583 	D(real) 0.42096409797668455 	D(fake) 1.068352508544922 	 G:  2.1047301 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 7.4466643 	D(real) 0.4209460258483887 	D(fake) 1.0683868408203125 	 G:  2.1046405 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 7.4467444 	D(real) 0.4209280967712402 	D(fake) 1.0684207916259765 	 G:  2.1045518 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 7.4468246 	D(real) 0.4209103584289551 	D(fake) 1.0684545516967774 	 G:  2.1044636 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 7.4469037 	D(real) 0.42089271545410156 	D(fake) 1.0684880256652831 	 G:  2.1043768 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 7.446984 	D(real) 0.42087535858154296 	D(fake) 1.0685214042663573 	 G:  2.10429 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 7.4470615 	D(real) 0.42085800170898435 	D(fake) 1.0685543060302733 	 G:  2.1042035 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 7.4471397 	D(real) 0.4208407402038574 	D(fake) 1.0685872077941894 	 G:  2.104118 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 7.447218 	D(real) 0.4208236217498779 	D(fake) 1.0686199188232421 	 G:  2.1040323 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 7.4471397 	D(real) 0.4208064556121826 	D(fake) 1.06862154006958 	 G:  2.1040237 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 7.4471483 	D(real) 0.4208047389984131 	D(fake) 1.0686248779296874 	 G:  2.104015 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 7.447156 	D(real) 0.42080302238464357 	D(fake) 1.0686282157897948 	 G:  2.1040068 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 7.447163 	D(real) 0.42080135345458985 	D(fake) 1.0686312675476075 	 G:  2.1039982 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 7.4471703 	D(real) 0.42079963684082033 	D(fake) 1.0686344146728515 	 G:  2.10399 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 7.447179 	D(real) 0.42079801559448243 	D(fake) 1.068637752532959 	 G:  2.1039815 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 7.447186 	D(real) 0.4207962989807129 	D(fake) 1.068640899658203 	 G:  2.1039734 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 7.447195 	D(real) 0.420794677734375 	D(fake) 1.0686443328857422 	 G:  2.1039648 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 7.4472017 	D(real) 0.4207929611206055 	D(fake) 1.0686473846435547 	 G:  2.103956 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 7.4472084 	D(real) 0.4207911968231201 	D(fake) 1.0686504364013671 	 G:  2.1039479 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 8}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 8
\seed data:	 8
\seed noise:	 8
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018627 	loss:  -1.0380248 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018276 	loss:  1.4418166 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018059 	loss:  1.0416175 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017508 	loss:  2.881459 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017852 	loss:  2.4680402 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017838 	loss:  3.5103033 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017598 	loss:  3.641487 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017854 	loss:  4.214913 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017538 	loss:  1.3882561 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017595 	loss:  1.4474995 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017748 	loss:  -0.531749 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017799 	loss:  -0.10519807 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017898 	loss:  0.8009072 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018090 	loss:  0.62824434 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018684 	loss:  0.571278 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018431 	loss:  0.45312288 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018221 	loss:  0.41875544 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017843 	loss:  0.40157813 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017722 	loss:  0.38395342 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017966 	loss:  0.46796376 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017898 	loss:  0.39296842 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018021 	loss:  0.4315819 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018302 	loss:  0.5343483 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017832 	loss:  0.5263115 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018132 	loss:  0.4849719 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017743 	loss:  0.42587885 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017913 	loss:  0.37373132 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018177 	loss:  0.3749048 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.018292 	loss:  0.39832017 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018064 	loss:  0.3970316 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018097 	loss:  0.33891505 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018107 	loss:  0.40832093 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017618 	loss:  0.28781784 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017678 	loss:  0.25962943 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018366 	loss:  0.4149036 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017804 	loss:  0.34487414 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018183 	loss:  0.422023 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018417 	loss:  0.34823698 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017823 	loss:  0.31866306 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018573 	loss:  0.26980203 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018359 	loss:  0.30751002 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017916 	loss:  0.3841694 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018959 	loss:  0.51453984 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018084 	loss:  0.34823656 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017679 	loss:  0.4345956 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017852 	loss:  0.41912702 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017817 	loss:  0.5166642 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018208 	loss:  0.3129744 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017468 	loss:  0.2682364 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.018304 	loss:  0.54109466 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.911641
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_8/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 17.302954 	D(real) 0.8851112259758843 	D(fake) 1.0374391343858507 	 G:  6.1008053 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 14.148665 	D(real) 0.6830649905734592 	D(fake) 0.8890089458889432 	 G:  4.9675837 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 13.377949 	D(real) 0.5521154403686523 	D(fake) 0.9343233108520508 	 G:  4.496676 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 13.637021 	D(real) 0.49960676829020184 	D(fake) 1.0156177944607205 	 G:  3.998018 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 13.7537 	D(real) 0.44421524471706814 	D(fake) 1.0839736726548936 	 G:  3.7484722 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 13.841497 	D(real) 0.416496647728814 	D(fake) 1.1214475631713867 	 G:  3.613819 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 13.896486 	D(real) 0.40153593487209743 	D(fake) 1.1425181494818792 	 G:  3.544379 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 13.900675 	D(real) 0.39382052421569824 	D(fake) 1.1506988737318251 	 G:  3.528579 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 13.860062 	D(real) 0.392064889272054 	D(fake) 1.1479420132107205 	 G:  3.554082 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 13.792298 	D(real) 0.39489905039469403 	D(fake) 1.1375785403781467 	 G:  3.6050348 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 13.595135 	D(real) 0.4005596902635362 	D(fake) 1.110010888841417 	 G:  3.6106532 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 13.589085 	D(real) 0.4011843469407823 	D(fake) 1.1087138917711046 	 G:  3.6159658 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 13.583516 	D(real) 0.40177493625217015 	D(fake) 1.1075046327379015 	 G:  3.6209493 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 13.578442 	D(real) 0.4023279613918728 	D(fake) 1.106387774149577 	 G:  3.6255665 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 13.573839 	D(real) 0.4028409851921929 	D(fake) 1.1053633160061307 	 G:  3.6298091 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 13.569696 	D(real) 0.40331244468688965 	D(fake) 1.1044315761990018 	 G:  3.6336682 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 13.565994 	D(real) 0.40374135971069336 	D(fake) 1.1035912831624348 	 G:  3.6371472 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 13.562714 	D(real) 0.40412794219122994 	D(fake) 1.1028402116563585 	 G:  3.6402512 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 13.559843 	D(real) 0.40447280142042374 	D(fake) 1.1021764543321397 	 G:  3.6429882 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 13.557333 	D(real) 0.40477728843688965 	D(fake) 1.101593017578125 	 G:  3.6453853 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 13.541972 	D(real) 0.40504317813449436 	D(fake) 1.099620395236545 	 G:  3.64559 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 13.541799 	D(real) 0.40506598684522843 	D(fake) 1.0995783276028104 	 G:  3.6457605 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 13.541645 	D(real) 0.40508516629536945 	D(fake) 1.099542087978787 	 G:  3.6459088 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 13.541514 	D(real) 0.4051014847225613 	D(fake) 1.099511252509223 	 G:  3.6460345 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 13.541405 	D(real) 0.4051153924730089 	D(fake) 1.0994850794474285 	 G:  3.646143 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 13.541304 	D(real) 0.4051274193657769 	D(fake) 1.0994618733723958 	 G:  3.6462388 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 13.541223 	D(real) 0.40513790978325737 	D(fake) 1.099442376030816 	 G:  3.6463194 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 13.541145 	D(real) 0.40514704916212296 	D(fake) 1.099424680074056 	 G:  3.6463938 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 13.54111 	D(real) 0.4051551553938124 	D(fake) 1.0994126001993816 	 G:  3.646443 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 13.54102 	D(real) 0.4051623609330919 	D(fake) 1.0993954340616863 	 G:  3.6465168 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 13.539537 	D(real) 0.4051688247256809 	D(fake) 1.0992241965399847 	 G:  3.646519 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 13.539527 	D(real) 0.4051694869995117 	D(fake) 1.099222395155165 	 G:  3.646527 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 13.539521 	D(real) 0.4051700168185764 	D(fake) 1.0992212295532227 	 G:  3.6465316 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 13.53952 	D(real) 0.4051704936557346 	D(fake) 1.099220699734158 	 G:  3.6465342 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 13.539517 	D(real) 0.40517094400193954 	D(fake) 1.0992198520236545 	 G:  3.6465366 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 13.539512 	D(real) 0.4051713678571913 	D(fake) 1.0992187923855252 	 G:  3.6465418 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 13.539504 	D(real) 0.4051716857486301 	D(fake) 1.099217626783583 	 G:  3.6465468 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 13.5395 	D(real) 0.40517213609483504 	D(fake) 1.0992167790730794 	 G:  3.6465502 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 13.539498 	D(real) 0.4051724274953206 	D(fake) 1.0992162492540147 	 G:  3.646553 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 13.539495 	D(real) 0.4051728778415256 	D(fake) 1.0992155075073242 	 G:  3.6465561 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 13.539352 	D(real) 0.40517324871487087 	D(fake) 1.0991991890801325 	 G:  3.646555 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 13.5393505 	D(real) 0.40517324871487087 	D(fake) 1.0991989771525066 	 G:  3.6465554 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 13.539347 	D(real) 0.40517324871487087 	D(fake) 1.0991985532972548 	 G:  3.6465569 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 13.539347 	D(real) 0.40517330169677734 	D(fake) 1.0991985532972548 	 G:  3.6465578 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 13.539349 	D(real) 0.4051733546786838 	D(fake) 1.0991987652248807 	 G:  3.6465564 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 13.539345 	D(real) 0.4051733546786838 	D(fake) 1.099198341369629 	 G:  3.6465583 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 13.539349 	D(real) 0.4051733546786838 	D(fake) 1.0991986592610676 	 G:  3.6465561 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 13.539346 	D(real) 0.405173381169637 	D(fake) 1.099198341369629 	 G:  3.6465578 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 13.539348 	D(real) 0.4051734341515435 	D(fake) 1.0991985532972548 	 G:  3.6465573 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 13.539349 	D(real) 0.40517348713344997 	D(fake) 1.0991985532972548 	 G:  3.6465573 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 9}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 9
\seed data:	 9
\seed noise:	 9
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.017874 	loss:  -1.925236 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017765 	loss:  2.660467 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017445 	loss:  4.4317 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017447 	loss:  4.031353 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017334 	loss:  3.7457511 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017461 	loss:  3.576115 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017797 	loss:  3.773704 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017179 	loss:  4.945759 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017787 	loss:  5.2030888 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017769 	loss:  5.746018 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017142 	loss:  4.888906 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017171 	loss:  4.888912 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017592 	loss:  4.1079726 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017374 	loss:  4.7460284 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017405 	loss:  5.5745783 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017638 	loss:  4.945988 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017450 	loss:  4.917415 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017540 	loss:  4.717413 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018133 	loss:  4.7174106 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017363 	loss:  4.54598 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018202 	loss:  4.4888353 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017380 	loss:  4.488833 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017138 	loss:  4.545973 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017150 	loss:  4.4031134 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017403 	loss:  4.403111 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017314 	loss:  4.403108 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017542 	loss:  4.3459625 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018205 	loss:  4.34596 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017140 	loss:  4.231672 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017519 	loss:  4.2316694 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018054 	loss:  4.231667 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017181 	loss:  4.4888096 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017270 	loss:  4.3045173 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017842 	loss:  4.3459516 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017138 	loss:  4.488809 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017367 	loss:  4.3595905 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017189 	loss:  4.4888086 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017677 	loss:  4.41544 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017624 	loss:  4.488808 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017693 	loss:  4.581245 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017126 	loss:  4.517379 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017470 	loss:  4.5173783 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017365 	loss:  4.660235 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017830 	loss:  4.660235 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017360 	loss:  4.6602345 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017378 	loss:  4.6602345 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017152 	loss:  4.6602345 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017449 	loss:  4.6602345 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017715 	loss:  4.6602345 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017608 	loss:  4.6602345 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.049616
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_9/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 10.852821 	D(real) 0.6662518637520927 	D(fake) 0.8841511181422642 	 G:  4.4217224 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 11.592516 	D(real) 0.6316506522042411 	D(fake) 1.0244229861668177 	 G:  3.1932206 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 11.125142 	D(real) 0.4554059164864676 	D(fake) 1.1339000974382674 	 G:  2.782899 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 10.920517 	D(real) 0.397594724382673 	D(fake) 1.1624791281563895 	 G:  2.8001902 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 10.705786 	D(real) 0.4000945772443499 	D(fake) 1.1293034553527832 	 G:  2.931077 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 10.557849 	D(real) 0.418769155229841 	D(fake) 1.0894949776785714 	 G:  3.0391767 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 10.505272 	D(real) 0.43419221469334196 	D(fake) 1.066560881478446 	 G:  3.0663815 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 10.521957 	D(real) 0.4380654607500349 	D(fake) 1.0650713784354073 	 G:  3.023368 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 10.557451 	D(real) 0.43191538538251606 	D(fake) 1.076291901724679 	 G:  2.9641867 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 10.574111 	D(real) 0.42345758846827913 	D(fake) 1.087129729134696 	 G:  2.9347649 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 10.44952 	D(real) 0.419252838407244 	D(fake) 1.073535782950265 	 G:  2.9331176 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 10.452007 	D(real) 0.41901728085109163 	D(fake) 1.0741265841892786 	 G:  2.9303122 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 10.455439 	D(real) 0.41861636298043386 	D(fake) 1.0750177247183663 	 G:  2.9265497 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 10.459614 	D(real) 0.418079103742327 	D(fake) 1.0761513710021973 	 G:  2.9220312 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 10.464353 	D(real) 0.41743346623011995 	D(fake) 1.0774740491594588 	 G:  2.916942 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 10.469493 	D(real) 0.41670639174325125 	D(fake) 1.0789354188101632 	 G:  2.911456 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 10.474889 	D(real) 0.41592267581394743 	D(fake) 1.0804899760654993 	 G:  2.905729 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 10.480412 	D(real) 0.41510438919067383 	D(fake) 1.0820972578866142 	 G:  2.899896 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 10.485949 	D(real) 0.41427128655569895 	D(fake) 1.083721365247454 	 G:  2.8940756 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 10.4914055 	D(real) 0.41343964849199566 	D(fake) 1.0853325980050224 	 G:  2.8883648 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 10.48122 	D(real) 0.41262381417410715 	D(fake) 1.084693363734654 	 G:  2.8878088 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 10.481735 	D(real) 0.41254448890686035 	D(fake) 1.0848462922232491 	 G:  2.8872685 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 10.482241 	D(real) 0.4124672072274344 	D(fake) 1.0849957466125488 	 G:  2.8867395 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 10.482737 	D(real) 0.41239166259765625 	D(fake) 1.0851421356201172 	 G:  2.886222 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 10.483224 	D(real) 0.41231775283813477 	D(fake) 1.0852856636047363 	 G:  2.8857138 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 10.483704 	D(real) 0.4122451032911028 	D(fake) 1.0854268755231584 	 G:  2.8852143 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 10.484175 	D(real) 0.4121737480163574 	D(fake) 1.0855654988970076 	 G:  2.884723 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 10.484643 	D(real) 0.41210358483450754 	D(fake) 1.085702555520194 	 G:  2.8842382 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 10.485102 	D(real) 0.41203430720738005 	D(fake) 1.0858372960771834 	 G:  2.8837605 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 10.485556 	D(real) 0.4119660513741629 	D(fake) 1.085970401763916 	 G:  2.8832884 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 10.484533 	D(real) 0.41189868109566824 	D(fake) 1.0858918598720007 	 G:  2.8832417 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 10.484579 	D(real) 0.4118920053754534 	D(fake) 1.085904938834054 	 G:  2.8831964 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 10.484622 	D(real) 0.41188532965523855 	D(fake) 1.0859178134373255 	 G:  2.88315 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 10.484667 	D(real) 0.4118788582938058 	D(fake) 1.085930619921003 	 G:  2.8831048 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 10.484709 	D(real) 0.411872352872576 	D(fake) 1.0859432220458984 	 G:  2.8830597 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 10.484754 	D(real) 0.4118658815111433 	D(fake) 1.08595609664917 	 G:  2.8830144 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 10.484797 	D(real) 0.4118594782693045 	D(fake) 1.0859685625348772 	 G:  2.88297 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 10.484841 	D(real) 0.4118530750274658 	D(fake) 1.0859813690185547 	 G:  2.8829248 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 10.484882 	D(real) 0.4118466717856271 	D(fake) 1.0859936305454798 	 G:  2.8828802 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 10.484925 	D(real) 0.4118403707231794 	D(fake) 1.0860060964311873 	 G:  2.8828359 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 10.484822 	D(real) 0.4118339334215437 	D(fake) 1.0859978539603097 	 G:  2.8828309 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 10.484827 	D(real) 0.4118332862854004 	D(fake) 1.0859990801130022 	 G:  2.8828266 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 10.484832 	D(real) 0.4118326391492571 	D(fake) 1.0860004425048828 	 G:  2.8828223 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 10.484836 	D(real) 0.4118321282523019 	D(fake) 1.0860015324183874 	 G:  2.8828177 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 10.4848385 	D(real) 0.4118314470563616 	D(fake) 1.0860026904514857 	 G:  2.882814 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 10.484845 	D(real) 0.41183086803981234 	D(fake) 1.0860041209629603 	 G:  2.8828096 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 10.484848 	D(real) 0.4118302209036691 	D(fake) 1.0860052108764648 	 G:  2.8828049 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 10.484854 	D(real) 0.41182964188711985 	D(fake) 1.0860065732683455 	 G:  2.8828008 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 10.484857 	D(real) 0.4118289606911795 	D(fake) 1.0860076631818498 	 G:  2.8827963 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 10.484862 	D(real) 0.41182844979422434 	D(fake) 1.0860090255737305 	 G:  2.8827915 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 10}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 10
\seed data:	 10
\seed noise:	 10
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018529 	loss:  -1.9973075 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018198 	loss:  -2.149838 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017906 	loss:  1.3280708 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017715 	loss:  3.316561 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017208 	loss:  3.4118059 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017271 	loss:  3.6212707 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017652 	loss:  3.6783164 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017729 	loss:  3.2779815 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017536 	loss:  3.277767 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017938 	loss:  3.335639 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018235 	loss:  2.2690597 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017497 	loss:  1.602406 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017341 	loss:  2.9665132 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017776 	loss:  3.8338773 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017206 	loss:  3.128046 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017572 	loss:  2.5597954 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017815 	loss:  2.0975027 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017829 	loss:  2.070816 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017284 	loss:  1.9152493 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017630 	loss:  1.8879694 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018109 	loss:  1.94671 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017719 	loss:  1.9070095 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017662 	loss:  1.8730291 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017317 	loss:  1.8498597 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017659 	loss:  1.8308091 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017211 	loss:  1.9831874 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017592 	loss:  1.9931095 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017666 	loss:  2.2308023 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017715 	loss:  2.7069907 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017529 	loss:  2.9355607 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017642 	loss:  3.1450834 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017469 	loss:  3.0688932 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017685 	loss:  2.9927025 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018918 	loss:  3.0523617 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017630 	loss:  3.164131 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017677 	loss:  3.2022257 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018033 	loss:  3.1831782 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017294 	loss:  3.2022254 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017817 	loss:  3.2974637 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017949 	loss:  3.4498446 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017261 	loss:  3.468892 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017985 	loss:  3.4688919 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017439 	loss:  3.5260346 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017806 	loss:  3.5587819 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018166 	loss:  3.5641298 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017301 	loss:  3.5641296 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017575 	loss:  3.5641296 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017512 	loss:  3.6140935 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018735 	loss:  3.5641296 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017291 	loss:  3.5470266 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.809074
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_10/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 13.81093 	D(real) 0.7581057548522949 	D(fake) 0.9682604670524597 	 G:  5.639242 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 12.865135 	D(real) 0.7052914500236511 	D(fake) 0.9028503894805908 	 G:  3.5441678 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 12.996751 	D(real) 0.4430318772792816 	D(fake) 1.1815619468688965 	 G:  2.7901092 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 13.0503 	D(real) 0.348764032125473 	D(fake) 1.2825233936309814 	 G:  2.6677277 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 12.838331 	D(real) 0.3334656059741974 	D(fake) 1.2713258266448975 	 G:  2.8348289 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 12.427635 	D(real) 0.3543529510498047 	D(fake) 1.199101448059082 	 G:  3.1459575 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 12.041286 	D(real) 0.3932441473007202 	D(fake) 1.1119166612625122 	 G:  3.4593184 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 11.832511 	D(real) 0.4324144423007965 	D(fake) 1.04664945602417 	 G:  3.6564379 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 11.800641 	D(real) 0.45705458521842957 	D(fake) 1.018025517463684 	 G:  3.6928668 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 11.880536 	D(real) 0.4616081714630127 	D(fake) 1.0234588384628296 	 G:  3.598138 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 11.751232 	D(real) 0.44976723194122314 	D(fake) 1.0191367864608765 	 G:  3.5817351 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 11.768031 	D(real) 0.44771695137023926 	D(fake) 1.0232869386672974 	 G:  3.5606039 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 11.787317 	D(real) 0.44507530331611633 	D(fake) 1.0283393859863281 	 G:  3.536422 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 11.808203 	D(real) 0.4420526623725891 	D(fake) 1.0339726209640503 	 G:  3.5105183 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 11.829965 	D(real) 0.43881475925445557 	D(fake) 1.039930820465088 	 G:  3.4839296 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 11.852013 	D(real) 0.435491144657135 	D(fake) 1.0460104942321777 	 G:  3.4574547 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 11.87386 	D(real) 0.432181715965271 	D(fake) 1.0520508289337158 	 G:  3.4316967 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 11.89511 	D(real) 0.42896202206611633 	D(fake) 1.0579267740249634 	 G:  3.4070997 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 11.915453 	D(real) 0.42588740587234497 	D(fake) 1.0635442733764648 	 G:  3.383976 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 11.934645 	D(real) 0.4229969382286072 	D(fake) 1.068833589553833 	 G:  3.3625307 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 11.92233 	D(real) 0.42031633853912354 	D(fake) 1.0699748992919922 	 G:  3.3605561 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 11.92399 	D(real) 0.42006951570510864 	D(fake) 1.0704293251037598 	 G:  3.3587244 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 11.925552 	D(real) 0.41984039545059204 	D(fake) 1.0708537101745605 	 G:  3.357008 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 11.927029 	D(real) 0.4196259379386902 	D(fake) 1.0712525844573975 	 G:  3.355391 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 11.928429 	D(real) 0.41942381858825684 	D(fake) 1.0716297626495361 	 G:  3.3538582 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 11.929773 	D(real) 0.41923215985298157 	D(fake) 1.0719895362854004 	 G:  3.3523924 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 11.93106 	D(real) 0.41904905438423157 	D(fake) 1.0723334550857544 	 G:  3.3509884 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 11.932304 	D(real) 0.41887348890304565 	D(fake) 1.0726646184921265 	 G:  3.3496351 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 11.933512 	D(real) 0.4187043607234955 	D(fake) 1.0729845762252808 	 G:  3.3483257 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 11.934681 	D(real) 0.41854068636894226 	D(fake) 1.0732944011688232 	 G:  3.3470554 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 11.933465 	D(real) 0.41838183999061584 	D(fake) 1.0733013153076172 	 G:  3.3469315 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 11.9335785 	D(real) 0.41836637258529663 	D(fake) 1.0733308792114258 	 G:  3.3468103 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 11.933687 	D(real) 0.4183512330055237 	D(fake) 1.073359727859497 	 G:  3.346692 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 11.933796 	D(real) 0.418336421251297 	D(fake) 1.0733880996704102 	 G:  3.3465745 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 11.933903 	D(real) 0.41832178831100464 	D(fake) 1.0734161138534546 	 G:  3.3464594 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 11.934008 	D(real) 0.418307363986969 	D(fake) 1.0734435319900513 	 G:  3.3463452 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 11.934113 	D(real) 0.4182929992675781 	D(fake) 1.0734710693359375 	 G:  3.3462315 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 11.934219 	D(real) 0.41827890276908875 	D(fake) 1.0734984874725342 	 G:  3.3461192 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 11.934322 	D(real) 0.418264776468277 	D(fake) 1.0735255479812622 	 G:  3.3460069 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 11.934423 	D(real) 0.41825082898139954 	D(fake) 1.073552131652832 	 G:  3.3458967 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 11.934301 	D(real) 0.41823694109916687 	D(fake) 1.0735507011413574 	 G:  3.3458848 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 11.934311 	D(real) 0.41823557019233704 	D(fake) 1.0735533237457275 	 G:  3.3458745 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 11.934321 	D(real) 0.4182342290878296 	D(fake) 1.0735559463500977 	 G:  3.3458643 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 11.934332 	D(real) 0.41823285818099976 	D(fake) 1.0735585689544678 	 G:  3.3458529 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 11.934343 	D(real) 0.41823145747184753 	D(fake) 1.073561429977417 	 G:  3.3458414 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 11.934354 	D(real) 0.4182301461696625 	D(fake) 1.073564052581787 	 G:  3.3458304 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 11.934361 	D(real) 0.41822871565818787 	D(fake) 1.0735664367675781 	 G:  3.34582 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 11.934372 	D(real) 0.4182273745536804 	D(fake) 1.0735691785812378 	 G:  3.3458087 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 11.934383 	D(real) 0.41822606325149536 	D(fake) 1.0735719203948975 	 G:  3.3457978 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 11.934391 	D(real) 0.41822466254234314 	D(fake) 1.073574185371399 	 G:  3.3457878 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 11}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 11
\seed data:	 11
\seed noise:	 11
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.019172 	loss:  -1.1709912 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018593 	loss:  1.0688653 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018725 	loss:  1.3984011 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018089 	loss:  3.279482 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018434 	loss:  2.7071435 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.018434 	loss:  4.171096 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017946 	loss:  4.1228476 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.018059 	loss:  4.8734155 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018176 	loss:  4.840641 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018019 	loss:  3.2990541 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018304 	loss:  -1.0165982 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018243 	loss:  -2.1858776 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.018928 	loss:  -2.6694467 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018224 	loss:  -2.3991973 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018688 	loss:  -1.4401579 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018649 	loss:  -0.77610004 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017957 	loss:  -0.7102866 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018502 	loss:  -0.58159894 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018511 	loss:  -0.70468974 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.018341 	loss:  -0.5452715 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018220 	loss:  -0.6651453 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018296 	loss:  -0.5745899 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018444 	loss:  -0.743023 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018609 	loss:  -0.723224 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018362 	loss:  -0.73902214 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018799 	loss:  -0.73107904 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018036 	loss:  -0.64180046 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018140 	loss:  -1.0425069 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.018151 	loss:  -0.99268454 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018193 	loss:  -1.1819239 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018104 	loss:  -1.3923597 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018553 	loss:  -1.21669 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018421 	loss:  -1.3375237 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018280 	loss:  -1.3552049 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018327 	loss:  -1.20384 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018509 	loss:  -1.3490063 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018980 	loss:  -1.2665608 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.019371 	loss:  -1.2811794 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018344 	loss:  -1.2421488 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018237 	loss:  -1.2987442 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018475 	loss:  -1.3137665 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018118 	loss:  -1.1645362 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018487 	loss:  -1.3342923 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018322 	loss:  -1.391766 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018245 	loss:  -1.2988038 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018238 	loss:  -1.3226551 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018070 	loss:  -1.2713954 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018490 	loss:  -1.470071 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018347 	loss:  -1.4494313 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.018354 	loss:  -1.3260497 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.072112
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_11/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 20.580431 	D(real) 0.4703467845916748 	D(fake) 1.5876962661743164 	 G:  4.2414923 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 16.471699 	D(real) 0.4247270584106445 	D(fake) 1.2224427223205567 	 G:  3.762495 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 15.744446 	D(real) 0.3762979030609131 	D(fake) 1.1981466293334961 	 G:  3.829266 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 15.412285 	D(real) 0.38290865421295167 	D(fake) 1.158319854736328 	 G:  3.9840708 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 15.210035 	D(real) 0.398380446434021 	D(fake) 1.1226230621337892 	 G:  4.127973 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 15.078321 	D(real) 0.4127814769744873 	D(fake) 1.0950507164001464 	 G:  4.2405195 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 15.004841 	D(real) 0.4240295886993408 	D(fake) 1.0764544486999512 	 G:  4.310523 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 14.985524 	D(real) 0.4310284614562988 	D(fake) 1.0675239562988281 	 G:  4.3313775 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 15.013441 	D(real) 0.43311028480529784 	D(fake) 1.0682338714599608 	 G:  4.3040667 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 15.075451 	D(real) 0.4303892612457275 	D(fake) 1.0771557807922363 	 G:  4.240142 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 14.893552 	D(real) 0.4239941596984863 	D(fake) 1.0653610229492188 	 G:  4.2312026 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 14.903433 	D(real) 0.4230926513671875 	D(fake) 1.067250633239746 	 G:  4.2200966 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 14.914701 	D(real) 0.4219816207885742 	D(fake) 1.069488525390625 	 G:  4.207588 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 14.9268265 	D(real) 0.42073235511779783 	D(fake) 1.071950340270996 	 G:  4.1942663 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 14.939173 	D(real) 0.4194022655487061 	D(fake) 1.0745150566101074 	 G:  4.18071 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 14.951847 	D(real) 0.41803817749023436 	D(fake) 1.0771465301513672 	 G:  4.1670585 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 14.9642 	D(real) 0.41667728424072265 	D(fake) 1.07974271774292 	 G:  4.153799 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 14.976198 	D(real) 0.4153486728668213 	D(fake) 1.082271194458008 	 G:  4.141055 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 14.987665 	D(real) 0.4140749454498291 	D(fake) 1.084691619873047 	 G:  4.129002 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 14.998354 	D(real) 0.412872838973999 	D(fake) 1.0869625091552735 	 G:  4.117817 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 14.981484 	D(real) 0.41175413131713867 	D(fake) 1.0863943099975586 	 G:  4.1167817 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 14.9823265 	D(real) 0.4116506099700928 	D(fake) 1.086582088470459 	 G:  4.115856 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 14.983287 	D(real) 0.41155376434326174 	D(fake) 1.0867749214172364 	 G:  4.1149 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 14.983942 	D(real) 0.4114626407623291 	D(fake) 1.0869316101074218 	 G:  4.114124 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 14.984753 	D(real) 0.4113763332366943 	D(fake) 1.0870988845825196 	 G:  4.1132917 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 14.985646 	D(real) 0.41129398345947266 	D(fake) 1.0872706413269042 	 G:  4.112433 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 14.986331 	D(real) 0.41121511459350585 	D(fake) 1.087417984008789 	 G:  4.111698 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 14.986893 	D(real) 0.4111391544342041 	D(fake) 1.0875500679016112 	 G:  4.1110377 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 14.987512 	D(real) 0.41106576919555665 	D(fake) 1.0876853942871094 	 G:  4.1103597 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 14.988327 	D(real) 0.4109945297241211 	D(fake) 1.0878381729125977 	 G:  4.1095924 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 14.986614 	D(real) 0.41092514991760254 	D(fake) 1.0877363204956054 	 G:  4.109542 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 14.986827 	D(real) 0.4109184265136719 	D(fake) 1.0877642631530762 	 G:  4.1094003 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 14.986816 	D(real) 0.41091175079345704 	D(fake) 1.0877698898315429 	 G:  4.1093726 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 14.986717 	D(real) 0.4109051704406738 	D(fake) 1.0877665519714355 	 G:  4.10939 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 14.987064 	D(real) 0.4108987331390381 	D(fake) 1.0878077507019044 	 G:  4.1091805 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 14.986846 	D(real) 0.410892391204834 	D(fake) 1.087792205810547 	 G:  4.10926 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 14.986946 	D(real) 0.4108860492706299 	D(fake) 1.0878085136413573 	 G:  4.109177 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 14.987156 	D(real) 0.41087980270385743 	D(fake) 1.0878357887268066 	 G:  4.1090393 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 14.987224 	D(real) 0.4108735084533691 	D(fake) 1.0878488540649414 	 G:  4.1089725 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 14.987117 	D(real) 0.4108673095703125 	D(fake) 1.0878443717956543 	 G:  4.108995 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 14.987025 	D(real) 0.41086111068725584 	D(fake) 1.0878414154052733 	 G:  4.1089506 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 14.986845 	D(real) 0.4108604907989502 	D(fake) 1.0878239631652833 	 G:  4.1090393 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 14.987003 	D(real) 0.41085991859436033 	D(fake) 1.0878403663635254 	 G:  4.1089563 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 14.986937 	D(real) 0.4108592987060547 	D(fake) 1.087834358215332 	 G:  4.1089864 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 14.987054 	D(real) 0.4108586311340332 	D(fake) 1.0878467559814453 	 G:  4.108923 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 14.986841 	D(real) 0.4108580589294434 	D(fake) 1.0878260612487793 	 G:  4.109029 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 14.987097 	D(real) 0.4108574390411377 	D(fake) 1.0878522872924805 	 G:  4.1088953 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 14.986989 	D(real) 0.410856819152832 	D(fake) 1.087842082977295 	 G:  4.108947 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 14.987038 	D(real) 0.410856294631958 	D(fake) 1.0878474235534668 	 G:  4.10892 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 14.987028 	D(real) 0.4108555793762207 	D(fake) 1.0878472328186035 	 G:  4.1089215 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 12}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 12
\seed data:	 12
\seed noise:	 12
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.019666 	loss:  -0.79849494 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.019339 	loss:  -0.82671565 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018418 	loss:  3.701216 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018497 	loss:  3.846613 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018570 	loss:  5.0536146 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.018793 	loss:  5.3787675 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018094 	loss:  6.0503078 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.018155 	loss:  3.410574 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018084 	loss:  4.346079 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018242 	loss:  4.6657743 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018651 	loss:  5.200826 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018049 	loss:  5.1814313 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.018006 	loss:  5.1812606 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018201 	loss:  4.6268516 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018014 	loss:  3.8413599 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018370 	loss:  2.7441473 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018837 	loss:  2.608376 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017928 	loss:  2.6471386 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018087 	loss:  2.841064 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.018524 	loss:  3.3550048 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018000 	loss:  3.2869236 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018256 	loss:  3.7440648 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017986 	loss:  3.841315 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018993 	loss:  3.967355 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017940 	loss:  4.2194595 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018105 	loss:  4.7236977 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018230 	loss:  4.655676 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018097 	loss:  4.666966 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017800 	loss:  4.7739472 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018007 	loss:  4.725453 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018654 	loss:  4.647877 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018209 	loss:  4.5412107 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018004 	loss:  4.4830294 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018042 	loss:  4.492726 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018033 	loss:  4.5315137 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.019037 	loss:  4.589695 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018645 	loss:  4.5896945 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018301 	loss:  4.589694 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018501 	loss:  4.589693 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018437 	loss:  4.5315113 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018039 	loss:  4.4830256 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018865 	loss:  4.492722 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018133 	loss:  4.4927216 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018587 	loss:  4.5315094 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018060 	loss:  4.5606 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018081 	loss:  4.541206 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018719 	loss:  4.5412054 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018042 	loss:  4.5412054 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017991 	loss:  4.5412054 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017852 	loss:  4.5509024 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.072028
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_12/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 17.159573 	D(real) 0.6508097648620605 	D(fake) 1.0651473999023438 	 G:  5.218652 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 15.08938 	D(real) 0.5203020095825195 	D(fake) 0.9886360168457031 	 G:  4.864093 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 15.006546 	D(real) 0.48421454429626465 	D(fake) 1.0164400100708009 	 G:  4.6436753 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 14.97773 	D(real) 0.45970330238342283 	D(fake) 1.038069725036621 	 G:  4.4753523 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 14.517616 	D(real) 0.4217220783233643 	D(fake) 1.0300395011901855 	 G:  4.8984137 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 14.069987 	D(real) 0.3745142936706543 	D(fake) 1.0324844360351562 	 G:  5.403103 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 13.535755 	D(real) 0.33661446571350095 	D(fake) 1.0169610023498534 	 G:  5.4933915 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 12.377977 	D(real) 0.27796759605407717 	D(fake) 0.9598301887512207 	 G:  6.6458187 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 16.284113 	D(real) 0.19708602428436278 	D(fake) 1.4313252449035645 	 G:  4.8451457 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 14.751729 	D(real) 0.16434624195098876 	D(fake) 1.3108266830444335 	 G:  6.442103 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 9.347081 	D(real) 0.18663452863693236 	D(fake) 0.7480735778808594 	 G:  10.113907 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 12.108208 	D(real) 0.18695806264877318 	D(fake) 1.0238627433776855 	 G:  7.697601 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 9.467494 	D(real) 0.18820165395736693 	D(fake) 0.7585477828979492 	 G:  10.176048 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 14.1046505 	D(real) 0.19174442291259766 	D(fake) 1.2187206268310546 	 G:  6.8227453 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 13.772855 	D(real) 0.19323995113372802 	D(fake) 1.1840455055236816 	 G:  6.9887977 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 12.378712 	D(real) 0.19502012729644774 	D(fake) 1.0428510665893556 	 G:  8.327231 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 7.649813 	D(real) 0.1957199454307556 	D(fake) 0.5692613601684571 	 G:  12.365065 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 8.62251 	D(real) 0.1915298342704773 	D(fake) 0.6707211494445801 	 G:  11.238842 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 16.54611 	D(real) 0.18633886575698852 	D(fake) 1.4682721138000487 	 G:  4.6463757 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 12.132613 	D(real) 0.18682534694671632 	D(fake) 1.026435947418213 	 G:  8.793613 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 10.571209 	D(real) 0.191228449344635 	D(fake) 0.8658924102783203 	 G:  10.176571 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 16.813864 	D(real) 0.19148105382919312 	D(fake) 1.4899052619934081 	 G:  4.607334 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 11.277708 	D(real) 0.19179816246032716 	D(fake) 0.9359725952148438 	 G:  9.050329 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 7.8778315 	D(real) 0.1925150752067566 	D(fake) 0.5952680587768555 	 G:  12.134226 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 13.340544 	D(real) 0.19333844184875487 	D(fake) 1.140715980529785 	 G:  7.5146227 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 9.854085 	D(real) 0.1941760540008545 	D(fake) 0.7912324428558349 	 G:  10.442252 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 12.507921 	D(real) 0.19512360095977782 	D(fake) 1.055668544769287 	 G:  7.999815 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 10.272587 	D(real) 0.19622786045074464 	D(fake) 0.8310308456420898 	 G:  10.357087 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 10.447414 	D(real) 0.19731954336166382 	D(fake) 0.847421932220459 	 G:  10.326874 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 13.221825 	D(real) 0.19807716608047485 	D(fake) 1.1241052627563477 	 G:  7.611554 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 13.209829 	D(real) 0.19878315925598145 	D(fake) 1.122199821472168 	 G:  7.5727367 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 15.177867 	D(real) 0.19887784719467164 	D(fake) 1.3189088821411132 	 G:  6.081594 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 12.087558 	D(real) 0.19898178577423095 	D(fake) 1.0097740173339844 	 G:  8.912802 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 13.171444 	D(real) 0.19906636476516723 	D(fake) 1.1180780410766602 	 G:  7.6262655 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 11.964065 	D(real) 0.19914731979370118 	D(fake) 0.9972591400146484 	 G:  8.846228 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 7.749256 	D(real) 0.1992296576499939 	D(fake) 0.5756959438323974 	 G:  12.222507 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 13.61523 	D(real) 0.19929171800613404 	D(fake) 1.1622312545776368 	 G:  7.4022098 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 10.483457 	D(real) 0.1993427872657776 	D(fake) 0.8490028381347656 	 G:  10.315105 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 11.759432 	D(real) 0.19937299489974974 	D(fake) 0.9765702247619629 	 G:  8.977099 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 12.114918 	D(real) 0.19938979148864747 	D(fake) 1.012101936340332 	 G:  8.778783 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 11.97487 	D(real) 0.19940303564071654 	D(fake) 0.9980839729309082 	 G:  8.791828 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 8.95281 	D(real) 0.19940361976623536 	D(fake) 0.6958774089813232 	 G:  11.757268 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 7.445766 	D(real) 0.1994016170501709 	D(fake) 0.5451749801635742 	 G:  12.882616 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 14.709888 	D(real) 0.1993952512741089 	D(fake) 1.2715935707092285 	 G:  6.1963496 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 11.929349 	D(real) 0.19939054250717164 	D(fake) 0.9935443878173829 	 G:  8.952987 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 8.871889 	D(real) 0.19938879013061522 	D(fake) 0.6878000736236572 	 G:  11.7616205 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 7.405953 	D(real) 0.19938483238220214 	D(fake) 0.5412104606628418 	 G:  13.089514 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 10.466056 	D(real) 0.19937647581100465 	D(fake) 0.8472290992736816 	 G:  10.349069 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 15.174412 	D(real) 0.199365234375 	D(fake) 1.318075942993164 	 G:  6.090204 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 7.3115387 	D(real) 0.19935553073883056 	D(fake) 0.5317983627319336 	 G:  13.195445 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 13}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 13
\seed data:	 13
\seed noise:	 13
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018534 	loss:  -0.43610054 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017825 	loss:  -0.6396186 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017339 	loss:  4.2461963 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017184 	loss:  4.790824 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017223 	loss:  4.4763637 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017385 	loss:  3.9306445 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017811 	loss:  3.4465666 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017642 	loss:  4.030476 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017538 	loss:  4.1620593 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017202 	loss:  1.219289 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017342 	loss:  -0.12535004 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017412 	loss:  0.48776874 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017444 	loss:  2.5333214 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018012 	loss:  2.9742126 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017877 	loss:  3.0156195 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017299 	loss:  2.5584505 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017243 	loss:  2.3870194 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017551 	loss:  2.3298736 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018461 	loss:  2.4163609 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017113 	loss:  2.5020723 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.016957 	loss:  2.5020692 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017811 	loss:  2.5020661 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017774 	loss:  2.5306344 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.016938 	loss:  2.50206 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017120 	loss:  2.5020566 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017254 	loss:  2.5020533 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017360 	loss:  2.5020502 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017250 	loss:  2.5020468 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017894 	loss:  2.5591865 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017483 	loss:  2.4163265 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017694 	loss:  2.473466 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017018 	loss:  2.4734654 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.016995 	loss:  2.4734652 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017181 	loss:  2.4448934 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017915 	loss:  2.5020359 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017978 	loss:  2.5020356 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017686 	loss:  2.5020351 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017795 	loss:  2.502035 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017004 	loss:  2.5020347 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017739 	loss:  2.5020342 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017778 	loss:  2.502034 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017292 	loss:  2.521103 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017030 	loss:  2.5877473 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017849 	loss:  2.5877469 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017524 	loss:  2.5877466 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017515 	loss:  2.5877464 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017062 	loss:  2.5877464 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017370 	loss:  2.5877461 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017634 	loss:  2.6191618 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017308 	loss:  2.644889 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.007186
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_13/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 14.032612 	D(real) 0.4909602233341762 	D(fake) 1.5136985778808594 	 G:  2.6463513 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 11.192257 	D(real) 0.38086683409554617 	D(fake) 1.218026978628976 	 G:  2.8243008 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 10.632655 	D(real) 0.40349224635532926 	D(fake) 1.1154584884643555 	 G:  3.0758662 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 10.419801 	D(real) 0.43939716475350515 	D(fake) 1.0491457666669572 	 G:  3.2172468 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 10.38227 	D(real) 0.459604161126273 	D(fake) 1.0235772814069475 	 G:  3.2324204 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 10.430542 	D(real) 0.4617757116045271 	D(fake) 1.028301783970424 	 G:  3.159978 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 10.528691 	D(real) 0.45142660822187153 	D(fake) 1.0526721136910575 	 G:  3.0350296 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 10.643583 	D(real) 0.4335763454437256 	D(fake) 1.086935588291713 	 G:  2.9018478 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 10.744835 	D(real) 0.41455010005405973 	D(fake) 1.1204263823372977 	 G:  2.7935734 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 10.811817 	D(real) 0.3990821497780936 	D(fake) 1.145463126046317 	 G:  2.7254987 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 10.665785 	D(real) 0.38935705593654085 	D(fake) 1.134326457977295 	 G:  2.7226908 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 10.665117 	D(real) 0.388955933707101 	D(fake) 1.134632178715297 	 G:  2.72291 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 10.661927 	D(real) 0.38898726872035433 	D(fake) 1.1341451917375838 	 G:  2.7254906 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 10.656811 	D(real) 0.38935586384364534 	D(fake) 1.1330456052507674 	 G:  2.729882 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 10.650264 	D(real) 0.38998321124485563 	D(fake) 1.1314830780029297 	 G:  2.73563 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 10.642718 	D(real) 0.3908043588910784 	D(fake) 1.1295839718409948 	 G:  2.7423527 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 10.634533 	D(real) 0.3917647770472935 	D(fake) 1.1274542127336775 	 G:  2.7497306 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 10.6259985 	D(real) 0.3928187234061105 	D(fake) 1.125181061880929 	 G:  2.7574975 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 10.617361 	D(real) 0.3939282212938581 	D(fake) 1.1228376116071428 	 G:  2.765429 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 10.608818 	D(real) 0.39506142480032785 	D(fake) 1.1204839433942522 	 G:  2.7733436 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 10.595813 	D(real) 0.3961921078818185 	D(fake) 1.117495400565011 	 G:  2.7741177 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 10.595013 	D(real) 0.39630266598292757 	D(fake) 1.1172706059047155 	 G:  2.7748704 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 10.594236 	D(real) 0.3964101927621024 	D(fake) 1.1170520782470703 	 G:  2.7756054 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 10.593475 	D(real) 0.39651516505650114 	D(fake) 1.1168385233197893 	 G:  2.776324 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 10.592732 	D(real) 0.39661785534449984 	D(fake) 1.1166296686444963 	 G:  2.777028 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 10.592001 	D(real) 0.3967184339250837 	D(fake) 1.116424628666469 	 G:  2.7777202 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 10.591285 	D(real) 0.39681717327662874 	D(fake) 1.1162234715053014 	 G:  2.7784 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 10.590581 	D(real) 0.39691427775791716 	D(fake) 1.1160258565630232 	 G:  2.7790685 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 10.589888 	D(real) 0.39700991766793386 	D(fake) 1.1158311026436942 	 G:  2.7797282 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 10.589203 	D(real) 0.397104093006679 	D(fake) 1.1156392097473145 	 G:  2.7803783 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 10.587942 	D(real) 0.39719700813293457 	D(fake) 1.1153661182948522 	 G:  2.7804425 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 10.587874 	D(real) 0.39720613615853445 	D(fake) 1.1153473172869002 	 G:  2.7805057 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 10.587808 	D(real) 0.3972151620047433 	D(fake) 1.1153287887573242 	 G:  2.7805681 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 10.587744 	D(real) 0.3972241537911551 	D(fake) 1.1153106008257185 	 G:  2.7806308 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 10.587679 	D(real) 0.3972330093383789 	D(fake) 1.1152924810137068 	 G:  2.7806926 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 10.587613 	D(real) 0.3972418648856027 	D(fake) 1.115274293082101 	 G:  2.7807536 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 10.587549 	D(real) 0.3972506182534354 	D(fake) 1.1152564457484655 	 G:  2.7808151 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 10.587484 	D(real) 0.3972593716212681 	D(fake) 1.1152383259364538 	 G:  2.7808757 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 10.587422 	D(real) 0.39726805686950684 	D(fake) 1.1152208873203822 	 G:  2.7809367 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 10.5873575 	D(real) 0.3972767080579485 	D(fake) 1.1152029037475586 	 G:  2.7809973 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 10.587232 	D(real) 0.3972853251865932 	D(fake) 1.1151763371058874 	 G:  2.7810032 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 10.587227 	D(real) 0.3972862107413156 	D(fake) 1.1151747022356306 	 G:  2.7810092 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 10.58722 	D(real) 0.39728713035583496 	D(fake) 1.1151728630065918 	 G:  2.781015 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 10.5872135 	D(real) 0.39728801591055735 	D(fake) 1.115171023777553 	 G:  2.781021 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 10.587208 	D(real) 0.39728879928588867 	D(fake) 1.1151693889072962 	 G:  2.781027 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 10.587201 	D(real) 0.39728971890040804 	D(fake) 1.1151676177978516 	 G:  2.781033 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 10.587194 	D(real) 0.39729057039533344 	D(fake) 1.1151657104492188 	 G:  2.7810395 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 10.587187 	D(real) 0.39729138783046175 	D(fake) 1.115163939339774 	 G:  2.7810452 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 10.587182 	D(real) 0.39729227338518414 	D(fake) 1.1151623044695174 	 G:  2.7810514 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 10.587175 	D(real) 0.39729312488010954 	D(fake) 1.1151605333600725 	 G:  2.7810576 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 14}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 14
\seed data:	 14
\seed noise:	 14
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.017701 	loss:  2.425163 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017725 	loss:  2.013579 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017818 	loss:  2.8816996 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017132 	loss:  2.333181 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017252 	loss:  2.0138712 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017532 	loss:  2.1961844 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017093 	loss:  3.2476966 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017138 	loss:  2.01341 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017017 	loss:  1.0076967 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.016813 	loss:  0.8248487 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.016643 	loss:  0.11293366 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017116 	loss:  0.09339309 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017528 	loss:  0.64195955 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018015 	loss:  0.5505448 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017274 	loss:  0.52368706 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017461 	loss:  1.0126854 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017332 	loss:  1.1286384 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017147 	loss:  1.0593978 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.016794 	loss:  1.0885932 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017545 	loss:  0.96195877 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017253 	loss:  1.1905285 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017071 	loss:  1.0271906 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.016860 	loss:  0.5832741 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.016969 	loss:  0.5505256 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.016883 	loss:  0.49713555 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.016667 	loss:  0.5962383 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.016820 	loss:  0.6701482 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017442 	loss:  0.59623635 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.016685 	loss:  0.6654741 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.016830 	loss:  0.603242 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.016997 	loss:  0.5505193 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017065 	loss:  0.46209392 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018726 	loss:  0.6419476 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018111 	loss:  0.60324085 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.016844 	loss:  0.60324067 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.016864 	loss:  0.5505188 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017417 	loss:  0.71585786 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017198 	loss:  0.6419471 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017325 	loss:  0.64194703 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017330 	loss:  0.60324025 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.016777 	loss:  0.7158574 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.016821 	loss:  0.64194673 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.016655 	loss:  0.77908957 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.016880 	loss:  0.46209282 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017303 	loss:  0.55051804 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.016978 	loss:  0.550518 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017863 	loss:  0.4977962 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017052 	loss:  0.6771506 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017390 	loss:  0.64194643 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.016961 	loss:  0.5505179 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.873356
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_14/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 12.858774 	D(real) 0.7311119238535563 	D(fake) 1.4120171864827473 	 G:  2.3204467 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 10.406778 	D(real) 0.3974171082178752 	D(fake) 1.3370459874471028 	 G:  1.9203731 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 9.654178 	D(real) 0.32007451852162677 	D(fake) 1.2889550526936848 	 G:  2.131888 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 9.267494 	D(real) 0.3553047974904378 	D(fake) 1.1892775694529216 	 G:  2.3671358 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 9.013159 	D(real) 0.3945215145746867 	D(fake) 1.107671578725179 	 G:  2.5792162 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 8.85827 	D(real) 0.42986635367075604 	D(fake) 1.046511967976888 	 G:  2.7338588 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 8.804581 	D(real) 0.4556233882904053 	D(fake) 1.011806805928548 	 G:  2.803039 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 8.829321 	D(real) 0.4671620925267537 	D(fake) 1.004391352335612 	 G:  2.7841904 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 8.904695 	D(real) 0.46403006712595624 	D(fake) 1.0200857321421306 	 G:  2.699462 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 9.007848 	D(real) 0.4498513142267863 	D(fake) 1.051456610361735 	 G:  2.5830102 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 8.892131 	D(real) 0.43041102091471356 	D(fake) 1.051610787709554 	 G:  2.578724 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 8.866251 	D(real) 0.42830053965250653 	D(fake) 1.049407958984375 	 G:  2.5870802 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 8.933537 	D(real) 0.4259657859802246 	D(fake) 1.062956968943278 	 G:  2.5414896 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 8.946237 	D(real) 0.4235496123631795 	D(fake) 1.0674898624420166 	 G:  2.527475 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 8.199826 	D(real) 0.42124418417612713 	D(fake) 0.9453935623168945 	 G:  3.332702 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 8.981117 	D(real) 0.41821861267089844 	D(fake) 1.078634262084961 	 G:  2.4895384 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 8.999714 	D(real) 0.4147485097249349 	D(fake) 1.0852038860321045 	 G:  2.4707472 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 9.006111 	D(real) 0.41177741686503094 	D(fake) 1.0892410278320312 	 G:  2.459821 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 8.27177 	D(real) 0.40925641854604083 	D(fake) 0.9693717956542969 	 G:  3.2691898 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 9.044493 	D(real) 0.4063856204350789 	D(fake) 1.1010297934214275 	 G:  2.422925 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 9.039731 	D(real) 0.4033631881078084 	D(fake) 1.1032586892445881 	 G:  2.4188068 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 9.038306 	D(real) 0.4031232992808024 	D(fake) 1.1032610734303792 	 G:  2.418947 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 9.038015 	D(real) 0.40293463071187335 	D(fake) 1.1034012635548909 	 G:  2.4186482 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 9.04216 	D(real) 0.4027872085571289 	D(fake) 1.1042394638061523 	 G:  2.4162402 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 9.043066 	D(real) 0.40267348289489746 	D(fake) 1.1045042673746746 	 G:  2.415529 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 9.043377 	D(real) 0.4025874932607015 	D(fake) 1.1046419143676758 	 G:  2.4151826 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 9.043709 	D(real) 0.4025242328643799 	D(fake) 1.1047606468200684 	 G:  2.4148808 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 9.043883 	D(real) 0.4024791320164998 	D(fake) 1.1048347155253093 	 G:  2.414702 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 8.970802 	D(real) 0.4024490515391032 	D(fake) 1.0926845868428547 	 G:  2.4530997 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 9.044275 	D(real) 0.40241726239522296 	D(fake) 1.1049620310465496 	 G:  2.4143186 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 9.043225 	D(real) 0.40238555272420246 	D(fake) 1.1048186620076497 	 G:  2.4143102 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 9.03421 	D(real) 0.4023837248484294 	D(fake) 1.1033179759979248 	 G:  2.4187963 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 9.039007 	D(real) 0.40238269170125324 	D(fake) 1.1041185855865479 	 G:  2.4163995 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 8.894902 	D(real) 0.4023823340733846 	D(fake) 1.0801013310750325 	 G:  2.4969962 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 9.042649 	D(real) 0.4023802677790324 	D(fake) 1.1047279834747314 	 G:  2.4145758 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 9.040905 	D(real) 0.40237708886464435 	D(fake) 1.104440450668335 	 G:  2.4154365 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 9.039806 	D(real) 0.4023751417795817 	D(fake) 1.1042591730753581 	 G:  2.4159782 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 9.043267 	D(real) 0.40237406889597577 	D(fake) 1.1048370997111003 	 G:  2.4142604 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 9.043285 	D(real) 0.40237398942311603 	D(fake) 1.1048402786254883 	 G:  2.4142525 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 9.04328 	D(real) 0.4023744265238444 	D(fake) 1.1048389275868733 	 G:  2.414258 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 9.043153 	D(real) 0.4023754994074504 	D(fake) 1.1048165957132976 	 G:  2.4142702 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 8.2761345 	D(real) 0.4023756186167399 	D(fake) 0.9769802093505859 	 G:  3.2613854 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 8.275676 	D(real) 0.4023750225702922 	D(fake) 0.9769042332967123 	 G:  3.262548 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 9.041422 	D(real) 0.4023732741673787 	D(fake) 1.1045304139455159 	 G:  2.4151156 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 8.291341 	D(real) 0.40237120787302655 	D(fake) 0.9795189698537191 	 G:  3.2237782 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 9.042744 	D(real) 0.40236886342366535 	D(fake) 1.1047550042470295 	 G:  2.414446 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 9.042899 	D(real) 0.40236639976501465 	D(fake) 1.1047834555308025 	 G:  2.4143627 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 9.043095 	D(real) 0.4023645321528117 	D(fake) 1.1048178672790527 	 G:  2.4142618 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 8.276391 	D(real) 0.40236302216847736 	D(fake) 0.9770354429880778 	 G:  3.2608123 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 9.04169 	D(real) 0.40236111481984455 	D(fake) 1.104587237040202 	 G:  2.4149463 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 15}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 15
\seed data:	 15
\seed noise:	 15
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018570 	loss:  -1.5970026 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018256 	loss:  1.2599789 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018141 	loss:  3.9835913 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017388 	loss:  3.9832554 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017520 	loss:  3.6212418 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017821 	loss:  2.8679223 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017808 	loss:  2.2502034 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017677 	loss:  3.1924298 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017824 	loss:  -1.0639461 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018169 	loss:  -2.8925056 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017735 	loss:  -2.1496472 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018028 	loss:  -0.9687049 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017376 	loss:  0.7265158 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017456 	loss:  1.4685513 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017655 	loss:  1.4121882 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017986 	loss:  1.3997289 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017859 	loss:  1.3284557 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017357 	loss:  1.2332158 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017471 	loss:  1.0990797 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017963 	loss:  1.0703346 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017226 	loss:  1.0312076 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017214 	loss:  0.80263406 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017928 	loss:  0.80263174 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017421 	loss:  0.61215323 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017509 	loss:  0.61215097 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017847 	loss:  0.5359584 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017779 	loss:  0.34547994 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017224 	loss:  0.30738273 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017232 	loss:  0.3073806 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017739 	loss:  0.30737847 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018227 	loss:  0.30737677 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017320 	loss:  0.30737665 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018610 	loss:  0.30737635 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017728 	loss:  0.3073761 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017543 	loss:  0.3073759 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017504 	loss:  0.30737582 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018008 	loss:  0.30737573 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018134 	loss:  0.30737552 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018160 	loss:  0.23118487 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017305 	loss:  0.24053697 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017379 	loss:  0.26550445 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017465 	loss:  0.30737472 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017781 	loss:  0.23118399 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017834 	loss:  0.23118386 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017558 	loss:  0.30737412 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017207 	loss:  0.30737394 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017265 	loss:  0.26550347 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017681 	loss:  0.23118342 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017781 	loss:  0.26550347 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017993 	loss:  0.23118347 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.384893
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_15/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 13.900851 	D(real) 0.7428600788116455 	D(fake) 0.9947463274002075 	 G:  5.848826 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 12.516839 	D(real) 0.735262930393219 	D(fake) 0.8293419480323792 	 G:  4.0840697 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 12.313124 	D(real) 0.5087474584579468 	D(fake) 1.0303930044174194 	 G:  3.5628076 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 12.198003 	D(real) 0.44539037346839905 	D(fake) 1.079360008239746 	 G:  3.481777 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 12.21633 	D(real) 0.4363977313041687 	D(fake) 1.0906435251235962 	 G:  3.402565 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 12.257847 	D(real) 0.42649275064468384 	D(fake) 1.1057381629943848 	 G:  3.2864904 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 12.272469 	D(real) 0.41130536794662476 	D(fake) 1.1227531433105469 	 G:  3.2149858 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 12.249832 	D(real) 0.40199536085128784 	D(fake) 1.1292335987091064 	 G:  3.2051132 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 12.207446 	D(real) 0.40070024132728577 	D(fake) 1.1252305507659912 	 G:  3.2290874 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 12.16281 	D(real) 0.40368497371673584 	D(fake) 1.116666316986084 	 G:  3.2623231 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 12.025607 	D(real) 0.40782126784324646 	D(fake) 1.0953795909881592 	 G:  3.264969 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 12.023962 	D(real) 0.40813881158828735 	D(fake) 1.0948563814163208 	 G:  3.2663875 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 12.023031 	D(real) 0.40832775831222534 	D(fake) 1.0945510864257812 	 G:  3.26709 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 12.022621 	D(real) 0.40841785073280334 	D(fake) 1.0944098234176636 	 G:  3.2672496 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 12.02279 	D(real) 0.40843120217323303 	D(fake) 1.0944175720214844 	 G:  3.2669008 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 12.023526 	D(real) 0.40838515758514404 	D(fake) 1.0945556163787842 	 G:  3.2660987 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 12.024178 	D(real) 0.40829336643218994 	D(fake) 1.0947288274765015 	 G:  3.2652128 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 12.025354 	D(real) 0.4081670939922333 	D(fake) 1.0950021743774414 	 G:  3.263971 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 12.026619 	D(real) 0.40801572799682617 	D(fake) 1.0953116416931152 	 G:  3.2626224 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 12.027931 	D(real) 0.4078468978404999 	D(fake) 1.095644474029541 	 G:  3.2612123 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 12.01687 	D(real) 0.4076669216156006 	D(fake) 1.0944417715072632 	 G:  3.2610118 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 12.016965 	D(real) 0.4076484441757202 	D(fake) 1.0944721698760986 	 G:  3.2608867 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 12.017182 	D(real) 0.40762969851493835 	D(fake) 1.0945180654525757 	 G:  3.2607 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 12.017229 	D(real) 0.40761083364486694 	D(fake) 1.0945427417755127 	 G:  3.2605996 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 12.017321 	D(real) 0.4075917601585388 	D(fake) 1.0945732593536377 	 G:  3.2604766 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 12.0177355 	D(real) 0.4075727164745331 	D(fake) 1.0946441888809204 	 G:  3.2601902 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 12.017793 	D(real) 0.40755367279052734 	D(fake) 1.0946704149246216 	 G:  3.2600844 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 12.0178 	D(real) 0.4075346291065216 	D(fake) 1.0946904420852661 	 G:  3.260004 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 12.018039 	D(real) 0.40751561522483826 	D(fake) 1.0947391986846924 	 G:  3.259808 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 12.018049 	D(real) 0.40749675035476685 	D(fake) 1.094759464263916 	 G:  3.259727 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 12.016927 	D(real) 0.40747785568237305 	D(fake) 1.0946379899978638 	 G:  3.2597208 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 12.016979 	D(real) 0.407476007938385 	D(fake) 1.0946463346481323 	 G:  3.259687 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 12.017059 	D(real) 0.40747418999671936 	D(fake) 1.0946582555770874 	 G:  3.2596388 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 12.016996 	D(real) 0.40747228264808655 	D(fake) 1.0946522951126099 	 G:  3.2596629 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 12.017103 	D(real) 0.4074704647064209 	D(fake) 1.0946674346923828 	 G:  3.2596025 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 12.017023 	D(real) 0.40746861696243286 	D(fake) 1.0946593284606934 	 G:  3.259635 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 12.01709 	D(real) 0.4074668288230896 	D(fake) 1.0946694612503052 	 G:  3.2595944 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 12.017122 	D(real) 0.40746498107910156 	D(fake) 1.0946753025054932 	 G:  3.259571 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 12.017067 	D(real) 0.4074631333351135 	D(fake) 1.094670295715332 	 G:  3.2595913 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 12.017212 	D(real) 0.4074612855911255 	D(fake) 1.094690203666687 	 G:  3.259511 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 12.016985 	D(real) 0.40745946764945984 	D(fake) 1.0946636199951172 	 G:  3.2595677 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 12.0169935 	D(real) 0.4074593484401703 	D(fake) 1.0946648120880127 	 G:  3.2595634 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 12.016974 	D(real) 0.4074591398239136 	D(fake) 1.0946626663208008 	 G:  3.259572 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 12.017048 	D(real) 0.40745896100997925 	D(fake) 1.0946719646453857 	 G:  3.2595346 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 12.016991 	D(real) 0.4074588119983673 	D(fake) 1.0946650505065918 	 G:  3.2595625 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 12.017081 	D(real) 0.407458633184433 	D(fake) 1.0946764945983887 	 G:  3.2595158 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 12.016997 	D(real) 0.40745842456817627 	D(fake) 1.0946662425994873 	 G:  3.2595572 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 12.017014 	D(real) 0.40745824575424194 	D(fake) 1.0946685075759888 	 G:  3.259548 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 12.017068 	D(real) 0.4074580669403076 	D(fake) 1.0946754217147827 	 G:  3.25952 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 12.017118 	D(real) 0.4074578583240509 	D(fake) 1.094681978225708 	 G:  3.2594945 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 16}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 16
\seed data:	 16
\seed noise:	 16
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018006 	loss:  0.71624166 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017643 	loss:  1.144637 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017330 	loss:  4.687268 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017810 	loss:  4.2871265 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017396 	loss:  1.7154952 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.016981 	loss:  5.3160033 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.019140 	loss:  5.1731 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017189 	loss:  5.6302595 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017238 	loss:  5.0017276 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017411 	loss:  4.887381 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017221 	loss:  3.9730287 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.016996 	loss:  4.6015906 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017017 	loss:  4.0585136 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017404 	loss:  2.8593621 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017411 	loss:  4.4586973 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017475 	loss:  4.0586753 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017182 	loss:  4.0586953 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017213 	loss:  4.0586987 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017153 	loss:  4.0586867 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017158 	loss:  4.058662 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017177 	loss:  4.058626 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017304 	loss:  4.0585814 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017509 	loss:  4.715672 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017338 	loss:  4.8584714 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017204 	loss:  4.8584085 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017879 	loss:  4.858341 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017047 	loss:  4.858271 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018203 	loss:  4.858202 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.018166 	loss:  4.8581443 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017476 	loss:  5.4866843 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017232 	loss:  5.4866924 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017519 	loss:  5.486694 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.016900 	loss:  5.486694 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017079 	loss:  5.486693 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017214 	loss:  5.48669 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017745 	loss:  5.486686 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017735 	loss:  5.486681 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017642 	loss:  5.4866757 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017386 	loss:  5.4866695 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017939 	loss:  5.486664 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017275 	loss:  5.4866586 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017130 	loss:  5.4866533 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017739 	loss:  5.486649 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017192 	loss:  5.486645 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017884 	loss:  5.4866424 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017090 	loss:  5.4866395 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017614 	loss:  5.4866395 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017440 	loss:  5.486639 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.016848 	loss:  5.486639 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017176 	loss:  5.4866385 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.913500
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_16/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 11.458063 	D(real) 0.8483026368277413 	D(fake) 0.7885635920933315 	 G:  4.7659864 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 9.165062 	D(real) 0.5621241841997419 	D(fake) 0.7471703801836286 	 G:  4.959504 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 9.714788 	D(real) 0.44845076969691683 	D(fake) 0.9393760817391532 	 G:  4.6581755 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 11.0867 	D(real) 0.3337548460279192 	D(fake) 1.2500595365251814 	 G:  2.9537683 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 9.804009 	D(real) 0.2918727057320731 	D(fake) 1.1087000710623605 	 G:  4.615378 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 4.3249583 	D(real) 0.30046892166137695 	D(fake) 0.3173822675432478 	 G:  9.97107 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 4.817997 	D(real) 0.2123352118900844 	D(fake) 0.47595010484967915 	 G:  10.205119 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 12.616936 	D(real) 0.13369497231074742 	D(fake) 1.668724468776158 	 G:  6.9389277 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 6.3372216 	D(real) 0.09904307978493827 	D(fake) 0.806274277823312 	 G:  10.262588 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 9.053974 	D(real) 0.12915273223604476 	D(fake) 1.1642721721104212 	 G:  8.640066 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 11.121922 	D(real) 0.08241055692945208 	D(fake) 1.5064353942871094 	 G:  6.6299467 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 3.9026482 	D(real) 0.0828450151852199 	D(fake) 0.4746761662619455 	 G:  12.586113 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 8.673315 	D(real) 0.08353567974908012 	D(fake) 1.1555092675345284 	 G:  8.654397 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 6.2643924 	D(real) 0.08425460542951312 	D(fake) 0.8106585911342076 	 G:  10.680875 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 3.8781662 	D(real) 0.08518932546888079 	D(fake) 0.46883440017700195 	 G:  12.7256155 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 8.607031 	D(real) 0.08585057939801898 	D(fake) 1.1437252589634486 	 G:  8.7026005 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 8.575615 	D(real) 0.08654565470559257 	D(fake) 1.1385421752929688 	 G:  8.715909 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 6.199334 	D(real) 0.08771082333156041 	D(fake) 0.7979083061218262 	 G:  10.750591 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 13.072933 	D(real) 0.08902830736977714 	D(fake) 1.7785335268293108 	 G:  4.6876063 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 6.1478 	D(real) 0.09091204404830933 	D(fake) 0.7873450687953404 	 G:  10.719283 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 8.424886 	D(real) 0.09323316812515259 	D(fake) 1.1103219985961914 	 G:  8.707248 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 12.991381 	D(real) 0.09346058538981847 	D(fake) 1.762450899396624 	 G:  4.6813493 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 6.1320486 	D(real) 0.09374524014336723 	D(fake) 0.782261712210519 	 G:  10.710953 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 17.525217 	D(real) 0.09404993057250977 	D(fake) 2.409552437918527 	 G:  0.6606799 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 6.118897 	D(real) 0.09440657922199794 	D(fake) 0.7797215325491769 	 G:  10.70589 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 10.824606 	D(real) 0.09479877778462001 	D(fake) 1.4515735081263952 	 G:  6.0051475 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 15.183138 	D(real) 0.09517221791403634 	D(fake) 2.0738474982125417 	 G:  2.673871 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 3.846219 	D(real) 0.0956020440374102 	D(fake) 0.4538578305925642 	 G:  12.688969 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 6.102916 	D(real) 0.09601228577750069 	D(fake) 0.7758327892848423 	 G:  10.681661 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 3.8475647 	D(real) 0.09633822100503105 	D(fake) 0.45331389563424246 	 G:  12.673816 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 6.101636 	D(real) 0.09659152371542794 	D(fake) 0.7750707353864398 	 G:  10.677772 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 8.357702 	D(real) 0.09661103997911726 	D(fake) 1.097346373966762 	 G:  8.671865 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 3.8473759 	D(real) 0.0966300538608006 	D(fake) 0.45299506187438965 	 G:  12.678715 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 6.1008425 	D(real) 0.09664607048034668 	D(fake) 0.7749028887067523 	 G:  10.678424 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 3.8472018 	D(real) 0.09665780408041817 	D(fake) 0.4529424394880022 	 G:  12.679825 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 10.607487 	D(real) 0.09666579110281807 	D(fake) 1.418689455304827 	 G:  6.676286 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 9.098603 	D(real) 0.09667563438415527 	D(fake) 1.2031248637608118 	 G:  7.133928 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 6.1005397 	D(real) 0.09669165100370135 	D(fake) 0.7748139926365444 	 G:  10.680706 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 4.1231747 	D(real) 0.09670817852020264 	D(fake) 0.49231679098946707 	 G:  11.697018 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 10.579731 	D(real) 0.09672020162854876 	D(fake) 1.4146699905395508 	 G:  6.6771545 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 6.100311 	D(real) 0.09673340831484113 	D(fake) 0.7747395379202706 	 G:  10.675955 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 7.993247 	D(real) 0.09673496655055455 	D(fake) 1.0451574325561523 	 G:  8.728341 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 8.359959 	D(real) 0.09673655884606498 	D(fake) 1.0975432395935059 	 G:  8.626365 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 3.7656336 	D(real) 0.09673830441066197 	D(fake) 0.44120935031345915 	 G:  12.686989 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 8.353022 	D(real) 0.0967397860118321 	D(fake) 1.0965490341186523 	 G:  8.67356 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 10.44083 	D(real) 0.09674107176916939 	D(fake) 1.3948060444423132 	 G:  6.687462 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 6.099205 	D(real) 0.09674285990851265 	D(fake) 0.7745721680777413 	 G:  10.681791 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 8.352682 	D(real) 0.09674480131694249 	D(fake) 1.0964954921177454 	 G:  8.676112 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 8.351505 	D(real) 0.09674679381506783 	D(fake) 1.0963253293718611 	 G:  8.6837 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 12.858566 	D(real) 0.09674889700753349 	D(fake) 1.7401891435895647 	 G:  4.6743555 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 17}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 17
\seed data:	 17
\seed noise:	 17
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018763 	loss:  -0.026288094 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.019672 	loss:  2.338755 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017971 	loss:  3.356363 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017974 	loss:  3.244545 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017811 	loss:  2.8176546 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017846 	loss:  2.8272462 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018208 	loss:  4.5634274 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.018113 	loss:  4.591751 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018535 	loss:  5.102817 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018339 	loss:  5.0545187 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018696 	loss:  5.3070035 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017927 	loss:  2.5861902 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017884 	loss:  0.12684374 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018239 	loss:  0.09766205 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018676 	loss:  0.24300502 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017942 	loss:  1.1544209 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018032 	loss:  1.154421 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018249 	loss:  1.0477525 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018160 	loss:  1.0477488 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.018022 	loss:  1.0574406 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018478 	loss:  1.0574341 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018075 	loss:  1.0962144 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018203 	loss:  1.4007745 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018408 	loss:  1.6489526 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018576 	loss:  1.5713665 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018616 	loss:  1.8816582 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018425 	loss:  2.9483123 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.019319 	loss:  2.8513296 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.018128 	loss:  2.8125272 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018545 	loss:  2.812511 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018452 	loss:  2.8221893 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018806 	loss:  2.8221872 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018894 	loss:  2.8221848 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.019279 	loss:  2.8221822 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018239 	loss:  2.8221788 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018651 	loss:  2.8221757 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018697 	loss:  2.8415663 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018879 	loss:  2.8706534 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018600 	loss:  2.783377 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018542 	loss:  2.652331 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018475 	loss:  2.5844479 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018472 	loss:  2.6038373 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018491 	loss:  2.6038325 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018298 	loss:  2.610595 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018145 	loss:  2.5941257 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018550 	loss:  2.5941205 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018460 	loss:  2.59412 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018822 	loss:  2.5941195 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018126 	loss:  2.594119 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.018603 	loss:  2.5941184 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.906209
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_17/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 18.440233 	D(real) 0.4979588508605957 	D(fake) 1.3460644721984862 	 G:  4.895295 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 16.941185 	D(real) 0.49048480987548826 	D(fake) 1.2036337852478027 	 G:  3.4381995 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 16.454037 	D(real) 0.34380207061767576 	D(fake) 1.3016016006469726 	 G:  3.3924987 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 15.90649 	D(real) 0.33924117088317873 	D(fake) 1.2514079093933106 	 G:  3.675809 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 15.33213 	D(real) 0.36757721900939944 	D(fake) 1.165635871887207 	 G:  4.0313344 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 14.943913 	D(real) 0.4031330108642578 	D(fake) 1.0912583351135254 	 G:  4.3149905 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 14.772573 	D(real) 0.4314988613128662 	D(fake) 1.0457585334777832 	 G:  4.472188 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 14.7388 	D(real) 0.4472187042236328 	D(fake) 1.0266613006591796 	 G:  4.510432 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 14.774723 	D(real) 0.45104317665100097 	D(fake) 1.0264291763305664 	 G:  4.465308 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 14.837102 	D(real) 0.446530818939209 	D(fake) 1.0371793746948241 	 G:  4.3829136 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 14.759405 	D(real) 0.4382914066314697 	D(fake) 1.037649154663086 	 G:  4.3738685 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 14.767907 	D(real) 0.43738679885864257 	D(fake) 1.0394039154052734 	 G:  4.3635397 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 14.777174 	D(real) 0.436353874206543 	D(fake) 1.041363525390625 	 G:  4.352332 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 14.78695 	D(real) 0.43523321151733396 	D(fake) 1.043461799621582 	 G:  4.340567 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 14.797043 	D(real) 0.4340567111968994 	D(fake) 1.0456476211547852 	 G:  4.3284984 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 14.807285 	D(real) 0.4328498363494873 	D(fake) 1.0478786468505858 	 G:  4.3163247 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 14.81756 	D(real) 0.43163247108459474 	D(fake) 1.0501235008239747 	 G:  4.3042045 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 14.827761 	D(real) 0.4304203510284424 	D(fake) 1.052355670928955 	 G:  4.2922573 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 14.837803 	D(real) 0.4292256832122803 	D(fake) 1.054554557800293 	 G:  4.280577 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 14.847628 	D(real) 0.42805771827697753 	D(fake) 1.0567049980163574 	 G:  4.2692323 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 14.841301 	D(real) 0.4269232273101807 	D(fake) 1.057206916809082 	 G:  4.2681327 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 14.842238 	D(real) 0.42681331634521485 	D(fake) 1.0574105262756348 	 G:  4.2670593 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 14.843161 	D(real) 0.42670602798461915 	D(fake) 1.057610034942627 	 G:  4.2660103 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 14.844063 	D(real) 0.426600980758667 	D(fake) 1.057805347442627 	 G:  4.26498 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 14.844955 	D(real) 0.4264979839324951 	D(fake) 1.0579975128173829 	 G:  4.263965 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 14.845837 	D(real) 0.4263965606689453 	D(fake) 1.0581871032714845 	 G:  4.2629642 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 14.846705 	D(real) 0.42629642486572267 	D(fake) 1.0583741188049316 	 G:  4.2619762 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 14.8475685 	D(real) 0.42619757652282714 	D(fake) 1.0585592269897461 	 G:  4.2609982 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 14.848423 	D(real) 0.4260998249053955 	D(fake) 1.0587425231933594 	 G:  4.260029 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 14.84927 	D(real) 0.42600293159484864 	D(fake) 1.058924102783203 	 G:  4.2590685 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 14.848646 	D(real) 0.4259068965911865 	D(fake) 1.0589576721191407 	 G:  4.258972 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 14.848724 	D(real) 0.42589716911315917 	D(fake) 1.0589753150939942 	 G:  4.258879 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 14.84881 	D(real) 0.4258878231048584 	D(fake) 1.058993148803711 	 G:  4.258784 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 14.848894 	D(real) 0.42587828636169434 	D(fake) 1.059011173248291 	 G:  4.25869 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 14.848978 	D(real) 0.42586894035339357 	D(fake) 1.0590288162231445 	 G:  4.2585955 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 14.84906 	D(real) 0.4258594989776611 	D(fake) 1.059046459197998 	 G:  4.2585025 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 14.84914 	D(real) 0.42585015296936035 	D(fake) 1.0590639114379883 	 G:  4.258409 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 14.849223 	D(real) 0.4258408546447754 	D(fake) 1.05908145904541 	 G:  4.258316 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 14.849308 	D(real) 0.42583155632019043 	D(fake) 1.0590991973876953 	 G:  4.258223 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 14.84939 	D(real) 0.4258223056793213 	D(fake) 1.059116744995117 	 G:  4.2581296 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 14.849327 	D(real) 0.4258129119873047 	D(fake) 1.0591197967529298 	 G:  4.25812 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 14.849333 	D(real) 0.4258120059967041 	D(fake) 1.059121322631836 	 G:  4.258111 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 14.849341 	D(real) 0.4258111000061035 	D(fake) 1.0591230392456055 	 G:  4.2581015 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 14.84935 	D(real) 0.4258101463317871 	D(fake) 1.0591248512268066 	 G:  4.2580934 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 14.849361 	D(real) 0.4258093357086182 	D(fake) 1.059126853942871 	 G:  4.2580824 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 14.849369 	D(real) 0.4258082389831543 	D(fake) 1.0591286659240722 	 G:  4.2580733 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 14.849375 	D(real) 0.42580742835998536 	D(fake) 1.0591300964355468 	 G:  4.2580643 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 14.849384 	D(real) 0.42580647468566896 	D(fake) 1.0591320037841796 	 G:  4.258055 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 14.849394 	D(real) 0.42580552101135255 	D(fake) 1.0591339111328124 	 G:  4.2580457 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 14.8494005 	D(real) 0.42580451965332033 	D(fake) 1.0591355323791505 	 G:  4.258036 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 18}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 18
\seed data:	 18
\seed noise:	 18
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018570 	loss:  0.22884482 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018141 	loss:  0.92200303 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017667 	loss:  1.5084741 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018136 	loss:  0.8818585 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017571 	loss:  1.8551391 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017926 	loss:  0.428392 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017944 	loss:  1.3349625 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017940 	loss:  2.0412002 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017913 	loss:  4.9477267 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018055 	loss:  4.721696 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018144 	loss:  4.401713 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018342 	loss:  4.4416857 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017700 	loss:  4.5082755 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017789 	loss:  4.4146004 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017904 	loss:  4.4157743 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018210 	loss:  4.414616 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017748 	loss:  4.494659 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017495 	loss:  5.268017 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017838 	loss:  5.094695 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017845 	loss:  5.094697 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017986 	loss:  5.1346908 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018545 	loss:  5.134678 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017982 	loss:  5.1346593 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018474 	loss:  5.134635 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017843 	loss:  5.134606 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017635 	loss:  5.1345716 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018043 	loss:  5.1345315 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017600 	loss:  4.8544865 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017641 	loss:  4.4677696 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017738 	loss:  4.4677153 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017945 	loss:  4.6676583 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017802 	loss:  4.6676526 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017743 	loss:  4.667647 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017991 	loss:  4.66764 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018408 	loss:  4.667634 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018369 	loss:  4.6676273 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017910 	loss:  4.6276207 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018009 	loss:  4.4276137 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018083 	loss:  4.467607 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018100 	loss:  4.6009336 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017925 	loss:  4.494261 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018388 	loss:  4.4942546 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017925 	loss:  4.4942484 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018267 	loss:  4.4809093 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017556 	loss:  4.520904 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017673 	loss:  4.520899 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018386 	loss:  4.5208983 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017494 	loss:  4.520898 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017791 	loss:  4.547564 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017820 	loss:  4.5475636 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.986968
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_18/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 17.416485 	D(real) 0.6521803008185493 	D(fake) 1.282984733581543 	 G:  4.2225237 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 14.976678 	D(real) 0.47216563754611546 	D(fake) 1.1919096840752497 	 G:  3.363974 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 14.43788 	D(real) 0.37361277474297416 	D(fake) 1.2305961185031467 	 G:  3.5417862 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 13.950851 	D(real) 0.39348294999864364 	D(fake) 1.1566116544935439 	 G:  3.7350492 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 13.660163 	D(real) 0.4150079091389974 	D(fake) 1.102787971496582 	 G:  3.8578746 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 13.510941 	D(real) 0.42865170372856987 	D(fake) 1.0725639131334093 	 G:  3.9478545 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 13.432188 	D(real) 0.4386584493849013 	D(fake) 1.0538069407145183 	 G:  4.009446 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 13.43631 	D(real) 0.4454766909281413 	D(fake) 1.0474466747707791 	 G:  3.9906383 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 13.508745 	D(real) 0.44344772232903373 	D(fake) 1.057523939344618 	 G:  3.8984308 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 13.608616 	D(real) 0.43315760294596356 	D(fake) 1.0789108276367188 	 G:  3.779628 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 13.441342 	D(real) 0.41996190283033585 	D(fake) 1.0735205544365778 	 G:  3.767932 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 13.452133 	D(real) 0.41865788565741646 	D(fake) 1.0760235256618924 	 G:  3.7559028 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 13.4641905 	D(real) 0.417316198348999 	D(fake) 1.0787049399481878 	 G:  3.7433023 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 13.474453 	D(real) 0.41597583558824325 	D(fake) 1.0811856587727864 	 G:  3.7318394 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 13.484812 	D(real) 0.41466689109802246 	D(fake) 1.083645502726237 	 G:  3.7206426 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 13.494626 	D(real) 0.41341254446241593 	D(fake) 1.0859903759426541 	 G:  3.7101057 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 13.50426 	D(real) 0.41222967041863334 	D(fake) 1.0882436964246962 	 G:  3.7000875 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 13.512936 	D(real) 0.4111294746398926 	D(fake) 1.090307765536838 	 G:  3.6910105 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 13.520628 	D(real) 0.4101190037197537 	D(fake) 1.0921730465359158 	 G:  3.682892 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 13.527922 	D(real) 0.40920231077406144 	D(fake) 1.0939000447591145 	 G:  3.6754355 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 13.513125 	D(real) 0.40838050842285156 	D(fake) 1.0930778715345595 	 G:  3.674731 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 13.51359 	D(real) 0.40830760531955296 	D(fake) 1.093202379014757 	 G:  3.6741993 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 13.513992 	D(real) 0.4082425965203179 	D(fake) 1.0933120515611436 	 G:  3.67373 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 13.514781 	D(real) 0.40818413098653156 	D(fake) 1.0934581756591797 	 G:  3.6730897 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 13.5150585 	D(real) 0.40813104311625165 	D(fake) 1.0935420989990234 	 G:  3.6727295 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 13.515355 	D(real) 0.40808243221706814 	D(fake) 1.0936236911349826 	 G:  3.6723757 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 13.515907 	D(real) 0.4080376360151503 	D(fake) 1.0937298668755426 	 G:  3.6719084 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 13.516143 	D(real) 0.40799596574571395 	D(fake) 1.0937976837158203 	 G:  3.6716135 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 13.516684 	D(real) 0.40795691808064777 	D(fake) 1.0938968658447266 	 G:  3.671174 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 13.516705 	D(real) 0.4079200161827935 	D(fake) 1.093936072455512 	 G:  3.671005 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 13.515153 	D(real) 0.40788502163357204 	D(fake) 1.0937986373901367 	 G:  3.670997 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 13.515372 	D(real) 0.4078816572825114 	D(fake) 1.0938263999091253 	 G:  3.6708715 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 13.515682 	D(real) 0.40787845187717015 	D(fake) 1.093864017062717 	 G:  3.6707015 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 13.515554 	D(real) 0.40787532594468856 	D(fake) 1.0938529968261719 	 G:  3.6707528 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 13.515382 	D(real) 0.4078722794850667 	D(fake) 1.093836784362793 	 G:  3.6708264 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 13.5152645 	D(real) 0.4078693389892578 	D(fake) 1.0938267178005643 	 G:  3.6708722 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 13.515746 	D(real) 0.4078664514753554 	D(fake) 1.093883090549045 	 G:  3.6706161 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 13.515467 	D(real) 0.4078636169433594 	D(fake) 1.0938549041748047 	 G:  3.670745 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 13.515586 	D(real) 0.40786075592041016 	D(fake) 1.0938710106743708 	 G:  3.6706722 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 13.515528 	D(real) 0.4078580008612739 	D(fake) 1.093867301940918 	 G:  3.6706896 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 13.515291 	D(real) 0.40785519282023114 	D(fake) 1.0938437779744465 	 G:  3.6707292 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 13.515247 	D(real) 0.40785498089260525 	D(fake) 1.0938392215304904 	 G:  3.6707494 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 13.515204 	D(real) 0.40785471598307294 	D(fake) 1.0938346650865343 	 G:  3.6707697 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 13.515366 	D(real) 0.4078543451097276 	D(fake) 1.093852890862359 	 G:  3.6706872 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 13.515318 	D(real) 0.4078541331821018 	D(fake) 1.0938479105631511 	 G:  3.670711 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 13.51542 	D(real) 0.4078538947635227 	D(fake) 1.0938594606187608 	 G:  3.6706576 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 13.515531 	D(real) 0.4078535768720839 	D(fake) 1.0938720703125 	 G:  3.6706002 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 13.515654 	D(real) 0.4078533914354112 	D(fake) 1.0938859515719943 	 G:  3.6705375 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 13.515303 	D(real) 0.40785307354397243 	D(fake) 1.0938472747802734 	 G:  3.6707127 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 13.515354 	D(real) 0.4078528616163466 	D(fake) 1.0938532087537978 	 G:  3.670686 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 19}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 19
\seed data:	 19
\seed noise:	 19
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018418 	loss:  1.4413036 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017588 	loss:  1.9551709 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017222 	loss:  2.384045 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017281 	loss:  2.1266968 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017683 	loss:  3.1044917 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017338 	loss:  4.8670387 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017222 	loss:  5.1904864 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017042 	loss:  5.5339603 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017611 	loss:  4.804768 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.016967 	loss:  4.019705 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017151 	loss:  3.648269 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017919 	loss:  3.0768273 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017953 	loss:  3.0482416 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017823 	loss:  3.1740842 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017886 	loss:  2.160692 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017269 	loss:  1.265209 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017103 	loss:  1.2652084 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.016936 	loss:  1.2484652 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017062 	loss:  1.2770357 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017115 	loss:  1.2770343 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017107 	loss:  1.2770331 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017474 	loss:  1.4198887 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017501 	loss:  1.4198872 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017323 	loss:  1.4198858 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017167 	loss:  1.4770272 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017220 	loss:  1.4770256 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017403 	loss:  1.6770239 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017199 	loss:  1.5913084 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017892 	loss:  1.6770209 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017113 	loss:  1.6770197 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017234 	loss:  1.6519717 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017386 	loss:  1.5913042 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017313 	loss:  1.5913041 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017227 	loss:  1.677018 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017898 	loss:  1.5913038 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017225 	loss:  1.5913037 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017187 	loss:  1.6770177 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017964 	loss:  1.5913035 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017065 	loss:  1.5662563 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018040 	loss:  1.6770173 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017334 	loss:  1.6102772 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017255 	loss:  1.566256 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017515 	loss:  1.677017 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017120 	loss:  1.5336426 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018091 	loss:  1.6193568 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017573 	loss:  1.6193568 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017203 	loss:  1.6193568 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017520 	loss:  1.5336423 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017025 	loss:  1.6193566 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017503 	loss:  1.5776631 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.360063
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_19/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 12.568212 	D(real) 0.5256632396153041 	D(fake) 1.2697955540248327 	 G:  2.8380065 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 10.502983 	D(real) 0.4054134913853237 	D(fake) 1.0950127329145158 	 G:  3.0476866 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 10.407554 	D(real) 0.43538410323006765 	D(fake) 1.0514093126569475 	 G:  3.1426046 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 10.397 	D(real) 0.44894364901951384 	D(fake) 1.0363420758928572 	 G:  3.1598816 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 10.440973 	D(real) 0.45141169003077913 	D(fake) 1.0401558876037598 	 G:  3.0953984 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 10.5226 	D(real) 0.442199775150844 	D(fake) 1.0610288892473494 	 G:  2.9830852 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 10.604773 	D(real) 0.42615502221243723 	D(fake) 1.0888124193464006 	 G:  2.874887 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 10.658173 	D(real) 0.4106981413705008 	D(fake) 1.1118980135236467 	 G:  2.8095934 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 10.67135 	D(real) 0.4013704913003104 	D(fake) 1.1231080463954382 	 G:  2.79807 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 10.65317 	D(real) 0.39972427913120817 	D(fake) 1.122157096862793 	 G:  2.8235905 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 10.551465 	D(real) 0.4033700738634382 	D(fake) 1.1039820398603166 	 G:  2.8264804 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 10.548811 	D(real) 0.40378291266305105 	D(fake) 1.1031900133405412 	 G:  2.8289838 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 10.54657 	D(real) 0.4041405405317034 	D(fake) 1.1025123596191406 	 G:  2.8311064 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 10.544714 	D(real) 0.4044437749045236 	D(fake) 1.1019439697265625 	 G:  2.8328683 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 10.543205 	D(real) 0.4046954768044608 	D(fake) 1.1014767374311174 	 G:  2.8343008 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 10.542005 	D(real) 0.404900108064924 	D(fake) 1.1011005129132951 	 G:  2.8354368 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 10.541077 	D(real) 0.4050624029976981 	D(fake) 1.1008057594299316 	 G:  2.8363101 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 10.540388 	D(real) 0.4051871640341623 	D(fake) 1.1005825315202986 	 G:  2.8369539 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 10.539904 	D(real) 0.4052791254861014 	D(fake) 1.100421360560826 	 G:  2.8373983 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 10.53959 	D(real) 0.4053426129477365 	D(fake) 1.1003131185259138 	 G:  2.8376737 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 10.530153 	D(real) 0.40538195201328825 	D(fake) 1.0989257267543249 	 G:  2.8376918 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 10.530138 	D(real) 0.40538454055786133 	D(fake) 1.0989208221435547 	 G:  2.8377056 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 10.530125 	D(real) 0.40538651602608816 	D(fake) 1.098916939326695 	 G:  2.837718 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 10.530113 	D(real) 0.40538828713553293 	D(fake) 1.0989136695861816 	 G:  2.837727 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 10.530106 	D(real) 0.4053895814078195 	D(fake) 1.0989112172807967 	 G:  2.837734 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 10.530097 	D(real) 0.4053905691419329 	D(fake) 1.0989089693341936 	 G:  2.83774 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 10.530092 	D(real) 0.40539142063685824 	D(fake) 1.098907538822719 	 G:  2.837744 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 10.5300865 	D(real) 0.4053919996534075 	D(fake) 1.0989061083112444 	 G:  2.8377485 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 10.5300865 	D(real) 0.4053926467895508 	D(fake) 1.098905427115304 	 G:  2.8377514 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 10.530084 	D(real) 0.40539305550711496 	D(fake) 1.0989046096801758 	 G:  2.8377535 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 10.529148 	D(real) 0.4053933620452881 	D(fake) 1.0987706184387207 	 G:  2.8377535 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 10.529148 	D(real) 0.4053933620452881 	D(fake) 1.0987706184387207 	 G:  2.8377535 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 10.529148 	D(real) 0.4053933620452881 	D(fake) 1.0987706184387207 	 G:  2.8377535 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 10.529145 	D(real) 0.4053933620452881 	D(fake) 1.0987702778407507 	 G:  2.8377535 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 10.529145 	D(real) 0.4053933620452881 	D(fake) 1.0987702778407507 	 G:  2.8377535 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 10.529145 	D(real) 0.4053933620452881 	D(fake) 1.0987702097211565 	 G:  2.837754 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 10.529145 	D(real) 0.4053934301648821 	D(fake) 1.0987702097211565 	 G:  2.837755 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 10.529145 	D(real) 0.40539356640407015 	D(fake) 1.0987700734819685 	 G:  2.8377554 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 10.529146 	D(real) 0.4053936345236642 	D(fake) 1.0987700734819685 	 G:  2.8377557 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 10.529146 	D(real) 0.4053936685834612 	D(fake) 1.0987700734819685 	 G:  2.8377557 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 10.529051 	D(real) 0.4053936685834612 	D(fake) 1.0987563814435686 	 G:  2.8377557 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 10.529051 	D(real) 0.4053936685834612 	D(fake) 1.0987563814435686 	 G:  2.8377557 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 10.529051 	D(real) 0.4053936685834612 	D(fake) 1.0987563814435686 	 G:  2.8377557 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 10.529051 	D(real) 0.4053936685834612 	D(fake) 1.0987563814435686 	 G:  2.8377557 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 10.529051 	D(real) 0.4053936685834612 	D(fake) 1.0987563814435686 	 G:  2.8377557 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 10.529051 	D(real) 0.4053936685834612 	D(fake) 1.0987563814435686 	 G:  2.8377557 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 10.529051 	D(real) 0.4053936685834612 	D(fake) 1.0987563814435686 	 G:  2.8377557 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 10.529051 	D(real) 0.4053936685834612 	D(fake) 1.0987563814435686 	 G:  2.8377566 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 10.529051 	D(real) 0.40539380482264925 	D(fake) 1.0987563814435686 	 G:  2.8377566 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 10.529051 	D(real) 0.40539380482264925 	D(fake) 1.0987563814435686 	 G:  2.8377566 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 20}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 20
\seed data:	 20
\seed noise:	 20
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018211 	loss:  2.097738 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017904 	loss:  3.6975749 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017668 	loss:  3.7542636 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017784 	loss:  4.020881 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017253 	loss:  3.3430333 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017243 	loss:  4.383083 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017569 	loss:  4.992628 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017675 	loss:  4.573577 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017889 	loss:  2.2706413 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017503 	loss:  1.6402336 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018047 	loss:  2.0211775 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017448 	loss:  2.9348824 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017853 	loss:  3.373542 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018094 	loss:  3.544965 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017312 	loss:  3.5640094 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018242 	loss:  3.6345067 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017344 	loss:  3.6345062 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017285 	loss:  3.6211498 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017193 	loss:  3.6401968 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017410 	loss:  3.6211486 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017774 	loss:  3.6345043 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017892 	loss:  3.640195 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017223 	loss:  3.6401942 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017471 	loss:  3.6401937 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018336 	loss:  3.640193 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017344 	loss:  3.6401925 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017405 	loss:  3.640192 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017852 	loss:  3.6401918 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.018096 	loss:  3.640191 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017290 	loss:  3.640191 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017677 	loss:  3.6401906 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018218 	loss:  3.6401906 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017590 	loss:  3.6401906 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018663 	loss:  3.6401906 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017862 	loss:  3.6401906 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017778 	loss:  3.6401904 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017246 	loss:  3.6803448 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017455 	loss:  3.6401906 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017726 	loss:  3.6401904 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017825 	loss:  3.6803446 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017583 	loss:  3.7163808 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018385 	loss:  3.6803446 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017263 	loss:  3.6401904 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017540 	loss:  3.6401904 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018079 	loss:  3.6401901 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017534 	loss:  3.7163808 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017976 	loss:  3.6401901 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017569 	loss:  3.6401901 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018093 	loss:  3.6401901 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017173 	loss:  3.6401904 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.236693
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_20/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 13.907562 	D(real) 0.7418599128723145 	D(fake) 0.9965853691101074 	 G:  6.173629 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 12.25973 	D(real) 0.7829984426498413 	D(fake) 0.7494678497314453 	 G:  4.4587765 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 12.097656 	D(real) 0.5573477149009705 	D(fake) 0.9548592567443848 	 G:  4.171775 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 12.028299 	D(real) 0.5232501029968262 	D(fake) 0.9802873730659485 	 G:  4.1800623 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 12.166437 	D(real) 0.5254214406013489 	D(fake) 0.9953831434249878 	 G:  3.9836733 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 12.098973 	D(real) 0.5006400346755981 	D(fake) 1.0117316246032715 	 G:  3.8574944 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 12.236096 	D(real) 0.48367202281951904 	D(fake) 1.0458400249481201 	 G:  3.5628703 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 12.470939 	D(real) 0.4473173916339874 	D(fake) 1.111549973487854 	 G:  3.219042 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 12.696299 	D(real) 0.4027552604675293 	D(fake) 1.1842820644378662 	 G:  2.9626582 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 12.762283 	D(real) 0.3711146414279938 	D(fake) 1.2241708040237427 	 G:  2.8602724 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 12.503199 	D(real) 0.3577635884284973 	D(fake) 1.2051362991333008 	 G:  2.8618155 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 12.486469 	D(real) 0.35800254344940186 	D(fake) 1.2028061151504517 	 G:  2.8737106 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 12.463398 	D(real) 0.35939285159111023 	D(fake) 1.1985318660736084 	 G:  2.8913958 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 12.430525 	D(real) 0.3616458773612976 	D(fake) 1.1921696662902832 	 G:  2.915638 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 12.401259 	D(real) 0.3645320236682892 	D(fake) 1.185625433921814 	 G:  2.940108 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 12.360117 	D(real) 0.3678641617298126 	D(fake) 1.1771504878997803 	 G:  2.9710753 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 12.322705 	D(real) 0.3714859187602997 	D(fake) 1.1688522100448608 	 G:  3.001322 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 12.285833 	D(real) 0.37526601552963257 	D(fake) 1.1604632139205933 	 G:  3.0318592 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 12.250792 	D(real) 0.37909355759620667 	D(fake) 1.1522554159164429 	 G:  3.0617602 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 12.217703 	D(real) 0.38287514448165894 	D(fake) 1.144337773323059 	 G:  3.0906537 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 12.193815 	D(real) 0.3865329623222351 	D(fake) 1.1376938819885254 	 G:  3.094154 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 12.191818 	D(real) 0.3868795335292816 	D(fake) 1.137097716331482 	 G:  3.0963318 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 12.187866 	D(real) 0.3872068226337433 	D(fake) 1.1362764835357666 	 G:  3.0993738 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 12.184914 	D(real) 0.38751792907714844 	D(fake) 1.1355962753295898 	 G:  3.101895 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 12.182896 	D(real) 0.3878151774406433 	D(fake) 1.1350468397140503 	 G:  3.103932 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 12.180775 	D(real) 0.38810062408447266 	D(fake) 1.1344962120056152 	 G:  3.1059809 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 12.178045 	D(real) 0.38837578892707825 	D(fake) 1.1338798999786377 	 G:  3.1082857 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 12.176875 	D(real) 0.3886420726776123 	D(fake) 1.1334673166275024 	 G:  3.1098235 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 12.173895 	D(real) 0.3889005780220032 	D(fake) 1.1328363418579102 	 G:  3.1121957 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 12.172286 	D(real) 0.3891521394252777 	D(fake) 1.1323835849761963 	 G:  3.113896 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 12.168684 	D(real) 0.38939768075942993 	D(fake) 1.1316877603530884 	 G:  3.1148198 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 12.169447 	D(real) 0.38942164182662964 	D(fake) 1.1317591667175293 	 G:  3.114546 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 12.169303 	D(real) 0.3894451856613159 	D(fake) 1.1317176818847656 	 G:  3.1147027 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 12.169789 	D(real) 0.38946834206581116 	D(fake) 1.1317553520202637 	 G:  3.1145582 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 12.16989 	D(real) 0.38949111104011536 	D(fake) 1.1317452192306519 	 G:  3.1145957 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 12.168148 	D(real) 0.38951367139816284 	D(fake) 1.1315048933029175 	 G:  3.1155107 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 12.1693 	D(real) 0.3895360827445984 	D(fake) 1.1316264867782593 	 G:  3.1150472 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 12.16888 	D(real) 0.38955825567245483 	D(fake) 1.131551742553711 	 G:  3.1153316 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 12.1681 	D(real) 0.3895803391933441 	D(fake) 1.1314321756362915 	 G:  3.115786 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 12.171518 	D(real) 0.38960230350494385 	D(fake) 1.1318374872207642 	 G:  3.114245 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 12.168346 	D(real) 0.3896242082118988 	D(fake) 1.131419062614441 	 G:  3.1156719 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 12.169872 	D(real) 0.3896263539791107 	D(fake) 1.1316076517105103 	 G:  3.1149545 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 12.167196 	D(real) 0.3896285593509674 	D(fake) 1.1312710046768188 	 G:  3.116236 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 12.168064 	D(real) 0.3896307349205017 	D(fake) 1.1313773393630981 	 G:  3.1158314 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 12.168055 	D(real) 0.389632910490036 	D(fake) 1.1313738822937012 	 G:  3.1158447 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 12.166868 	D(real) 0.3896351158618927 	D(fake) 1.131223440170288 	 G:  3.116417 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 12.166871 	D(real) 0.38963720202445984 	D(fake) 1.1312216520309448 	 G:  3.1164236 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 12.167848 	D(real) 0.38963940739631653 	D(fake) 1.131341576576233 	 G:  3.1159668 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 12.169265 	D(real) 0.38964155316352844 	D(fake) 1.1315165758132935 	 G:  3.1153014 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 12.166315 	D(real) 0.38964369893074036 	D(fake) 1.131145715713501 	 G:  3.1167135 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 21}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 21
\seed data:	 21
\seed noise:	 21
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018734 	loss:  1.4405133 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017905 	loss:  0.51528364 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017369 	loss:  0.772286 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017175 	loss:  -0.68489563 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017095 	loss:  1.9432338 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017036 	loss:  4.2300014 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017379 	loss:  4.400173 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017360 	loss:  4.001278 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017213 	loss:  3.6870527 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017130 	loss:  -2.1404774 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017241 	loss:  -1.6191103 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017662 	loss:  -1.3551344 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017458 	loss:  0.07676036 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017449 	loss:  -1.0347534 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017115 	loss:  -0.99060696 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017331 	loss:  0.30183685 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017879 	loss:  0.5271322 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017249 	loss:  1.1728398 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017345 	loss:  0.9524152 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017583 	loss:  0.5264631 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018038 	loss:  1.0986938 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017389 	loss:  1.35897 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017913 	loss:  0.72596335 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017796 	loss:  0.6928778 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017440 	loss:  0.22127588 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017360 	loss:  -0.53296846 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017831 	loss:  -0.6277977 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018074 	loss:  -1.4959058 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017455 	loss:  -1.7585366 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017669 	loss:  -2.5866249 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017264 	loss:  -2.5842502 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017298 	loss:  -2.8932328 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017710 	loss:  -2.1745114 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017610 	loss:  -2.4206095 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017898 	loss:  -2.2422862 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017242 	loss:  -2.278073 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017532 	loss:  -2.4412715 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017620 	loss:  -2.6847665 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018083 	loss:  -2.4109097 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017524 	loss:  -2.6098795 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017986 	loss:  -2.3169494 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017579 	loss:  -2.1319563 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017615 	loss:  -2.5588646 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018153 	loss:  -2.8074367 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017265 	loss:  -2.5723486 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017496 	loss:  -1.5535816 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017339 	loss:  -2.559887 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017453 	loss:  -2.668549 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018259 	loss:  -2.327686 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017504 	loss:  -1.9591604 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.817316
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_21/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 11.439257 	D(real) 0.7935987200055804 	D(fake) 0.840580872126988 	 G:  5.1400967 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 10.516661 	D(real) 0.7340784754071917 	D(fake) 0.7683016232081822 	 G:  4.0708375 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 10.203326 	D(real) 0.5815545490809849 	D(fake) 0.876063483101981 	 G:  3.7373605 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 10.340038 	D(real) 0.5338996478489467 	D(fake) 0.9432486125401088 	 G:  3.411621 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 10.662825 	D(real) 0.48736889021737234 	D(fake) 1.0358917372567313 	 G:  3.0383484 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 10.849736 	D(real) 0.4340473583766392 	D(fake) 1.115914957863944 	 G:  2.7963347 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 10.919963 	D(real) 0.39947499547685894 	D(fake) 1.160519736153739 	 G:  2.6751218 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 10.936617 	D(real) 0.382159948348999 	D(fake) 1.1802139282226562 	 G:  2.6378083 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 10.911412 	D(real) 0.3768294538770403 	D(fake) 1.181943757193429 	 G:  2.6605978 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 10.849239 	D(real) 0.3800851958138602 	D(fake) 1.1698060716901506 	 G:  2.721779 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 10.663017 	D(real) 0.3888255868639265 	D(fake) 1.134462560926165 	 G:  2.7291198 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 10.65257 	D(real) 0.3898869923182896 	D(fake) 1.131908689226423 	 G:  2.7378025 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 10.641817 	D(real) 0.3911140646253313 	D(fake) 1.1291454860142298 	 G:  2.747121 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 10.630884 	D(real) 0.39244556427001953 	D(fake) 1.1262521743774414 	 G:  2.7568138 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 10.620056 	D(real) 0.3938302312578474 	D(fake) 1.1233205795288086 	 G:  2.7665834 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 10.609567 	D(real) 0.3952257973807199 	D(fake) 1.1204265866960799 	 G:  2.7761848 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 10.599645 	D(real) 0.3965974875858852 	D(fake) 1.1176374299185616 	 G:  2.7854023 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 10.590288 	D(real) 0.39791747501918245 	D(fake) 1.11498076575143 	 G:  2.7941506 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 10.581733 	D(real) 0.3991640295301165 	D(fake) 1.1125120435442244 	 G:  2.8022466 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 10.573992 	D(real) 0.4003206661769322 	D(fake) 1.1102496555873327 	 G:  2.8096347 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 10.558475 	D(real) 0.40137600898742676 	D(fake) 1.1069774627685547 	 G:  2.8103 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 10.557849 	D(real) 0.4014711720602853 	D(fake) 1.10679292678833 	 G:  2.8109057 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 10.557305 	D(real) 0.4015577180044992 	D(fake) 1.10662875856672 	 G:  2.8114455 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 10.556739 	D(real) 0.40163731575012207 	D(fake) 1.1064682006835938 	 G:  2.8119786 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 10.556243 	D(real) 0.4017108849116734 	D(fake) 1.1063237871442522 	 G:  2.812459 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 10.555778 	D(real) 0.40177954946245464 	D(fake) 1.1061887059892928 	 G:  2.8129108 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 10.555355 	D(real) 0.40184409277779715 	D(fake) 1.1060638427734375 	 G:  2.8133292 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 10.554933 	D(real) 0.4019050598144531 	D(fake) 1.1059424536568778 	 G:  2.8137383 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 10.554525 	D(real) 0.4019630636487688 	D(fake) 1.1058262416294642 	 G:  2.8141313 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 10.554138 	D(real) 0.40201847893851145 	D(fake) 1.1057154791695731 	 G:  2.8145058 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 10.552679 	D(real) 0.4020716803414481 	D(fake) 1.1054538999285017 	 G:  2.8145297 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 10.552624 	D(real) 0.4020768233707973 	D(fake) 1.1054408209664481 	 G:  2.8145742 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 10.552586 	D(real) 0.4020817961011614 	D(fake) 1.1054304667881556 	 G:  2.8146098 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 10.552553 	D(real) 0.4020867347717285 	D(fake) 1.1054209300449915 	 G:  2.8146422 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 10.552523 	D(real) 0.4020914350237165 	D(fake) 1.1054118020193917 	 G:  2.8146741 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 10.552487 	D(real) 0.4020961012159075 	D(fake) 1.1054020609174455 	 G:  2.814707 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 10.55249 	D(real) 0.40210076740809847 	D(fake) 1.1053979056222099 	 G:  2.8147218 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 10.552425 	D(real) 0.40210533142089844 	D(fake) 1.105384009225028 	 G:  2.8147697 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 10.552404 	D(real) 0.40210982731410433 	D(fake) 1.1053765841892786 	 G:  2.814795 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 10.552444 	D(real) 0.40211425508771625 	D(fake) 1.1053777422223772 	 G:  2.8147905 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 10.552213 	D(real) 0.4021186828613281 	D(fake) 1.1053402764456612 	 G:  2.8148355 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 10.552216 	D(real) 0.40211915969848633 	D(fake) 1.1053401402064733 	 G:  2.8148365 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 10.552204 	D(real) 0.4021195684160505 	D(fake) 1.1053382328578405 	 G:  2.8148425 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 10.5522 	D(real) 0.4021199771336147 	D(fake) 1.10533721106393 	 G:  2.8148456 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 10.5522 	D(real) 0.40212041991097586 	D(fake) 1.1053367342267717 	 G:  2.814848 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 10.5522 	D(real) 0.4021208626883371 	D(fake) 1.1053363255092077 	 G:  2.8148494 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 10.5521965 	D(real) 0.4021212714059012 	D(fake) 1.105335303715297 	 G:  2.8148525 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 10.552193 	D(real) 0.4021217141832624 	D(fake) 1.1053344181605749 	 G:  2.8148556 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 10.552187 	D(real) 0.40212208884102957 	D(fake) 1.1053331920078822 	 G:  2.8148599 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 10.552191 	D(real) 0.4021225316183908 	D(fake) 1.1053333282470703 	 G:  2.8148596 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 22}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 22
\seed data:	 22
\seed noise:	 22
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.019214 	loss:  -0.40510148 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018392 	loss:  1.6314843 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018663 	loss:  3.6478767 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018150 	loss:  2.9494622 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018815 	loss:  4.219641 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017883 	loss:  4.234192 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.018011 	loss:  4.085219 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.018085 	loss:  3.1529365 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018908 	loss:  4.2875767 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018945 	loss:  3.346523 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018796 	loss:  2.7734973 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018390 	loss:  2.8167803 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017907 	loss:  3.099461 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018439 	loss:  3.0412788 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018102 	loss:  3.1518397 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018455 	loss:  3.147839 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017879 	loss:  3.246003 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018378 	loss:  3.2351086 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018266 	loss:  3.2395122 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017898 	loss:  3.2644756 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018060 	loss:  3.2932835 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018190 	loss:  3.254493 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018405 	loss:  3.2447934 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018145 	loss:  3.2447906 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018205 	loss:  3.2447877 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018169 	loss:  3.2447848 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018196 	loss:  3.2442207 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018245 	loss:  3.2253852 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.018362 	loss:  3.2253823 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018525 	loss:  3.2548394 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018347 	loss:  3.235074 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018696 	loss:  3.2544675 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017742 	loss:  3.2544672 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017977 	loss:  3.254467 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018030 	loss:  3.2544668 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018088 	loss:  3.2544665 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018729 	loss:  3.2544663 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017788 	loss:  3.254466 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017826 	loss:  3.3618555 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017888 	loss:  3.2889063 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018436 	loss:  3.254465 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018360 	loss:  3.347265 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017959 	loss:  3.3223433 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018382 	loss:  3.370828 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017891 	loss:  3.3223429 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017971 	loss:  3.3708272 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018179 	loss:  3.3223426 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017914 	loss:  3.3223424 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017991 	loss:  3.3472638 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.018002 	loss:  3.3708272 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.403563
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_22/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 20.212748 	D(real) 0.5770848751068115 	D(fake) 1.4441899299621581 	 G:  4.632105 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 15.650139 	D(real) 0.46761517524719237 	D(fake) 1.0973987579345703 	 G:  4.170013 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 15.310389 	D(real) 0.41655879020690917 	D(fake) 1.1144801139831544 	 G:  4.225286 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 14.896702 	D(real) 0.4226274013519287 	D(fake) 1.0670428276062012 	 G:  4.6017795 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 14.636939 	D(real) 0.4603269577026367 	D(fake) 1.0033669471740723 	 G:  4.869789 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 14.678574 	D(real) 0.48708148002624513 	D(fake) 0.9807759284973144 	 G:  4.823576 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 14.894172 	D(real) 0.48241844177246096 	D(fake) 1.0069987297058105 	 G:  4.540925 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 15.125591 	D(real) 0.45412449836730956 	D(fake) 1.0584345817565919 	 G:  4.2307997 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 15.28784 	D(real) 0.42309346199035647 	D(fake) 1.1056904792785645 	 G:  4.027196 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 15.365178 	D(real) 0.4027240753173828 	D(fake) 1.1337937355041503 	 G:  3.9392042 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 15.181934 	D(real) 0.39392192363739015 	D(fake) 1.1242714881896974 	 G:  3.936522 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 15.181293 	D(real) 0.39365358352661134 	D(fake) 1.1244756698608398 	 G:  3.9367015 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 15.178399 	D(real) 0.39367141723632815 	D(fake) 1.1241684913635255 	 G:  3.9390733 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 15.173791 	D(real) 0.39390857219696046 	D(fake) 1.1234704971313476 	 G:  3.9431136 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 15.167919 	D(real) 0.39431259632110593 	D(fake) 1.1224793434143066 	 G:  3.9483953 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 15.161148 	D(real) 0.39484071731567383 	D(fake) 1.1212740898132325 	 G:  3.954572 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 15.153794 	D(real) 0.3954582214355469 	D(fake) 1.1199212074279785 	 G:  3.9613538 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 15.146097 	D(real) 0.3961364984512329 	D(fake) 1.1184732437133789 	 G:  3.9685073 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 15.138276 	D(real) 0.3968517541885376 	D(fake) 1.1169758796691895 	 G:  3.9758348 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 15.130484 	D(real) 0.3975844860076904 	D(fake) 1.1154638290405274 	 G:  3.9831784 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 15.114713 	D(real) 0.39831886291503904 	D(fake) 1.1131524085998534 	 G:  3.9839003 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 15.113974 	D(real) 0.3983910083770752 	D(fake) 1.1130064010620118 	 G:  3.9846065 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 15.113247 	D(real) 0.3984616756439209 	D(fake) 1.1128629684448241 	 G:  3.9853017 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 15.112534 	D(real) 0.39853105545043943 	D(fake) 1.1127223014831542 	 G:  3.9859836 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 15.111833 	D(real) 0.3985992431640625 	D(fake) 1.1125840187072753 	 G:  3.9866552 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 15.111142 	D(real) 0.3986664772033691 	D(fake) 1.112447738647461 	 G:  3.9873173 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 15.110462 	D(real) 0.39873270988464354 	D(fake) 1.1123135566711426 	 G:  3.9879706 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 15.109791 	D(real) 0.39879803657531737 	D(fake) 1.1121809959411622 	 G:  3.9886167 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 15.109127 	D(real) 0.3988626003265381 	D(fake) 1.1120500564575195 	 G:  3.989255 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 15.108469 	D(real) 0.3989264726638794 	D(fake) 1.11192045211792 	 G:  3.9898868 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 15.10692 	D(real) 0.3989896297454834 	D(fake) 1.1117024421691895 	 G:  3.9899485 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 15.106856 	D(real) 0.3989958524703979 	D(fake) 1.1116897583007812 	 G:  3.9900105 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 15.106793 	D(real) 0.39900205135345457 	D(fake) 1.1116772651672364 	 G:  3.9900725 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 15.106728 	D(real) 0.39900805950164797 	D(fake) 1.1116646766662597 	 G:  3.9901333 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 15.106668 	D(real) 0.3990142345428467 	D(fake) 1.1116525650024414 	 G:  3.990193 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 15.106604 	D(real) 0.39902024269104003 	D(fake) 1.1116400718688966 	 G:  3.990254 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 15.106543 	D(real) 0.3990263700485229 	D(fake) 1.1116278648376465 	 G:  3.9903138 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 15.10648 	D(real) 0.3990323543548584 	D(fake) 1.1116155624389648 	 G:  3.9903734 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 15.106419 	D(real) 0.39903841018676756 	D(fake) 1.1116034507751464 	 G:  3.990434 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 15.106355 	D(real) 0.39904441833496096 	D(fake) 1.1115910530090332 	 G:  3.9904945 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 15.106198 	D(real) 0.39905033111572263 	D(fake) 1.1115694999694825 	 G:  3.9905 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 15.106192 	D(real) 0.3990509510040283 	D(fake) 1.1115682601928711 	 G:  3.9905055 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 15.106188 	D(real) 0.39905147552490233 	D(fake) 1.1115673065185547 	 G:  3.9905121 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 15.106183 	D(real) 0.39905214309692383 	D(fake) 1.111566162109375 	 G:  3.9905164 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 15.106175 	D(real) 0.3990528106689453 	D(fake) 1.1115647315979005 	 G:  3.990523 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 15.106173 	D(real) 0.3990533113479614 	D(fake) 1.1115639686584473 	 G:  3.9905286 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 15.106164 	D(real) 0.39905383586883547 	D(fake) 1.1115625381469727 	 G:  3.9905348 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 15.106157 	D(real) 0.3990545034408569 	D(fake) 1.1115612030029296 	 G:  3.990541 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 15.10615 	D(real) 0.39905500411987305 	D(fake) 1.1115599632263184 	 G:  3.9905462 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 15.106145 	D(real) 0.39905557632446287 	D(fake) 1.1115589141845703 	 G:  3.9905527 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 23}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 23
\seed data:	 23
\seed noise:	 23
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018922 	loss:  1.2520123 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018159 	loss:  1.6519778 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018075 	loss:  2.0961282 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018174 	loss:  4.259217 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018224 	loss:  5.2868695 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017555 	loss:  3.1971915 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017408 	loss:  5.020495 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017557 	loss:  4.0488257 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017849 	loss:  2.9821851 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018089 	loss:  2.4587874 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017378 	loss:  -0.017394142 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017389 	loss:  -0.8654073 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017666 	loss:  -1.036374 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018700 	loss:  -1.436029 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018326 	loss:  -1.187609 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017693 	loss:  -0.9496869 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017782 	loss:  -0.82181615 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018003 	loss:  -0.7834926 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017336 	loss:  -0.8066593 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017401 	loss:  -0.80005336 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017672 	loss:  -0.76856524 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018005 	loss:  -0.7973092 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017738 	loss:  -0.79731005 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017820 	loss:  -0.76856804 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017405 	loss:  -0.81635976 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017376 	loss:  -0.76857 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017578 	loss:  -0.79731417 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017926 	loss:  -0.7685721 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017548 	loss:  -0.69025785 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017631 	loss:  -0.79731745 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017566 	loss:  -0.78055894 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017431 	loss:  -0.7685757 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018301 	loss:  -0.7678275 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017817 	loss:  -0.7518162 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017519 	loss:  -0.76857597 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017992 	loss:  -0.74952847 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017720 	loss:  -0.69238573 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018262 	loss:  -0.7615123 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017751 	loss:  -0.7424646 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017718 	loss:  -0.7805601 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.018087 	loss:  -0.72112936 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018198 	loss:  -0.7615128 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017572 	loss:  -0.72341764 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017554 	loss:  -0.7234177 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017923 	loss:  -0.67965525 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018106 	loss:  -0.7114345 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017630 	loss:  -0.692387 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017784 	loss:  -0.75524986 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017789 	loss:  -0.74952984 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017685 	loss:  -0.77827305 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:35.147506
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_23/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 12.60349 	D(real) 0.6515302062034607 	D(fake) 0.9239060282707214 	 G:  5.050397 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 11.50243 	D(real) 0.6312321424484253 	D(fake) 0.8065716624259949 	 G:  4.6141977 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 11.912476 	D(real) 0.5767749547958374 	D(fake) 0.9122844934463501 	 G:  3.889213 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 12.149712 	D(real) 0.48615169525146484 	D(fake) 1.032562255859375 	 G:  3.4597602 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 12.205055 	D(real) 0.43247002363204956 	D(fake) 1.093161940574646 	 G:  3.3735502 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 12.093276 	D(real) 0.4216937720775604 	D(fake) 1.0899657011032104 	 G:  3.4772012 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 11.963037 	D(real) 0.43465015292167664 	D(fake) 1.0607293844223022 	 G:  3.5857768 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 11.943254 	D(real) 0.4482221007347107 	D(fake) 1.0446847677230835 	 G:  3.5863893 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 12.021734 	D(real) 0.4482986629009247 	D(fake) 1.0544180870056152 	 G:  3.4859254 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 12.139466 	D(real) 0.4357406795024872 	D(fake) 1.0816925764083862 	 G:  3.3469465 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 11.964982 	D(real) 0.41836830973625183 	D(fake) 1.0772544145584106 	 G:  3.3337538 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 11.9761715 	D(real) 0.4167192280292511 	D(fake) 1.0803022384643555 	 G:  3.3211763 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 11.986833 	D(real) 0.4151470363140106 	D(fake) 1.0832070112228394 	 G:  3.3094087 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 11.996798 	D(real) 0.41367608308792114 	D(fake) 1.085923671722412 	 G:  3.2985723 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 12.005967 	D(real) 0.412321537733078 	D(fake) 1.0884243249893188 	 G:  3.2887285 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 12.014272 	D(real) 0.41109105944633484 	D(fake) 1.0906928777694702 	 G:  3.279903 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 12.021692 	D(real) 0.4099878668785095 	D(fake) 1.0927237272262573 	 G:  3.2720888 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 12.028224 	D(real) 0.4090110957622528 	D(fake) 1.0945168733596802 	 G:  3.2652588 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 12.033889 	D(real) 0.4081573486328125 	D(fake) 1.0960787534713745 	 G:  3.2593708 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 12.038724 	D(real) 0.407421350479126 	D(fake) 1.0974191427230835 	 G:  3.2543683 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 12.02409 	D(real) 0.40679603815078735 	D(fake) 1.0962151288986206 	 G:  3.2539446 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 12.02444 	D(real) 0.4067430794239044 	D(fake) 1.0963119268417358 	 G:  3.2535818 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 12.024745 	D(real) 0.40669772028923035 	D(fake) 1.0963953733444214 	 G:  3.2532675 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 12.025008 	D(real) 0.40665844082832336 	D(fake) 1.0964676141738892 	 G:  3.2529943 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 12.025243 	D(real) 0.40662428736686707 	D(fake) 1.0965310335159302 	 G:  3.2527544 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 12.025451 	D(real) 0.40659430623054504 	D(fake) 1.096587061882019 	 G:  3.2525408 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 12.025634 	D(real) 0.40656760334968567 	D(fake) 1.0966366529464722 	 G:  3.2523499 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 12.025803 	D(real) 0.4065437316894531 	D(fake) 1.0966815948486328 	 G:  3.2521784 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 12.025955 	D(real) 0.40652230381965637 	D(fake) 1.09672212600708 	 G:  3.2520213 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 12.026098 	D(real) 0.4065026640892029 	D(fake) 1.0967596769332886 	 G:  3.251877 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 12.024659 	D(real) 0.4064846336841583 	D(fake) 1.0965977907180786 	 G:  3.251865 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 12.024675 	D(real) 0.40648311376571655 	D(fake) 1.0966013669967651 	 G:  3.2518523 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 12.024686 	D(real) 0.40648153424263 	D(fake) 1.0966042280197144 	 G:  3.2518404 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 12.024697 	D(real) 0.4064800441265106 	D(fake) 1.0966070890426636 	 G:  3.251829 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 12.024709 	D(real) 0.406478613615036 	D(fake) 1.0966099500656128 	 G:  3.251818 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 12.024718 	D(real) 0.4064772427082062 	D(fake) 1.096612572669983 	 G:  3.2518077 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 12.024729 	D(real) 0.4064759612083435 	D(fake) 1.096615195274353 	 G:  3.2517965 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 12.024738 	D(real) 0.4064745604991913 	D(fake) 1.0966176986694336 	 G:  3.2517858 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 12.024748 	D(real) 0.40647321939468384 	D(fake) 1.0966202020645142 	 G:  3.251776 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 12.024756 	D(real) 0.40647199749946594 	D(fake) 1.0966225862503052 	 G:  3.2517667 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 12.024614 	D(real) 0.4064708352088928 	D(fake) 1.096605896949768 	 G:  3.2517657 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 12.024614 	D(real) 0.40647071599960327 	D(fake) 1.0966061353683472 	 G:  3.2517645 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 12.024615 	D(real) 0.40647056698799133 	D(fake) 1.0966063737869263 	 G:  3.251764 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 12.024617 	D(real) 0.40647050738334656 	D(fake) 1.0966066122055054 	 G:  3.2517629 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 12.02462 	D(real) 0.4064703583717346 	D(fake) 1.0966070890426636 	 G:  3.2517622 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 12.02462 	D(real) 0.40647026896476746 	D(fake) 1.0966072082519531 	 G:  3.2517605 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 12.024619 	D(real) 0.40647006034851074 	D(fake) 1.0966073274612427 	 G:  3.25176 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 12.02462 	D(real) 0.40647000074386597 	D(fake) 1.0966075658798218 	 G:  3.2517588 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 12.024623 	D(real) 0.40646985173225403 	D(fake) 1.09660804271698 	 G:  3.2517583 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 12.024625 	D(real) 0.40646979212760925 	D(fake) 1.096608281135559 	 G:  3.251757 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 24}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 24
\seed data:	 24
\seed noise:	 24
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.019299 	loss:  0.6133499 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018469 	loss:  -3.4977381 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018719 	loss:  3.7055054 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018409 	loss:  3.744375 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018599 	loss:  3.8799796 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017853 	loss:  4.413451 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017899 	loss:  1.8393852 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.018213 	loss:  -1.3508167 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018021 	loss:  1.4722831 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018509 	loss:  4.2116036 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.018378 	loss:  4.632784 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018121 	loss:  4.0084114 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.018642 	loss:  3.447734 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.018203 	loss:  3.3219419 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.018400 	loss:  3.363625 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.018073 	loss:  3.2854476 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.018117 	loss:  3.1916397 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018363 	loss:  3.4463005 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.018135 	loss:  3.3595355 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.018010 	loss:  3.2124534 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018724 	loss:  3.2171526 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018276 	loss:  3.361664 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018192 	loss:  3.2974257 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.018172 	loss:  3.4756608 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018192 	loss:  3.385915 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018511 	loss:  3.4362414 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018775 	loss:  3.421263 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.018357 	loss:  3.4117131 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.018192 	loss:  3.5942779 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.018775 	loss:  3.5199277 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018172 	loss:  3.778087 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.018207 	loss:  3.53525 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.018089 	loss:  3.7146137 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018287 	loss:  3.6902122 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018103 	loss:  3.684423 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.018331 	loss:  3.7400799 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018509 	loss:  3.8389866 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018560 	loss:  3.5333366 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018430 	loss:  3.6690145 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018728 	loss:  3.7859635 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.019181 	loss:  3.482359 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.018250 	loss:  3.5827692 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.018107 	loss:  3.685226 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.018280 	loss:  3.675927 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018440 	loss:  3.6028395 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018340 	loss:  3.6737444 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.018495 	loss:  3.679201 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.018274 	loss:  3.667412 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018468 	loss:  3.6233866 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.018366 	loss:  3.6482534 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.859114
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_24/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 18.792856 	D(real) 0.7835654735565185 	D(fake) 1.0957201957702636 	 G:  4.5872483 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 15.280758 	D(real) 0.46052823066711424 	D(fake) 1.067547607421875 	 G:  4.54664 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 14.786448 	D(real) 0.454655122756958 	D(fake) 1.0239896774291992 	 G:  4.70489 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 14.812965 	D(real) 0.47048330307006836 	D(fake) 1.0108132362365723 	 G:  4.6284213 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 14.986408 	D(real) 0.4628403663635254 	D(fake) 1.0358004570007324 	 G:  4.407006 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 15.202595 	D(real) 0.4406996250152588 	D(fake) 1.0795598030090332 	 G:  4.154758 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 15.402204 	D(real) 0.4154754638671875 	D(fake) 1.1247448921203613 	 G:  3.947534 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 15.538907 	D(real) 0.3947532415390015 	D(fake) 1.1591374397277832 	 G:  3.8196287 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 15.586377 	D(real) 0.38196287155151365 	D(fake) 1.1766748428344727 	 G:  3.7762513 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 15.545412 	D(real) 0.3776251792907715 	D(fake) 1.1769160270690917 	 G:  3.8058252 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 15.322046 	D(real) 0.3805825233459473 	D(fake) 1.1516221046447754 	 G:  3.8137665 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 15.308584 	D(real) 0.3813766002655029 	D(fake) 1.1494817733764648 	 G:  3.8249588 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 15.292606 	D(real) 0.3824958801269531 	D(fake) 1.1467647552490234 	 G:  3.8384864 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 15.275002 	D(real) 0.3838486194610596 	D(fake) 1.143651580810547 	 G:  3.853603 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 15.256483 	D(real) 0.3853602886199951 	D(fake) 1.1402879714965821 	 G:  3.8697093 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 15.237623 	D(real) 0.38697094917297364 	D(fake) 1.1367914199829101 	 G:  3.8863091 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 15.218878 	D(real) 0.38863091468811034 	D(fake) 1.1332568168640136 	 G:  3.9030042 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 15.200602 	D(real) 0.3903003931045532 	D(fake) 1.1297597885131836 	 G:  3.919467 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 15.183062 	D(real) 0.3919466495513916 	D(fake) 1.126359462738037 	 G:  3.935442 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 15.166454 	D(real) 0.3935441493988037 	D(fake) 1.1231013298034669 	 G:  3.9507246 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 15.148292 	D(real) 0.39507246017456055 	D(fake) 1.1197566986083984 	 G:  3.9521666 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 15.146845 	D(real) 0.395216703414917 	D(fake) 1.1194677352905273 	 G:  3.9535255 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 15.14547 	D(real) 0.3953525543212891 	D(fake) 1.1191944122314452 	 G:  3.9548144 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 15.14416 	D(real) 0.3954814910888672 	D(fake) 1.1189345359802245 	 G:  3.9560463 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 15.142903 	D(real) 0.39560461044311523 	D(fake) 1.1186857223510742 	 G:  3.9572284 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 15.141695 	D(real) 0.3957228183746338 	D(fake) 1.1184466361999512 	 G:  3.958368 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 15.140524 	D(real) 0.3958368062973022 	D(fake) 1.118215560913086 	 G:  3.959472 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 15.139387 	D(real) 0.3959472179412842 	D(fake) 1.1179915428161622 	 G:  3.9605448 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 15.138283 	D(real) 0.39605448246002195 	D(fake) 1.1177738189697266 	 G:  3.9615903 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 15.137201 	D(real) 0.3961589813232422 	D(fake) 1.117561149597168 	 G:  3.9626117 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 15.135469 	D(real) 0.39626116752624513 	D(fake) 1.1172858238220216 	 G:  3.962711 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 15.1353655 	D(real) 0.39627115726470946 	D(fake) 1.1172654151916503 	 G:  3.9628096 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 15.135265 	D(real) 0.39628095626831056 	D(fake) 1.117245578765869 	 G:  3.9629061 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 15.135162 	D(real) 0.39629063606262205 	D(fake) 1.1172255516052245 	 G:  3.963002 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 15.135066 	D(real) 0.39630019664764404 	D(fake) 1.1172063827514649 	 G:  3.9630961 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 15.134966 	D(real) 0.39630961418151855 	D(fake) 1.1171870231628418 	 G:  3.96319 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 15.134867 	D(real) 0.3963189601898193 	D(fake) 1.1171676635742187 	 G:  3.963283 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 15.1347685 	D(real) 0.3963282823562622 	D(fake) 1.1171485900878906 	 G:  3.9633753 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 15.134669 	D(real) 0.39633750915527344 	D(fake) 1.117129421234131 	 G:  3.9634678 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 15.134577 	D(real) 0.39634673595428466 	D(fake) 1.1171109199523925 	 G:  3.963558 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 15.134403 	D(real) 0.39635581970214845 	D(fake) 1.1170845031738281 	 G:  3.9635675 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 15.134394 	D(real) 0.3963567495346069 	D(fake) 1.1170825958251953 	 G:  3.9635768 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 15.134383 	D(real) 0.3963576316833496 	D(fake) 1.1170806884765625 	 G:  3.9635859 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 15.134375 	D(real) 0.39635863304138186 	D(fake) 1.1170787811279297 	 G:  3.9635954 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 15.134365 	D(real) 0.39635956287384033 	D(fake) 1.1170769691467286 	 G:  3.9636042 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 15.134354 	D(real) 0.3963604211807251 	D(fake) 1.117074966430664 	 G:  3.9636135 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 15.134344 	D(real) 0.3963613510131836 	D(fake) 1.1170730590820312 	 G:  3.9636228 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 15.134335 	D(real) 0.3963622570037842 	D(fake) 1.1170712471008302 	 G:  3.9636316 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 15.134324 	D(real) 0.39636318683624266 	D(fake) 1.1170692443847656 	 G:  3.9636402 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 15.134316 	D(real) 0.39636409282684326 	D(fake) 1.117067527770996 	 G:  3.9636497 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 25}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 25
\seed data:	 25
\seed noise:	 25
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018570 	loss:  -1.6112996 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017752 	loss:  5.402454 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017997 	loss:  4.9736886 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.017313 	loss:  3.402104 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017785 	loss:  4.2305984 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017254 	loss:  5.0308104 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017209 	loss:  6.002291 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017302 	loss:  5.5737386 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017281 	loss:  5.630887 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017657 	loss:  6.516589 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017572 	loss:  7.173715 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017724 	loss:  7.00227 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017100 	loss:  6.830824 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017120 	loss:  6.859369 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017716 	loss:  6.773618 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017367 	loss:  6.944996 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017802 	loss:  6.9735584 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018115 	loss:  6.8306875 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017469 	loss:  6.6592402 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017633 	loss:  6.773502 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017024 	loss:  6.916329 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.018188 	loss:  6.9162908 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017477 	loss:  7.03053 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017861 	loss:  7.0590467 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017302 	loss:  7.2589846 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018212 	loss:  7.173203 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017272 	loss:  7.0017095 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017042 	loss:  6.4588 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017262 	loss:  6.1730466 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017256 	loss:  6.1444306 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017208 	loss:  6.087219 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017716 	loss:  6.030068 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017897 	loss:  6.0300574 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017429 	loss:  5.972904 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017250 	loss:  6.058608 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017648 	loss:  6.058598 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017369 	loss:  6.0585885 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017507 	loss:  6.0871515 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017217 	loss:  6.00143 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.016996 	loss:  6.0014234 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017118 	loss:  5.9157023 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017000 	loss:  5.858553 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017739 	loss:  5.8585463 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017937 	loss:  5.8585386 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017078 	loss:  6.001388 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017287 	loss:  5.887095 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017788 	loss:  5.887094 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017737 	loss:  5.887093 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017408 	loss:  5.8870926 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017242 	loss:  5.8870916 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.854735
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_25/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 11.947835 	D(real) 0.9061925070626395 	D(fake) 0.8006410598754883 	 G:  4.8475366 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 10.363267 	D(real) 0.6920864922659737 	D(fake) 0.7883802141462054 	 G:  4.3777227 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 10.342958 	D(real) 0.6253540175301688 	D(fake) 0.8522115434919085 	 G:  3.7823856 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 10.692703 	D(real) 0.5403484957558768 	D(fake) 0.9871805054800851 	 G:  3.1094909 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 10.984186 	D(real) 0.4442229611533029 	D(fake) 1.124946457999093 	 G:  2.6719153 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 11.185271 	D(real) 0.3817038195473807 	D(fake) 1.2161921092442103 	 G:  2.4787662 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 11.234819 	D(real) 0.35410990033830914 	D(fake) 1.2508643014090401 	 G:  2.463988 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 11.147504 	D(real) 0.3519984654017857 	D(fake) 1.240502085004534 	 G:  2.5435743 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 10.977416 	D(real) 0.36336779594421387 	D(fake) 1.2048345293317522 	 G:  2.6682272 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 10.78378 	D(real) 0.3811753136771066 	D(fake) 1.1593647003173828 	 G:  2.8081682 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 10.565241 	D(real) 0.40116688183375765 	D(fake) 1.1081532069614954 	 G:  2.8214233 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 10.55333 	D(real) 0.40306047030857634 	D(fake) 1.1045581272670202 	 G:  2.8324382 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 10.543817 	D(real) 0.40463403293064665 	D(fake) 1.1016255106244768 	 G:  2.8413713 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 10.53641 	D(real) 0.40591018540518625 	D(fake) 1.0992913246154785 	 G:  2.848401 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 10.530843 	D(real) 0.406914438520159 	D(fake) 1.097491673060826 	 G:  2.8537204 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 10.526863 	D(real) 0.4076743466513498 	D(fake) 1.096163272857666 	 G:  2.8575268 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 10.5242405 	D(real) 0.40821811131068636 	D(fake) 1.0952448844909668 	 G:  2.8600192 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 10.522764 	D(real) 0.40857417242867605 	D(fake) 1.0946779251098633 	 G:  2.86139 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 10.52224 	D(real) 0.4087700162615095 	D(fake) 1.094407081604004 	 G:  2.861823 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 10.522482 	D(real) 0.40883186885288786 	D(fake) 1.0943798337663924 	 G:  2.8614929 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 10.507316 	D(real) 0.40878469603402273 	D(fake) 1.0922603607177734 	 G:  2.8614035 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 10.50745 	D(real) 0.4087719236101423 	D(fake) 1.092292308807373 	 G:  2.8612685 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 10.507616 	D(real) 0.40875264576503206 	D(fake) 1.0923352922712053 	 G:  2.8610964 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 10.507812 	D(real) 0.4087280545915876 	D(fake) 1.0923878805977958 	 G:  2.8608966 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 10.508031 	D(real) 0.40869951248168945 	D(fake) 1.0924477577209473 	 G:  2.8606734 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 10.508266 	D(real) 0.4086677687508719 	D(fake) 1.092513084411621 	 G:  2.8604338 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 10.508516 	D(real) 0.4086334364754813 	D(fake) 1.092583111354283 	 G:  2.8601804 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 10.508774 	D(real) 0.40859719685145784 	D(fake) 1.092656203678676 	 G:  2.8599157 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 10.509042 	D(real) 0.40855939047677176 	D(fake) 1.0927322932652064 	 G:  2.8596444 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 10.509314 	D(real) 0.40852063042776926 	D(fake) 1.0928099496023995 	 G:  2.8593674 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 10.507816 	D(real) 0.4084810529436384 	D(fake) 1.0926356315612793 	 G:  2.8593392 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 10.507846 	D(real) 0.4084770679473877 	D(fake) 1.0926438059125627 	 G:  2.8593109 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 10.507874 	D(real) 0.40847298077174593 	D(fake) 1.0926518440246582 	 G:  2.8592825 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 10.507902 	D(real) 0.4084689276559012 	D(fake) 1.0926600183759416 	 G:  2.859254 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 10.507931 	D(real) 0.4084648404802595 	D(fake) 1.092668056488037 	 G:  2.8592255 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 10.507958 	D(real) 0.40846078736441477 	D(fake) 1.0926761627197266 	 G:  2.8591962 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 10.507986 	D(real) 0.408456598009382 	D(fake) 1.09268433707101 	 G:  2.8591676 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 10.508015 	D(real) 0.40845251083374023 	D(fake) 1.0926924433026994 	 G:  2.8591387 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 10.508045 	D(real) 0.40844842365809847 	D(fake) 1.092700822012765 	 G:  2.8591094 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 10.508073 	D(real) 0.4084442343030657 	D(fake) 1.0927090644836426 	 G:  2.8590803 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 10.507923 	D(real) 0.4084400790078299 	D(fake) 1.0926917621067591 	 G:  2.859077 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 10.507924 	D(real) 0.4084396021706717 	D(fake) 1.0926923751831055 	 G:  2.859074 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 10.507928 	D(real) 0.40843915939331055 	D(fake) 1.0926933969770158 	 G:  2.8590713 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 10.507933 	D(real) 0.40843875067574636 	D(fake) 1.0926944187709264 	 G:  2.8590682 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 10.507935 	D(real) 0.4084383760179792 	D(fake) 1.0926950999668665 	 G:  2.8590655 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 10.507938 	D(real) 0.408437933240618 	D(fake) 1.092696053641183 	 G:  2.8590631 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 10.50794 	D(real) 0.4084376607622419 	D(fake) 1.0926966667175293 	 G:  2.859059 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 10.507942 	D(real) 0.40843704768589567 	D(fake) 1.0926975522722517 	 G:  2.8590565 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 10.507945 	D(real) 0.40843660490853445 	D(fake) 1.092698437826974 	 G:  2.8590536 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 10.507948 	D(real) 0.4084362643105643 	D(fake) 1.0926991190229143 	 G:  2.8590508 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 26}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 26
\seed data:	 26
\seed noise:	 26
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018813 	loss:  1.0881139 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018697 	loss:  1.6213157 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018014 	loss:  3.602045 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018104 	loss:  4.173054 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017524 	loss:  4.8970923 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017575 	loss:  5.259087 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017867 	loss:  6.0782 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017450 	loss:  5.640094 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.018235 	loss:  3.418392 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018321 	loss:  2.630592 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017669 	loss:  1.9316374 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017735 	loss:  1.4063019 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017714 	loss:  1.4354606 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017900 	loss:  1.3402272 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017854 	loss:  1.2175398 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017724 	loss:  1.1887938 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017979 	loss:  1.1086713 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.018188 	loss:  1.1737187 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017377 	loss:  1.1010724 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.017401 	loss:  1.1448567 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.017502 	loss:  1.1065304 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017716 	loss:  1.1065283 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.018141 	loss:  0.91945404 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017817 	loss:  0.7633051 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018008 	loss:  0.7146187 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017837 	loss:  0.73435235 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.018033 	loss:  0.7258004 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017284 	loss:  0.76618385 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017311 	loss:  0.69499815 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017623 	loss:  0.867914 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.018431 	loss:  1.0466354 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017684 	loss:  1.1069814 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017624 	loss:  0.9405932 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018001 	loss:  1.1089263 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017479 	loss:  1.104007 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017482 	loss:  0.80119 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017729 	loss:  0.77836704 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.018003 	loss:  1.0049936 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017579 	loss:  1.1448478 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.018164 	loss:  1.1592898 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017362 	loss:  1.1472932 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017571 	loss:  1.2591333 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017570 	loss:  1.1992733 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017644 	loss:  1.1700724 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017641 	loss:  1.038312 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017693 	loss:  1.0062798 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017907 	loss:  0.8528695 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017868 	loss:  1.177022 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.017772 	loss:  1.0835001 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017572 	loss:  0.72900265 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.868951
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_26/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 12.712584 	D(real) 0.5588719844818115 	D(fake) 1.0302009582519531 	 G:  4.3022285 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 12.102225 	D(real) 0.5387696027755737 	D(fake) 0.9740085601806641 	 G:  3.8681052 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 11.794268 	D(real) 0.4834670126438141 	D(fake) 0.9908164739608765 	 G:  3.8617725 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 11.887279 	D(real) 0.4827120006084442 	D(fake) 1.0031977891921997 	 G:  3.6899085 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 12.050383 	D(real) 0.4612198770046234 	D(fake) 1.045077919960022 	 G:  3.4671478 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 12.15723 	D(real) 0.43337082862854004 	D(fake) 1.0862829685211182 	 G:  3.3064985 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 12.223503 	D(real) 0.41330188512802124 	D(fake) 1.114635944366455 	 G:  3.1969774 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 12.2515545 	D(real) 0.3996155858039856 	D(fake) 1.131828784942627 	 G:  3.1513848 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 12.219419 	D(real) 0.39391812682151794 	D(fake) 1.1335091590881348 	 G:  3.1711056 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 12.176203 	D(real) 0.39638665318489075 	D(fake) 1.125638723373413 	 G:  3.206225 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 12.077752 	D(real) 0.400775671005249 	D(fake) 1.1089433431625366 	 G:  3.2094305 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 12.074494 	D(real) 0.40117761492729187 	D(fake) 1.108134150505066 	 G:  3.2122772 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 12.071666 	D(real) 0.4015321433544159 	D(fake) 1.1074260473251343 	 G:  3.2147992 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 12.06913 	D(real) 0.40184855461120605 	D(fake) 1.106792688369751 	 G:  3.2170806 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 12.0668745 	D(real) 0.40213289856910706 	D(fake) 1.1062264442443848 	 G:  3.2191367 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 12.06485 	D(real) 0.40238964557647705 	D(fake) 1.105716586112976 	 G:  3.220999 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 12.063057 	D(real) 0.402621865272522 	D(fake) 1.1052602529525757 	 G:  3.2226715 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 12.061376 	D(real) 0.4028320610523224 	D(fake) 1.1048399209976196 	 G:  3.2242217 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 12.059967 	D(real) 0.4030221700668335 	D(fake) 1.1044737100601196 	 G:  3.2255678 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 12.058654 	D(real) 0.40319380164146423 	D(fake) 1.104137897491455 	 G:  3.2268078 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 12.0504265 	D(real) 0.4033484160900116 	D(fake) 1.1029548645019531 	 G:  3.226914 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 12.050285 	D(real) 0.40336284041404724 	D(fake) 1.102922797203064 	 G:  3.2270374 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 12.05015 	D(real) 0.40337690711021423 	D(fake) 1.1028918027877808 	 G:  3.227158 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 12.050066 	D(real) 0.4033905863761902 	D(fake) 1.1028677225112915 	 G:  3.2272518 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 12.04997 	D(real) 0.4034041464328766 	D(fake) 1.102842092514038 	 G:  3.2273521 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 12.049833 	D(real) 0.4034174084663391 	D(fake) 1.1028116941452026 	 G:  3.2274714 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 12.049757 	D(real) 0.4034304618835449 	D(fake) 1.1027891635894775 	 G:  3.227559 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 12.049652 	D(real) 0.4034433960914612 	D(fake) 1.1027631759643555 	 G:  3.2276611 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 12.049546 	D(real) 0.40345609188079834 	D(fake) 1.1027371883392334 	 G:  3.2277641 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 12.049449 	D(real) 0.40346869826316833 	D(fake) 1.1027123928070068 	 G:  3.2278612 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 12.048637 	D(real) 0.4034811854362488 	D(fake) 1.1025984287261963 	 G:  3.2278724 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 12.048633 	D(real) 0.4034824073314667 	D(fake) 1.102596640586853 	 G:  3.22788 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 12.048614 	D(real) 0.40348365902900696 	D(fake) 1.1025930643081665 	 G:  3.227894 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 12.048611 	D(real) 0.40348488092422485 	D(fake) 1.1025913953781128 	 G:  3.227901 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 12.048593 	D(real) 0.40348613262176514 	D(fake) 1.1025879383087158 	 G:  3.2279148 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 12.048574 	D(real) 0.40348732471466064 	D(fake) 1.1025844812393188 	 G:  3.2279286 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 12.048538 	D(real) 0.40348854660987854 	D(fake) 1.1025787591934204 	 G:  3.2279513 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 12.048572 	D(real) 0.4034898281097412 	D(fake) 1.1025816202163696 	 G:  3.2279398 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 12.048555 	D(real) 0.4034910798072815 	D(fake) 1.1025782823562622 	 G:  3.2279527 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 12.048523 	D(real) 0.403492271900177 	D(fake) 1.1025731563568115 	 G:  3.227973 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 12.048468 	D(real) 0.4034935235977173 	D(fake) 1.1025649309158325 	 G:  3.2279623 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 12.048449 	D(real) 0.4034937024116516 	D(fake) 1.102562427520752 	 G:  3.227972 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 12.048458 	D(real) 0.4034937918186188 	D(fake) 1.102563500404358 	 G:  3.227968 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 12.048431 	D(real) 0.40349388122558594 	D(fake) 1.102560043334961 	 G:  3.2279813 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 12.048451 	D(real) 0.4034940004348755 	D(fake) 1.102562427520752 	 G:  3.227972 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 12.048277 	D(real) 0.40349411964416504 	D(fake) 1.1025404930114746 	 G:  3.2280595 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 12.048465 	D(real) 0.403494268655777 	D(fake) 1.1025638580322266 	 G:  3.2279658 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 12.048458 	D(real) 0.4034944176673889 	D(fake) 1.1025627851486206 	 G:  3.2279708 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 12.048447 	D(real) 0.40349453687667847 	D(fake) 1.102561354637146 	 G:  3.2279758 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 12.048445 	D(real) 0.403494656085968 	D(fake) 1.1025609970092773 	 G:  3.2279773 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 27}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 27
\seed data:	 27
\seed noise:	 27
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018777 	loss:  4.278009 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018439 	loss:  2.77262 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017172 	loss:  4.7837677 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.016940 	loss:  7.8464193 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.017217 	loss:  6.777142 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.016787 	loss:  7.98347 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.016946 	loss:  5.8352246 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.016971 	loss:  5.515275 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017238 	loss:  4.783856 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017152 	loss:  2.5438614 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017066 	loss:  2.133106 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.017044 	loss:  3.495528 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.016853 	loss:  3.5489159 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017025 	loss:  3.640337 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017365 	loss:  2.8148003 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017593 	loss:  3.2262192 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017089 	loss:  3.2262185 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017330 	loss:  3.16699 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017055 	loss:  3.0356853 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.016941 	loss:  3.252744 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.016925 	loss:  3.4412735 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017157 	loss:  3.4547868 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017775 	loss:  3.5005 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.016967 	loss:  3.3935552 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017156 	loss:  3.5004988 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.017183 	loss:  3.4749713 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017076 	loss:  3.363355 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.016998 	loss:  3.5462112 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017307 	loss:  3.7539272 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.016956 	loss:  3.7290673 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017161 	loss:  3.7290668 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017137 	loss:  3.8662097 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017083 	loss:  3.8662097 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017734 	loss:  3.5919242 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.018247 	loss:  3.7290666 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017182 	loss:  3.7290666 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017774 	loss:  3.710881 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017071 	loss:  3.820495 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.017036 	loss:  3.7290664 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017476 	loss:  3.7996397 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017396 	loss:  3.7996397 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017489 	loss:  3.7290661 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017131 	loss:  3.7996397 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.017151 	loss:  3.6678364 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017266 	loss:  3.7290661 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017693 	loss:  3.7108808 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017529 	loss:  3.7290661 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.016851 	loss:  3.5919235 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.016942 	loss:  3.729066 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.017498 	loss:  3.7290661 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.083988
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_27/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 10.264202 	D(real) 0.8257981141408285 	D(fake) 0.8849022388458252 	 G:  4.32273 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 9.143408 	D(real) 0.7223446369171143 	D(fake) 0.801556666692098 	 G:  3.427956 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 8.895823 	D(real) 0.5712666511535645 	D(fake) 0.9113704363505045 	 G:  2.949065 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 9.141513 	D(real) 0.4916165272394816 	D(fake) 1.0319689114888508 	 G:  2.5958705 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 9.362187 	D(real) 0.43282584349314374 	D(fake) 1.1275386810302734 	 G:  2.3740194 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 9.462306 	D(real) 0.3957565625508626 	D(fake) 1.1812944412231445 	 G:  2.277557 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 9.409947 	D(real) 0.37949633598327637 	D(fake) 1.1888282299041748 	 G:  2.2990515 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 9.274504 	D(real) 0.38312840461730957 	D(fake) 1.162622292836507 	 G:  2.3840673 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 9.1489935 	D(real) 0.3973718484242757 	D(fake) 1.1274604002634685 	 G:  2.4706326 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 9.074955 	D(real) 0.4118303855260213 	D(fake) 1.100662072499593 	 G:  2.5259113 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 8.947142 	D(real) 0.4210354487101237 	D(fake) 1.0701548258463542 	 G:  2.5279105 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 8.948006 	D(real) 0.42136136690775555 	D(fake) 1.0699729919433594 	 G:  2.5269034 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 8.9506035 	D(real) 0.42120782534281415 	D(fake) 1.0705593427022297 	 G:  2.5238776 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 8.954835 	D(real) 0.42069069544474286 	D(fake) 1.0717817942301433 	 G:  2.519175 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 8.960331 	D(real) 0.41990474859873456 	D(fake) 1.0734837849934895 	 G:  2.513235 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 8.966282 	D(real) 0.4189279079437256 	D(fake) 1.075452486673991 	 G:  2.5066872 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 8.972792 	D(real) 0.4178247054417928 	D(fake) 1.0776405334472656 	 G:  2.4996455 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 8.97955 	D(real) 0.4166485865910848 	D(fake) 1.079943100611369 	 G:  2.4924095 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 8.986291 	D(real) 0.4154429038365682 	D(fake) 1.0822722911834717 	 G:  2.485224 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 8.992897 	D(real) 0.41424238681793213 	D(fake) 1.084573745727539 	 G:  2.4782338 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 8.98214 	D(real) 0.4130744934082031 	D(fake) 1.0839488506317139 	 G:  2.4775698 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 8.982739 	D(real) 0.4129625956217448 	D(fake) 1.0841606458028157 	 G:  2.4769309 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 8.983456 	D(real) 0.4128549098968506 	D(fake) 1.0843876997629802 	 G:  2.4762444 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 8.984007 	D(real) 0.4127509593963623 	D(fake) 1.0845834414164226 	 G:  2.4756532 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 8.984894 	D(real) 0.41265010833740234 	D(fake) 1.0848321914672852 	 G:  2.474898 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 8.985117 	D(real) 0.41255199909210205 	D(fake) 1.0849675337473552 	 G:  2.47449 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 8.985525 	D(real) 0.41245631376902264 	D(fake) 1.0851311683654785 	 G:  2.4739957 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 8.986149 	D(real) 0.41236285368601483 	D(fake) 1.0853285789489746 	 G:  2.4733968 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 8.986589 	D(real) 0.4122714598973592 	D(fake) 1.0854934056599934 	 G:  2.472898 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 8.987128 	D(real) 0.41218193372090656 	D(fake) 1.0856727759043376 	 G:  2.472354 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 8.986035 	D(real) 0.41209407647450763 	D(fake) 1.0855785210927327 	 G:  2.4723144 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 8.986214 	D(real) 0.41208545366923016 	D(fake) 1.085616906483968 	 G:  2.4721975 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 8.986214 	D(real) 0.4120769500732422 	D(fake) 1.085625410079956 	 G:  2.4721715 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 8.986202 	D(real) 0.41206852595011395 	D(fake) 1.0856319268544514 	 G:  2.472152 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 8.98645 	D(real) 0.4120602210362752 	D(fake) 1.085681438446045 	 G:  2.4720008 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 8.986372 	D(real) 0.4120519955952962 	D(fake) 1.0856765906016033 	 G:  2.4720159 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 8.986412 	D(real) 0.41204380989074707 	D(fake) 1.0856916109720867 	 G:  2.4719703 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 8.986428 	D(real) 0.41203562418619794 	D(fake) 1.0857024192810059 	 G:  2.4719367 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 8.986429 	D(real) 0.4120275179545085 	D(fake) 1.0857107639312744 	 G:  2.4719112 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 8.986581 	D(real) 0.4120194911956787 	D(fake) 1.0857439835866292 	 G:  2.4718099 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 8.986391 	D(real) 0.41201146443684894 	D(fake) 1.0857203006744385 	 G:  2.4718475 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 8.986391 	D(real) 0.4120106299718221 	D(fake) 1.0857212543487549 	 G:  2.4718447 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 8.986432 	D(real) 0.4120098352432251 	D(fake) 1.0857288837432861 	 G:  2.4718215 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 8.986357 	D(real) 0.4120090405146281 	D(fake) 1.0857171217600505 	 G:  2.4718573 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 8.986554 	D(real) 0.41200824578603107 	D(fake) 1.0857508182525635 	 G:  2.4717546 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 8.986454 	D(real) 0.41200749079386395 	D(fake) 1.0857349236806233 	 G:  2.4718032 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 8.986416 	D(real) 0.4120066563288371 	D(fake) 1.0857293605804443 	 G:  2.47182 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 8.986401 	D(real) 0.4120059013366699 	D(fake) 1.085727612177531 	 G:  2.4718256 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 8.986601 	D(real) 0.41200510660807294 	D(fake) 1.0857617855072021 	 G:  2.471721 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 8.986488 	D(real) 0.4120043118794759 	D(fake) 1.0857436656951904 	 G:  2.4717762 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 28}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 28
\seed data:	 28
\seed noise:	 28
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018710 	loss:  -1.0781862 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.018398 	loss:  1.921647 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.018333 	loss:  2.6681266 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.018145 	loss:  1.7080193 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.018039 	loss:  2.867863 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.017479 	loss:  4.2146173 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.017488 	loss:  3.4300303 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.017583 	loss:  4.588086 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.017636 	loss:  3.8147602 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.018048 	loss:  3.3347485 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017805 	loss:  2.9880643 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.018523 	loss:  1.9284114 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.017738 	loss:  1.2147036 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.017612 	loss:  1.2280325 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017479 	loss:  0.52887774 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.017456 	loss:  0.3136142 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.017727 	loss:  0.4952635 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017719 	loss:  0.25470397 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017965 	loss:  0.22067149 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.018155 	loss:  0.24733724 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.018047 	loss:  0.0053909225 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.017915 	loss:  -0.03863259 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.017516 	loss:  -0.1921627 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.017585 	loss:  -0.08204502 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.018475 	loss:  -0.24628085 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.018243 	loss:  -0.20667335 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.017806 	loss:  -0.56171256 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.017993 	loss:  -0.32484177 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017949 	loss:  -0.07054684 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.017970 	loss:  -0.060368042 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.017732 	loss:  -0.17430802 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017737 	loss:  -0.16757068 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.017993 	loss:  -0.09665534 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.018351 	loss:  -0.13398586 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017584 	loss:  0.03098952 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.017525 	loss:  -0.06530691 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.018182 	loss:  0.07934719 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017814 	loss:  -0.08460791 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.018467 	loss:  -0.0069000744 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.017931 	loss:  -0.13674113 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017729 	loss:  -0.011973536 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017607 	loss:  0.014749004 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017855 	loss:  -0.067263536 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.019271 	loss:  0.12426715 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.018084 	loss:  -0.011023326 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.018207 	loss:  -0.018500756 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017754 	loss:  0.03811728 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.017749 	loss:  0.0857621 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.018548 	loss:  0.14802621 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.018131 	loss:  0.045873966 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:30.928108
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_28/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 13.459336 	D(real) 0.7717200915018717 	D(fake) 0.7237617174784342 	 G:  7.1525235 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 13.936997 	D(real) 0.7948540581597222 	D(fake) 0.7537012100219727 	 G:  5.2071314 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 13.874004 	D(real) 0.5785137812296549 	D(fake) 0.9630422592163086 	 G:  3.9854286 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 14.267584 	D(real) 0.44281869464450413 	D(fake) 1.1424684524536133 	 G:  3.3022707 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 14.603056 	D(real) 0.36691853735182023 	D(fake) 1.2556432088216145 	 G:  3.000807 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 14.692279 	D(real) 0.33342340257432723 	D(fake) 1.2990520265367296 	 G:  2.9756026 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 14.489024 	D(real) 0.3306230703989665 	D(fake) 1.2792684766981337 	 G:  3.162746 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 14.081859 	D(real) 0.35141650835673016 	D(fake) 1.2132344775729709 	 G:  3.476162 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 13.672388 	D(real) 0.38624029689364964 	D(fake) 1.1329139073689778 	 G:  3.7996368 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 13.416524 	D(real) 0.4221818976932102 	D(fake) 1.0685430102878146 	 G:  4.0211897 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 13.22177 	D(real) 0.44679896036783856 	D(fake) 1.0222866270277235 	 G:  4.028386 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 13.227642 	D(real) 0.44759851031833225 	D(fake) 1.0221394432915583 	 G:  4.022395 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 13.240927 	D(real) 0.4469328456454807 	D(fake) 1.0242812898423936 	 G:  4.0065746 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 13.259626 	D(real) 0.4451750119527181 	D(fake) 1.0281168619791667 	 G:  3.983715 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 13.282166 	D(real) 0.44263503286573624 	D(fake) 1.0331611633300781 	 G:  3.9561167 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 13.307252 	D(real) 0.43956854608323837 	D(fake) 1.0390150282118056 	 G:  3.925668 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 13.333821 	D(real) 0.4361853864457872 	D(fake) 1.0453502866956923 	 G:  3.8938868 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 13.360973 	D(real) 0.43265411588880753 	D(fake) 1.0518984264797635 	 G:  3.8619714 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 13.3879595 	D(real) 0.4291079574161106 	D(fake) 1.0584430694580078 	 G:  3.8308458 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 13.414166 	D(real) 0.42564961645338273 	D(fake) 1.0648132960001628 	 G:  3.801197 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 13.396872 	D(real) 0.422355228000217 	D(fake) 1.066186057196723 	 G:  3.798413 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 13.399229 	D(real) 0.4220459991031223 	D(fake) 1.0667572021484375 	 G:  3.7957866 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 13.401476 	D(real) 0.4217540952894423 	D(fake) 1.0672987831963434 	 G:  3.7932916 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 13.403627 	D(real) 0.4214768674638536 	D(fake) 1.067815038892958 	 G:  3.7909093 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 13.405695 	D(real) 0.42121219635009766 	D(fake) 1.0683094660441081 	 G:  3.7886238 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 13.40769 	D(real) 0.420958227581448 	D(fake) 1.068785137600369 	 G:  3.7864213 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 13.409624 	D(real) 0.42071347766452366 	D(fake) 1.0692448086208768 	 G:  3.7842941 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 13.411503 	D(real) 0.42047712537977433 	D(fake) 1.0696898566351996 	 G:  3.7822318 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 13.413336 	D(real) 0.42024797863430446 	D(fake) 1.0701226128472223 	 G:  3.7802243 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 13.415122 	D(real) 0.4200249777899848 	D(fake) 1.0705441368950739 	 G:  3.7782707 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 13.41342 	D(real) 0.41980791091918945 	D(fake) 1.0705720053778753 	 G:  3.77808 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 13.413591 	D(real) 0.4197866916656494 	D(fake) 1.0706123775906033 	 G:  3.777893 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 13.41376 	D(real) 0.4197659757402208 	D(fake) 1.0706517961290147 	 G:  3.7777095 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 13.413925 	D(real) 0.4197455247243245 	D(fake) 1.0706905788845487 	 G:  3.777529 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 13.414091 	D(real) 0.4197254445817735 	D(fake) 1.0707291497124567 	 G:  3.7773495 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 13.414252 	D(real) 0.4197055763668484 	D(fake) 1.0707668728298612 	 G:  3.777172 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 13.414413 	D(real) 0.419685787624783 	D(fake) 1.0708045959472656 	 G:  3.7769952 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 13.414576 	D(real) 0.41966623730129665 	D(fake) 1.0708421071370442 	 G:  3.7768204 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 13.414733 	D(real) 0.41964676645067 	D(fake) 1.0708790885077581 	 G:  3.776648 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 13.414894 	D(real) 0.4196276134914822 	D(fake) 1.0709161758422852 	 G:  3.7764735 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 13.414721 	D(real) 0.41960827509562176 	D(fake) 1.070916281806098 	 G:  3.7764564 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 13.414738 	D(real) 0.419606261783176 	D(fake) 1.0709202024671767 	 G:  3.77644 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 13.414755 	D(real) 0.4196045133802626 	D(fake) 1.0709238052368164 	 G:  3.776423 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 13.414769 	D(real) 0.4196026060316298 	D(fake) 1.0709273020426433 	 G:  3.7764058 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 13.414784 	D(real) 0.419600698682997 	D(fake) 1.070930904812283 	 G:  3.776389 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 13.414801 	D(real) 0.4195987913343642 	D(fake) 1.0709346135457356 	 G:  3.7763722 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 13.414816 	D(real) 0.4195969369676378 	D(fake) 1.0709381103515625 	 G:  3.776355 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 13.414833 	D(real) 0.41959502961900497 	D(fake) 1.0709419250488281 	 G:  3.7763376 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 13.414846 	D(real) 0.41959312227037215 	D(fake) 1.070945421854655 	 G:  3.7763212 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 13.414864 	D(real) 0.4195912414126926 	D(fake) 1.0709491305881076 	 G:  3.7763045 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
|------------------------
| Modelcase   : GAN_linear_pretrained_16_METR_bt
|             : {'id': 2, 'model_case': 'GAN_linear_pretrained_16_METR_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 29}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 29
\seed data:	 29
\seed noise:	 29
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_METR_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.018043 	loss:  1.3583273 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.017172 	loss:  1.2864995 	lr:  0.01
	epoch:	 3 / 50 	 - time tr epoch:  0:00:00.017101 	loss:  3.9714818 	lr:  0.01
	epoch:	 4 / 50 	 - time tr epoch:  0:00:00.016752 	loss:  4.246046 	lr:  0.01
	epoch:	 5 / 50 	 - time tr epoch:  0:00:00.016498 	loss:  4.3258295 	lr:  0.01
	epoch:	 6 / 50 	 - time tr epoch:  0:00:00.016356 	loss:  3.2251449 	lr:  0.01
	epoch:	 7 / 50 	 - time tr epoch:  0:00:00.016737 	loss:  5.7660604 	lr:  0.01
	epoch:	 8 / 50 	 - time tr epoch:  0:00:00.016805 	loss:  6.6114545 	lr:  0.01
	epoch:	 9 / 50 	 - time tr epoch:  0:00:00.016444 	loss:  4.9662795 	lr:  0.01
	epoch:	 10 / 50 	 - time tr epoch:  0:00:00.017097 	loss:  5.173551 	lr:  0.01
	epoch:	 11 / 50 	 - time tr epoch:  0:00:00.017102 	loss:  5.2514677 	lr:  0.01
	epoch:	 12 / 50 	 - time tr epoch:  0:00:00.016403 	loss:  5.0114627 	lr:  0.01
	epoch:	 13 / 50 	 - time tr epoch:  0:00:00.016698 	loss:  4.246265 	lr:  0.01
	epoch:	 14 / 50 	 - time tr epoch:  0:00:00.016430 	loss:  4.086263 	lr:  0.01
	epoch:	 15 / 50 	 - time tr epoch:  0:00:00.017493 	loss:  4.023159 	lr:  0.001
	epoch:	 16 / 50 	 - time tr epoch:  0:00:00.016960 	loss:  4.3449674 	lr:  0.001
	epoch:	 17 / 50 	 - time tr epoch:  0:00:00.016879 	loss:  4.2301636 	lr:  0.001
	epoch:	 18 / 50 	 - time tr epoch:  0:00:00.017279 	loss:  4.2504196 	lr:  0.001
	epoch:	 19 / 50 	 - time tr epoch:  0:00:00.017345 	loss:  4.2504196 	lr:  0.001
	epoch:	 20 / 50 	 - time tr epoch:  0:00:00.016820 	loss:  4.250419 	lr:  0.001
	epoch:	 21 / 50 	 - time tr epoch:  0:00:00.016708 	loss:  4.010419 	lr:  0.001
	epoch:	 22 / 50 	 - time tr epoch:  0:00:00.016890 	loss:  4.0104184 	lr:  0.001
	epoch:	 23 / 50 	 - time tr epoch:  0:00:00.016472 	loss:  4.170418 	lr:  0.001
	epoch:	 24 / 50 	 - time tr epoch:  0:00:00.016844 	loss:  4.170417 	lr:  0.001
	epoch:	 25 / 50 	 - time tr epoch:  0:00:00.017546 	loss:  4.1704164 	lr:  0.001
	epoch:	 26 / 50 	 - time tr epoch:  0:00:00.016734 	loss:  4.090416 	lr:  0.001
	epoch:	 27 / 50 	 - time tr epoch:  0:00:00.016612 	loss:  4.090415 	lr:  0.001
	epoch:	 28 / 50 	 - time tr epoch:  0:00:00.016589 	loss:  4.3304143 	lr:  0.001
	epoch:	 29 / 50 	 - time tr epoch:  0:00:00.017044 	loss:  4.330414 	lr:  0.001
	epoch:	 30 / 50 	 - time tr epoch:  0:00:00.016496 	loss:  4.330413 	lr:  0.0001
	epoch:	 31 / 50 	 - time tr epoch:  0:00:00.016934 	loss:  4.3304124 	lr:  0.0001
	epoch:	 32 / 50 	 - time tr epoch:  0:00:00.017252 	loss:  4.3304124 	lr:  0.0001
	epoch:	 33 / 50 	 - time tr epoch:  0:00:00.016891 	loss:  4.3304124 	lr:  0.0001
	epoch:	 34 / 50 	 - time tr epoch:  0:00:00.017012 	loss:  4.3304124 	lr:  0.0001
	epoch:	 35 / 50 	 - time tr epoch:  0:00:00.017383 	loss:  4.330412 	lr:  0.0001
	epoch:	 36 / 50 	 - time tr epoch:  0:00:00.016809 	loss:  4.330412 	lr:  0.0001
	epoch:	 37 / 50 	 - time tr epoch:  0:00:00.017042 	loss:  4.330412 	lr:  0.0001
	epoch:	 38 / 50 	 - time tr epoch:  0:00:00.017464 	loss:  4.330412 	lr:  0.0001
	epoch:	 39 / 50 	 - time tr epoch:  0:00:00.016779 	loss:  4.330412 	lr:  0.0001
	epoch:	 40 / 50 	 - time tr epoch:  0:00:00.016750 	loss:  4.330412 	lr:  0.0001
	epoch:	 41 / 50 	 - time tr epoch:  0:00:00.017280 	loss:  4.330412 	lr:  0.0001
	epoch:	 42 / 50 	 - time tr epoch:  0:00:00.017025 	loss:  4.3304114 	lr:  0.0001
	epoch:	 43 / 50 	 - time tr epoch:  0:00:00.017731 	loss:  4.3304114 	lr:  0.0001
	epoch:	 44 / 50 	 - time tr epoch:  0:00:00.016832 	loss:  4.3304114 	lr:  0.0001
	epoch:	 45 / 50 	 - time tr epoch:  0:00:00.017226 	loss:  4.3304114 	lr:  1e-05
	epoch:	 46 / 50 	 - time tr epoch:  0:00:00.017354 	loss:  4.3304114 	lr:  1e-05
	epoch:	 47 / 50 	 - time tr epoch:  0:00:00.017523 	loss:  4.3304114 	lr:  1e-05
	epoch:	 48 / 50 	 - time tr epoch:  0:00:00.016942 	loss:  4.3304114 	lr:  1e-05
	epoch:	 49 / 50 	 - time tr epoch:  0:00:00.016847 	loss:  4.3304114 	lr:  1e-05
	epoch:	 50 / 50 	 - time tr epoch:  0:00:00.016722 	loss:  4.3304114 	lr:  1e-05
	TIME TRAIN MODEL:	 0:00:31.581903
	SAVE TRAINED MODEL:	 data/neuroCorrelation/2023_11_17___chengdu_29/AE/model_save/model_weights.pth
1
optim_score: 1
PHASE: AutoEncoder
PREDICT PHASE: Training data
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Testing data
		 Statistics data
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: latent
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: latent
			correlation analysis: output
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
PREDICT PHASE: Copula Latent data
	copulaLatent	copula.sample : start
	copulaLatent	copula.sample : end
	STATS PHASE:  Correlation and distribution
	STATS PHASE:  Plots
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  GAN
	TRAIN TRAINED MODEL:	
GAN gen mode training:	 True
GAN dis mode training:	 True
model_gen.training	:  True
model_dis.training	:  True
	epoch:	 0 / 50  - 
	epoch:	 0 / 50 	 - loss D:	all 8.964231 	D(real) 0.7924872398376465 	D(fake) 1.0003588676452637 	 G:  3.5610375 			lr D:  0.1 	 G:  0.1
	epoch:	 1 / 50 	 - loss D:	all 7.664797 	D(real) 0.7174176216125489 	D(fake) 0.8155417442321777 	 G:  2.7011175 			lr D:  0.1 	 G:  0.1
	epoch:	 2 / 50 	 - loss D:	all 7.503735 	D(real) 0.5401564598083496 	D(fake) 0.9605905532836914 	 G:  2.394224 			lr D:  0.1 	 G:  0.1
	epoch:	 3 / 50 	 - loss D:	all 7.4536467 	D(real) 0.47890496253967285 	D(fake) 1.0118243217468261 	 G:  2.317086 			lr D:  0.1 	 G:  0.1
	epoch:	 4 / 50 	 - loss D:	all 7.4880238 	D(real) 0.4634555339813232 	D(fake) 1.034149169921875 	 G:  2.238911 			lr D:  0.1 	 G:  0.1
	epoch:	 5 / 50 	 - loss D:	all 7.565174 	D(real) 0.44760966300964355 	D(fake) 1.0654251098632812 	 G:  2.1371553 			lr D:  0.1 	 G:  0.1
	epoch:	 6 / 50 	 - loss D:	all 7.651701 	D(real) 0.4272927284240723 	D(fake) 1.1030474662780763 	 G:  2.038968 			lr D:  0.1 	 G:  0.1
	epoch:	 7 / 50 	 - loss D:	all 7.7216177 	D(real) 0.4077305316925049 	D(fake) 1.1365930557250976 	 G:  1.9668436 			lr D:  0.1 	 G:  0.1
	epoch:	 8 / 50 	 - loss D:	all 7.758412 	D(real) 0.3933208703994751 	D(fake) 1.1583615303039552 	 G:  1.9301699 			lr D:  0.1 	 G:  0.1
	epoch:	 9 / 50 	 - loss D:	all 7.7561865 	D(real) 0.3860130786895752 	D(fake) 1.165224266052246 	 G:  1.9282718 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 10 / 50 	 - loss D:	all 7.6350937 	D(real) 0.3856377601623535 	D(fake) 1.1413809776306152 	 G:  1.9305887 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 11 / 50 	 - loss D:	all 7.630093 	D(real) 0.3861078262329102 	D(fake) 1.1399107933044434 	 G:  1.9346423 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 12 / 50 	 - loss D:	all 7.6239 	D(real) 0.3869154930114746 	D(fake) 1.1378644943237304 	 G:  1.9398847 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 13 / 50 	 - loss D:	all 7.6168427 	D(real) 0.38796708583831785 	D(fake) 1.135401439666748 	 G:  1.945982 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 14 / 50 	 - loss D:	all 7.609222 	D(real) 0.3891876220703125 	D(fake) 1.1326567649841308 	 G:  1.9526482 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 15 / 50 	 - loss D:	all 7.601433 	D(real) 0.3905160903930664 	D(fake) 1.1297704696655273 	 G:  1.9595798 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 16 / 50 	 - loss D:	all 7.5936193 	D(real) 0.3919032335281372 	D(fake) 1.1268206596374513 	 G:  1.9666115 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 17 / 50 	 - loss D:	all 7.5859704 	D(real) 0.39330894947052003 	D(fake) 1.123885154724121 	 G:  1.9735742 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 18 / 50 	 - loss D:	all 7.578663 	D(real) 0.3947011470794678 	D(fake) 1.1210314750671386 	 G:  1.9803183 			lr D:  0.010000000000000002 	 G:  0.010000000000000002
	epoch:	 19 / 50 	 - loss D:	all 7.571677 	D(real) 0.3960543632507324 	D(fake) 1.118281078338623 	 G:  1.986801 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 20 / 50 	 - loss D:	all 7.562207 	D(real) 0.3973489046096802 	D(fake) 1.1150925636291504 	 G:  1.9873997 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 21 / 50 	 - loss D:	all 7.561595 	D(real) 0.3974708080291748 	D(fake) 1.1148481369018555 	 G:  1.9879763 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 22 / 50 	 - loss D:	all 7.5610137 	D(real) 0.3975853681564331 	D(fake) 1.1146173477172852 	 G:  1.9885235 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 23 / 50 	 - loss D:	all 7.560459 	D(real) 0.3976937770843506 	D(fake) 1.1143980026245117 	 G:  1.9890453 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 24 / 50 	 - loss D:	all 7.5599823 	D(real) 0.39779708385467527 	D(fake) 1.1141993522644043 	 G:  1.9895184 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 25 / 50 	 - loss D:	all 7.559415 	D(real) 0.39789595603942873 	D(fake) 1.1139869689941406 	 G:  1.9900278 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 26 / 50 	 - loss D:	all 7.5589056 	D(real) 0.39799113273620607 	D(fake) 1.1137900352478027 	 G:  1.9905 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 27 / 50 	 - loss D:	all 7.5584717 	D(real) 0.3980830669403076 	D(fake) 1.1136112213134766 	 G:  1.99093 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 28 / 50 	 - loss D:	all 7.558064 	D(real) 0.3981722116470337 	D(fake) 1.1134406089782716 	 G:  1.9913404 			lr D:  0.0010000000000000002 	 G:  0.0010000000000000002
	epoch:	 29 / 50 	 - loss D:	all 7.5576153 	D(real) 0.39825899600982667 	D(fake) 1.1132640838623047 	 G:  1.9917667 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 30 / 50 	 - loss D:	all 7.5567083 	D(real) 0.39834353923797605 	D(fake) 1.112998104095459 	 G:  1.991812 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 31 / 50 	 - loss D:	all 7.556654 	D(real) 0.3983518123626709 	D(fake) 1.112979030609131 	 G:  1.9918585 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 32 / 50 	 - loss D:	all 7.556636 	D(real) 0.3983598709106445 	D(fake) 1.112967300415039 	 G:  1.9918865 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 33 / 50 	 - loss D:	all 7.556552 	D(real) 0.3983678579330444 	D(fake) 1.1129425048828125 	 G:  1.9919472 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 34 / 50 	 - loss D:	all 7.5565705 	D(real) 0.3983757019042969 	D(fake) 1.112938404083252 	 G:  1.9919567 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 35 / 50 	 - loss D:	all 7.556487 	D(real) 0.3983834981918335 	D(fake) 1.1129138946533204 	 G:  1.9920169 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 36 / 50 	 - loss D:	all 7.5564823 	D(real) 0.3983911991119385 	D(fake) 1.1129053115844727 	 G:  1.9920374 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 37 / 50 	 - loss D:	all 7.556395 	D(real) 0.3983988046646118 	D(fake) 1.1128802299499512 	 G:  1.9920987 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 38 / 50 	 - loss D:	all 7.5563917 	D(real) 0.3984063625335693 	D(fake) 1.1128719329833985 	 G:  1.9921188 			lr D:  0.00010000000000000003 	 G:  0.00010000000000000003
	epoch:	 39 / 50 	 - loss D:	all 7.5562954 	D(real) 0.398413872718811 	D(fake) 1.112845230102539 	 G:  1.9921842 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 40 / 50 	 - loss D:	all 7.556279 	D(real) 0.3984213829040527 	D(fake) 1.1128344535827637 	 G:  1.9921521 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 41 / 50 	 - loss D:	all 7.5562506 	D(real) 0.39842209815979 	D(fake) 1.112827968597412 	 G:  1.9921681 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 42 / 50 	 - loss D:	all 7.5562687 	D(real) 0.3984228134155273 	D(fake) 1.112830924987793 	 G:  1.9921608 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 43 / 50 	 - loss D:	all 7.5562363 	D(real) 0.39842355251312256 	D(fake) 1.1128236770629882 	 G:  1.9921787 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 44 / 50 	 - loss D:	all 7.5562625 	D(real) 0.3984243154525757 	D(fake) 1.1128281593322753 	 G:  1.9921675 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 45 / 50 	 - loss D:	all 7.556202 	D(real) 0.3984250545501709 	D(fake) 1.1128153800964355 	 G:  1.9921987 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 46 / 50 	 - loss D:	all 7.5561614 	D(real) 0.3984257698059082 	D(fake) 1.112806510925293 	 G:  1.9922206 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 47 / 50 	 - loss D:	all 7.5562344 	D(real) 0.39842653274536133 	D(fake) 1.1128203392028808 	 G:  1.9921869 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 48 / 50 	 - loss D:	all 7.5562 	D(real) 0.39842724800109863 	D(fake) 1.1128128051757813 	 G:  1.9922051 			lr D:  1.0000000000000004e-05 	 G:  1.0000000000000004e-05
	epoch:	 49 / 50 	 - loss D:	all 7.556197 	D(real) 0.39842801094055175 	D(fake) 1.1128114700317382 	 G:  1.9922085 			lr D:  1.0000000000000004e-06 	 G:  1.0000000000000004e-06
1
optim_score: 1
PHASE: Generative Adversarial Network
PREDICT PHASE: Noised data generation
	STATS PHASE:  Correlation and distribution
	PLOT: Predicted Test
		distribution analysis
			distribution analysis: input
			distribution analysis: output
		distribution analysis: real and generated
		correlation analysis
			correlation analysis: input
			correlation analysis: output
Traceback (most recent call last):
  File "/home/ubuntu/mcarbonera/osg/test.py", line 163, in <module>
    experiment_folder_name = f"{main_folder_name}___{case_list_name[case]}_{seed}"
IndexError: list index out of range
 
      Welcome - OSG      
|------------------------
| Process: --nAll
|------------------------
 
|------------------------
| Modelcase   : GAN_linear_pretrained_16_PEMS_bt
|             : {'id': 1, 'model_case': 'GAN_linear_pretrained_16_PEMS_bt', 'epoch': {'AE': 50, 'GAN': 50}, 'univar_count': 16, 'lat_dim': 12, 'dataset_setting': {'batch_size': 128, 'train_percentual': 0.5, 'starting_sample': None, 'train_samples': None, 'test_samples': None, 'noise_samples': None, 'seed': 0}, 'instaces_size': 1, 'input_shape': 'vector'}
|------------------------
 
SETTING PHASE: Seed 
\seed torch:	 0
\seed data:	 0
\seed noise:	 0
SETTING PHASE: Device selection
	device:	 cpu
SETTING PHASE: Model creation
	model_case:	 GAN_linear_pretrained_16_PEMS_bt
SETTING PHASE: Summary model file - DONE
DATASET PHASE: Load maps data
	train samples: done
	test samples: done
	train correlation: done
	test correlation: done
	train correlation plot: done
	test correlation plot: done
saveDataset_setting	 batch_size
saveDataset_setting	 train_percentual
saveDataset_setting	 starting_sample
saveDataset_setting	 train_samples
saveDataset_setting	 test_samples
saveDataset_setting	 noise_samples
saveDataset_setting	 seed
SETTING PHASE: Summary dataset file - DONE
OPTIMIZATION PHASE:
{'JENSEN_SHANNON_DIVERGENCE_LOSS': 0.6, 'MEDIAN_LOSS_batch': 5e-05, 'SPEARMAN_CORRELATION_LOSS': 0.8}
		OPTIMIZATION:	False
TRAINING PHASE: Training data -  AE
	TRAIN TRAINED MODEL:	
AE mode training:	 True
	epoch:	 0 / 50 	 -
	epoch:	 1 / 50 	 - time tr epoch:  0:00:00.020618 	loss:  1.0980313 	lr:  0.01
	epoch:	 2 / 50 	 - time tr epoch:  0:00:00.016251 	loss:  0.13788368 	lr:  0.01
Traceback (most recent call last):
  File "/home/ubuntu/mcarbonera/osg/test.py", line 164, in <module>
    neuroDist(num_case=case, seed=seed, folder=experiment_folder_name )
  File "/home/ubuntu/mcarbonera/osg/test.py", line 77, in neuroDist
    neuroExp = NeuroExperiment(num_case=num_case, folder=folder, seed=seed, load_model=load_model)
  File "/home/ubuntu/mcarbonera/osg/src/NeuroCorrelation/NeuroExperiment.py", line 26, in __init__
    nc.start_experiment()
  File "/home/ubuntu/mcarbonera/osg/src/NeuroCorrelation/NeuralCore.py", line 345, in start_experiment
    model_ae_trained = self.training_model(self.data_splitted, model_type="AE", model=self.model_ae, loss_obj=self.loss_obj['AE'], epoch=self.epoch)
  File "/home/ubuntu/mcarbonera/osg/src/NeuroCorrelation/NeuralCore.py", line 515, in training_model
    optim_score = training_obj.training(batch_size=self.batch_size, model_flatten_in=model_flatten_in,load_model=load_model)
  File "/home/ubuntu/mcarbonera/osg/src/NeuroCorrelation/ModelTraining/ModelTraining.py", line 100, in training
    self.training_AE(plot_loss=plot_loss, batch_size=batch_size, model_flatten_in=model_flatten_in)
  File "/home/ubuntu/mcarbonera/osg/src/NeuroCorrelation/ModelTraining/ModelTraining.py", line 202, in training_AE
    self.plot_grad_flow(named_parameters = self.model.named_parameters(), epoch= f"{epoch+1}")
  File "/home/ubuntu/mcarbonera/osg/src/NeuroCorrelation/ModelTraining/ModelTraining.py", line 442, in plot_grad_flow
    plt.savefig(path_save_gradexpl)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py", line 959, in savefig
    res = fig.savefig(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py", line 3285, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py", line 2338, in print_figure
    result = print_method(
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py", line 2204, in <lambda>
    print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/_api/deprecation.py", line 410, in wrapper
    return func(*inner_args, **inner_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py", line 517, in print_png
    self._print_pil(filename_or_obj, "png", pil_kwargs, metadata)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py", line 463, in _print_pil
    FigureCanvasAgg.draw(self)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py", line 405, in draw
    self.figure.draw(self.renderer)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py", line 74, in draw_wrapper
    result = draw(artist, renderer, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py", line 51, in draw_wrapper
    return draw(artist, renderer)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py", line 3082, in draw
    mimage._draw_list_compositing_images(
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/image.py", line 131, in _draw_list_compositing_images
    a.draw(renderer)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py", line 51, in draw_wrapper
    return draw(artist, renderer)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py", line 3100, in draw
    mimage._draw_list_compositing_images(
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/image.py", line 131, in _draw_list_compositing_images
    a.draw(renderer)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py", line 51, in draw_wrapper
    return draw(artist, renderer)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/patches.py", line 589, in draw
    self._draw_paths_with_artist_properties(
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/patches.py", line 574, in _draw_paths_with_artist_properties
    renderer.draw_path(gc, *draw_path_args)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py", line 146, in draw_path
    self._renderer.draw_path(gc, path, transform, rgbFace)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py", line 251, in __array__
    return self.get_points()
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py", line 1116, in get_points
    points = self._transform.transform(
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py", line 1490, in transform
    res = self.transform_affine(self.transform_non_affine(values))
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py", line 2420, in transform_affine
    return self.get_affine().transform(points)
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py", line 2447, in get_affine
    self._a.get_affine().get_matrix()))
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py", line 2447, in get_affine
    self._a.get_affine().get_matrix()))
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py", line 2608, in get_matrix
    self._mtx = np.array([[outw,  0.0, outl],
KeyboardInterrupt
